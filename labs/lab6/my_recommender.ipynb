{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Recommendation Systems"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load Pandas, we are going to need it for manipulating data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from typing import Optional, List, Tuple, Dict, Any, NoReturn, Iterable, Union, Literal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "_rng: np.random.Generator = np.random.default_rng(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "data": {
      "text/plain": "     0     1     2     3     4     5     6     7     8     9    ...   91   \\\n1  100.0  4.08 -0.29  6.36  4.37 -2.38 -9.66 -0.73 -5.34  8.88  ...  2.82   \n2   49.0   NaN   NaN   NaN   NaN  9.03  9.27  9.03  9.27   NaN  ...   NaN   \n3   48.0   NaN  8.35   NaN   NaN  1.80  8.16 -2.82  6.21   NaN  ...   NaN   \n4   91.0  8.50  4.61 -4.17 -5.39  1.36  1.60  7.04  4.61 -0.44  ...  5.19   \n5  100.0 -6.17 -3.54  0.44 -8.50 -7.09 -4.32 -8.69 -0.87 -6.65  ... -3.54   \n\n    92    93    94    95    96    97    98    99    100  \n1 -4.95 -0.29  7.86 -0.19 -2.14  3.06  0.34 -4.32  1.07  \n2   NaN   NaN  9.08   NaN   NaN   NaN   NaN   NaN   NaN  \n3   NaN   NaN  0.53   NaN   NaN   NaN   NaN   NaN   NaN  \n4  5.58  4.27  5.19  5.73  1.55  3.11  6.55  1.80  1.60  \n5 -6.89 -0.68 -2.96 -2.18 -3.35  0.05 -9.08 -5.05 -3.45  \n\n[5 rows x 101 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n      <th>100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>100.0</td>\n      <td>4.08</td>\n      <td>-0.29</td>\n      <td>6.36</td>\n      <td>4.37</td>\n      <td>-2.38</td>\n      <td>-9.66</td>\n      <td>-0.73</td>\n      <td>-5.34</td>\n      <td>8.88</td>\n      <td>...</td>\n      <td>2.82</td>\n      <td>-4.95</td>\n      <td>-0.29</td>\n      <td>7.86</td>\n      <td>-0.19</td>\n      <td>-2.14</td>\n      <td>3.06</td>\n      <td>0.34</td>\n      <td>-4.32</td>\n      <td>1.07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.03</td>\n      <td>9.27</td>\n      <td>9.03</td>\n      <td>9.27</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.08</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48.0</td>\n      <td>NaN</td>\n      <td>8.35</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.80</td>\n      <td>8.16</td>\n      <td>-2.82</td>\n      <td>6.21</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.53</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>91.0</td>\n      <td>8.50</td>\n      <td>4.61</td>\n      <td>-4.17</td>\n      <td>-5.39</td>\n      <td>1.36</td>\n      <td>1.60</td>\n      <td>7.04</td>\n      <td>4.61</td>\n      <td>-0.44</td>\n      <td>...</td>\n      <td>5.19</td>\n      <td>5.58</td>\n      <td>4.27</td>\n      <td>5.19</td>\n      <td>5.73</td>\n      <td>1.55</td>\n      <td>3.11</td>\n      <td>6.55</td>\n      <td>1.80</td>\n      <td>1.60</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>100.0</td>\n      <td>-6.17</td>\n      <td>-3.54</td>\n      <td>0.44</td>\n      <td>-8.50</td>\n      <td>-7.09</td>\n      <td>-4.32</td>\n      <td>-8.69</td>\n      <td>-0.87</td>\n      <td>-6.65</td>\n      <td>...</td>\n      <td>-3.54</td>\n      <td>-6.89</td>\n      <td>-0.68</td>\n      <td>-2.96</td>\n      <td>-2.18</td>\n      <td>-3.35</td>\n      <td>0.05</td>\n      <td>-9.08</td>\n      <td>-5.05</td>\n      <td>-3.45</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 101 columns</p>\n</div>"
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = [\"rated\"] + [i for i in range(1,101)]\n",
    "\n",
    "\n",
    "\n",
    "data: pd.DataFrame = pd.read_csv(\n",
    "    \"jester-data-1.csv\",\n",
    "    #names=colnames,\n",
    "    header=None\n",
    ")\n",
    "#data.drop(\"rated\", axis=1, inplace=True)\n",
    "\n",
    "data.drop(0, inplace=True)\n",
    "data.replace(99, np.NaN, inplace=True)\n",
    "\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24982, 101)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      72.381109\n",
      "1       0.905104\n",
      "2       0.207988\n",
      "3       0.317174\n",
      "4      -1.448684\n",
      "         ...    \n",
      "96      1.528003\n",
      "97      1.674444\n",
      "98      0.767692\n",
      "99     -0.031244\n",
      "100     1.354711\n",
      "Length: 101, dtype: float64\n",
      "Highest rated: 0 72.38110919240191\n",
      "Lowest  rated: 58 -3.833520447530859\n"
     ]
    }
   ],
   "source": [
    "means: pd.Series = data.mean()\n",
    "\n",
    "print(means)\n",
    "\n",
    "print(f\"Highest rated: {means.idxmax()} {means[means.idxmax()]}\")\n",
    "print(f\"Lowest  rated: {means.idxmin()} {means[means.idxmin()]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data: pd.DataFrame = data.copy()\n",
    "\n",
    "\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1514684  203125  960596 ... 1522583  370175 1644993]\n",
      "(array([    0,     0,     0, ..., 24981, 24981, 24981]), array([ 0,  1,  2, ..., 70, 71, 87]))\n",
      "(array([], dtype=int64),)\n",
      "99s: 0\n"
     ]
    }
   ],
   "source": [
    "def make_validation_set(\n",
    "        original: pd.DataFrame, replace_proportion: float = 0.1, replace_with: Any = 99\n",
    ") -> Tuple[pd.DataFrame, Tuple[np.ndarray], Tuple[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Creates a validation set version of the dataset.\n",
    "    Obtains replace_proportion of the non NaN values in the dataset,\n",
    "    and with those specific selected non-NaNs, replaces\n",
    "    them with replace_with in that dataset.\n",
    "    :param original: \n",
    "    :param size_percent: \n",
    "    :param replace_with:\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    valid_set: pd.DataFrame = original.copy()\n",
    "    rated = np.where(~np.isnan(valid_set.values))\n",
    "    n_rated: int = len(rated[0])\n",
    "    replace_these = _rng.choice(n_rated, size=int(replace_proportion*n_rated), replace=False)\n",
    "\n",
    "    print(replace_these)\n",
    "\n",
    "    print(rated)\n",
    "\n",
    "\n",
    "\n",
    "    valid_vals: np.ndarry = valid_set.values.flatten()\n",
    "    valid_vals.flatten()[replace_these] = replace_with\n",
    "\n",
    "\n",
    "    \n",
    "    nintetynines = np.where(valid_vals==replace_with)\n",
    "\n",
    "    print(nintetynines)\n",
    "\n",
    "    #for x, y in zip(replace_these[0][i], ):\n",
    "    #    valid_set[replace_these[i]]\n",
    "    #valid_set.loc[rated[0][replace_these]],[rated[1][replace_these]] = replace_with\n",
    "    return valid_set, (rated[0][replace_these], rated[1][replace_these])\n",
    "    \n",
    "\n",
    "v_orig: Tuple[pd.DataFrame, Tuple[np.ndarray], Tuple[np.ndarray]] = make_validation_set(\n",
    "    data, 0.1, 99\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "validation: pd.DataFrame = v_orig[0]\n",
    "\n",
    "count_99 = 0\n",
    "\n",
    "for c in validation.columns:\n",
    "    try:\n",
    "        count_99 += validation[c].value_counts()[99]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(f\"99s: {count_99}\")\n",
    "\n",
    "\n",
    "#validation\n",
    "\n",
    "\n",
    "def sgd(iterations, validation_val = 99, train_val = np.NaN):\n",
    "    \"\"\" Iterate over all users and all items and train for \n",
    "        a certain number of iterations\n",
    "    \"\"\"\n",
    "    mse_history = []\n",
    "    for iteration in range(iterations):\n",
    "        error = []\n",
    "        \n",
    "        for user_id in range(latent_user_preferences.shape[0]):\n",
    "            for item_id in range(latent_item_features.shape[0]):\n",
    "                rating = user_ratings[user_id, item_id]\n",
    "                #if not np.isnan(rating):\n",
    "                if (not np.isnan(rating)) and (rating != train_val and rating != validation_val):\n",
    "                    err = train(user_id, item_id, rating)\n",
    "                    error.append(err)\n",
    "        mse = (np.array(error) ** 2).mean()   \n",
    "        if (iteration % 10) == 0:\n",
    "            print('Iteration %d/%d:    MSE=%.3f' % (iteration, iterations, mse))\n",
    "            mse_history.append(mse)\n",
    "    return mse_history\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.02\n"
     ]
    }
   ],
   "source": [
    "#df_jester.iloc[user_x, joke_y].\n",
    "\n",
    "print(data.iloc[19928, 32])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "data": {
      "text/plain": "    Movie ID                                              Title   Factor1  \\\n0         11          Star Wars: Episode IV - A New Hope (1977) -1.521848   \n1         12                                Finding Nemo (2003) -0.342185   \n2         13                                Forrest Gump (1994) -2.240888   \n3         14                             American Beauty (1999) -0.634531   \n4         22  Pirates of the Caribbean: The Curse of the Bla...  0.517348   \n..       ...                                                ...       ...   \n95      9806                             The Incredibles (2004)  0.159967   \n96     10020                        Beauty and the Beast (1991)  1.286288   \n97     36657                                       X-Men (2000)  0.811901   \n98     36658                            X2: X-Men United (2003)  1.161006   \n99     36955                                   True Lies (1994)  1.734008   \n\n     Factor2   Factor3   Factor4   Factor5   Factor6   Factor7   Factor8  \\\n0  -1.038507  2.027269  0.247933 -0.594548  2.513260 -1.848910  0.476710   \n1  -0.296586 -0.385962  2.443297 -1.097015 -0.619465  0.572887  0.329516   \n2  -0.438815 -2.275177  0.614548  0.904469  0.711919 -0.420876  1.302036   \n3   2.186059 -0.066681  0.086197  0.517558 -0.185319 -0.412352  0.063841   \n4  -1.456763  0.369161  0.073903 -0.098332 -0.594722  0.828888  0.033626   \n..       ...       ...       ...       ...       ...       ...       ...   \n95 -0.051123  0.311183  1.841867 -1.952736 -0.836041  0.639252 -0.413082   \n96  0.004957 -0.157640  2.579640 -0.042687 -0.256582 -0.007971  0.458163   \n97 -0.893280  0.668953 -0.885074 -1.070468 -0.973154 -0.037449 -0.925609   \n98 -0.715613  0.712633 -0.688808 -0.717785 -1.007047 -0.267268 -0.802322   \n99  0.265436 -0.003391 -0.491754 -0.322739  0.850165 -0.150377 -0.075895   \n\n     Factor9  Factor10  Factor11  Factor12  Factor13  Factor14  Factor15  \n0  -0.224146 -0.760681 -0.973915  0.862379  0.403861  1.129616 -0.248806  \n1  -0.712228  0.323554 -0.561948 -0.142405 -0.564415  0.506876  1.274993  \n2  -0.868418 -0.160122  0.633667  0.133138 -0.330276 -2.209004 -0.419092  \n3   0.075937 -0.577682  0.526803 -1.465557 -0.819682  0.549010 -0.681191  \n4  -0.707414  0.717877  1.394326 -0.786986  1.429191  0.855746 -2.292566  \n..       ...       ...       ...       ...       ...       ...       ...  \n95 -0.310868  0.448225 -0.846044 -0.158192 -0.649164  0.045580  1.017861  \n96  0.091394  0.323339 -0.862833 -0.508185  0.994535  0.868700 -0.487076  \n97 -0.122112 -0.328822 -0.163103 -0.307299  0.642105 -1.355542  0.067790  \n98 -0.249239 -0.540419 -0.291422 -0.240216  0.290714 -1.217250 -0.288130  \n99  1.373386  0.934767  0.489299 -0.062678  0.333703 -0.223382 -0.022599  \n\n[100 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Movie ID</th>\n      <th>Title</th>\n      <th>Factor1</th>\n      <th>Factor2</th>\n      <th>Factor3</th>\n      <th>Factor4</th>\n      <th>Factor5</th>\n      <th>Factor6</th>\n      <th>Factor7</th>\n      <th>Factor8</th>\n      <th>Factor9</th>\n      <th>Factor10</th>\n      <th>Factor11</th>\n      <th>Factor12</th>\n      <th>Factor13</th>\n      <th>Factor14</th>\n      <th>Factor15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11</td>\n      <td>Star Wars: Episode IV - A New Hope (1977)</td>\n      <td>-1.521848</td>\n      <td>-1.038507</td>\n      <td>2.027269</td>\n      <td>0.247933</td>\n      <td>-0.594548</td>\n      <td>2.513260</td>\n      <td>-1.848910</td>\n      <td>0.476710</td>\n      <td>-0.224146</td>\n      <td>-0.760681</td>\n      <td>-0.973915</td>\n      <td>0.862379</td>\n      <td>0.403861</td>\n      <td>1.129616</td>\n      <td>-0.248806</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12</td>\n      <td>Finding Nemo (2003)</td>\n      <td>-0.342185</td>\n      <td>-0.296586</td>\n      <td>-0.385962</td>\n      <td>2.443297</td>\n      <td>-1.097015</td>\n      <td>-0.619465</td>\n      <td>0.572887</td>\n      <td>0.329516</td>\n      <td>-0.712228</td>\n      <td>0.323554</td>\n      <td>-0.561948</td>\n      <td>-0.142405</td>\n      <td>-0.564415</td>\n      <td>0.506876</td>\n      <td>1.274993</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13</td>\n      <td>Forrest Gump (1994)</td>\n      <td>-2.240888</td>\n      <td>-0.438815</td>\n      <td>-2.275177</td>\n      <td>0.614548</td>\n      <td>0.904469</td>\n      <td>0.711919</td>\n      <td>-0.420876</td>\n      <td>1.302036</td>\n      <td>-0.868418</td>\n      <td>-0.160122</td>\n      <td>0.633667</td>\n      <td>0.133138</td>\n      <td>-0.330276</td>\n      <td>-2.209004</td>\n      <td>-0.419092</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14</td>\n      <td>American Beauty (1999)</td>\n      <td>-0.634531</td>\n      <td>2.186059</td>\n      <td>-0.066681</td>\n      <td>0.086197</td>\n      <td>0.517558</td>\n      <td>-0.185319</td>\n      <td>-0.412352</td>\n      <td>0.063841</td>\n      <td>0.075937</td>\n      <td>-0.577682</td>\n      <td>0.526803</td>\n      <td>-1.465557</td>\n      <td>-0.819682</td>\n      <td>0.549010</td>\n      <td>-0.681191</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22</td>\n      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n      <td>0.517348</td>\n      <td>-1.456763</td>\n      <td>0.369161</td>\n      <td>0.073903</td>\n      <td>-0.098332</td>\n      <td>-0.594722</td>\n      <td>0.828888</td>\n      <td>0.033626</td>\n      <td>-0.707414</td>\n      <td>0.717877</td>\n      <td>1.394326</td>\n      <td>-0.786986</td>\n      <td>1.429191</td>\n      <td>0.855746</td>\n      <td>-2.292566</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>9806</td>\n      <td>The Incredibles (2004)</td>\n      <td>0.159967</td>\n      <td>-0.051123</td>\n      <td>0.311183</td>\n      <td>1.841867</td>\n      <td>-1.952736</td>\n      <td>-0.836041</td>\n      <td>0.639252</td>\n      <td>-0.413082</td>\n      <td>-0.310868</td>\n      <td>0.448225</td>\n      <td>-0.846044</td>\n      <td>-0.158192</td>\n      <td>-0.649164</td>\n      <td>0.045580</td>\n      <td>1.017861</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>10020</td>\n      <td>Beauty and the Beast (1991)</td>\n      <td>1.286288</td>\n      <td>0.004957</td>\n      <td>-0.157640</td>\n      <td>2.579640</td>\n      <td>-0.042687</td>\n      <td>-0.256582</td>\n      <td>-0.007971</td>\n      <td>0.458163</td>\n      <td>0.091394</td>\n      <td>0.323339</td>\n      <td>-0.862833</td>\n      <td>-0.508185</td>\n      <td>0.994535</td>\n      <td>0.868700</td>\n      <td>-0.487076</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>36657</td>\n      <td>X-Men (2000)</td>\n      <td>0.811901</td>\n      <td>-0.893280</td>\n      <td>0.668953</td>\n      <td>-0.885074</td>\n      <td>-1.070468</td>\n      <td>-0.973154</td>\n      <td>-0.037449</td>\n      <td>-0.925609</td>\n      <td>-0.122112</td>\n      <td>-0.328822</td>\n      <td>-0.163103</td>\n      <td>-0.307299</td>\n      <td>0.642105</td>\n      <td>-1.355542</td>\n      <td>0.067790</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>36658</td>\n      <td>X2: X-Men United (2003)</td>\n      <td>1.161006</td>\n      <td>-0.715613</td>\n      <td>0.712633</td>\n      <td>-0.688808</td>\n      <td>-0.717785</td>\n      <td>-1.007047</td>\n      <td>-0.267268</td>\n      <td>-0.802322</td>\n      <td>-0.249239</td>\n      <td>-0.540419</td>\n      <td>-0.291422</td>\n      <td>-0.240216</td>\n      <td>0.290714</td>\n      <td>-1.217250</td>\n      <td>-0.288130</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>36955</td>\n      <td>True Lies (1994)</td>\n      <td>1.734008</td>\n      <td>0.265436</td>\n      <td>-0.003391</td>\n      <td>-0.491754</td>\n      <td>-0.322739</td>\n      <td>0.850165</td>\n      <td>-0.150377</td>\n      <td>-0.075895</td>\n      <td>1.373386</td>\n      <td>0.934767</td>\n      <td>0.489299</td>\n      <td>-0.062678</td>\n      <td>0.333703</td>\n      <td>-0.223382</td>\n      <td>-0.022599</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "movies_df: pd.DataFrame = pd.read_excel(\"movies_latent_factors.xlsx\")\n",
    "\n",
    "movies_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "data": {
      "text/plain": "    User   Factor1   Factor2   Factor3   Factor4   Factor5   Factor6  \\\n0   4768 -0.204024  0.161079 -0.090447  0.138495 -0.162934  0.163894   \n1    156 -0.189652 -0.178979 -0.091490 -0.000823 -0.032646  0.177209   \n2   5323 -0.115308 -0.090886 -0.053129  0.018472 -0.068081 -0.004828   \n3    174 -0.227462 -0.272532 -0.017231  0.054324  0.214755 -0.072639   \n4   4529 -0.014616 -0.102218 -0.107935  0.155784 -0.123362 -0.118228   \n5    783 -0.020301 -0.031919 -0.036955  0.033690  0.000174 -0.003178   \n6   3878 -0.091462  0.215879 -0.180453  0.085408 -0.321094  0.227947   \n7    768  0.000819 -0.009229 -0.019228  0.002703  0.012869  0.006655   \n8   4469 -0.030528 -0.011537 -0.042822 -0.014378  0.031338  0.012297   \n9   1882 -0.083093 -0.029160  0.013748  0.022716 -0.062732 -0.080670   \n10  4997 -0.185443 -0.276496 -0.781275 -0.240506  0.029611 -0.271814   \n11  2067 -0.083242  0.181171 -0.344267 -0.019713 -0.243199  0.039220   \n12  3806 -0.042344 -0.040755 -0.055720 -0.073726  0.018203  0.091940   \n13  2848 -0.113283 -0.098942 -0.040393  0.042180 -0.041068 -0.039568   \n14  4433 -0.298760 -0.290228 -0.160120  0.156277 -0.055364 -0.434205   \n15  3519 -0.068454  0.020090  0.039336  0.002958 -0.018140  0.006501   \n16  5338 -0.061259  0.014661  0.011412  0.001727  0.064996 -0.078448   \n17  3947 -0.022340 -0.115285 -0.136980  0.038593 -0.003029  0.071770   \n18  4373 -0.136550 -0.089406 -0.235399  0.120585 -0.168168  0.129990   \n19  2092 -0.121763  0.011065 -0.037121  0.032568  0.017570  0.095802   \n20   525 -0.040290  0.014383 -0.098967 -0.018957  0.012388  0.035546   \n21  4327  0.008227  0.073899 -0.323967  0.131203 -0.320862  0.054997   \n22  3048 -0.320315  0.078290 -0.083182 -0.221577 -0.078184 -0.145306   \n23  2665 -0.076167 -0.006064 -0.001902 -0.053641  0.021751  0.048207   \n24  4940 -0.113099  0.047643 -0.053024  0.024834  0.010643 -0.012051   \n\n     Factor7   Factor8   Factor9  Factor10  Factor11  Factor12  Factor13  \\\n0   0.051502 -0.088582  0.126829  0.065967  0.085008  0.355404  0.007108   \n1  -0.098123 -0.068283 -0.011575  0.120866 -0.009931 -0.048606  0.045916   \n2   0.113005  0.102107  0.034758  0.000693 -0.073712 -0.019460  0.108372   \n3  -0.033122 -0.086508 -0.131479  0.180403  0.095890 -0.082396  0.036767   \n4  -0.013549 -0.050622  0.058698 -0.159600 -0.142382 -0.132836 -0.039897   \n5   0.054474  0.045424 -0.053308  0.003437 -0.041750  0.059725 -0.021647   \n6   0.053767  0.038017  0.097141 -0.139872  0.029253  0.214467  0.189250   \n7   0.007687  0.018747  0.014705 -0.009256 -0.010116 -0.010051 -0.002108   \n8  -0.000038 -0.010264 -0.006781 -0.019950 -0.014435  0.010926  0.024400   \n9  -0.019723  0.013253 -0.091305 -0.090687  0.030638 -0.113364 -0.021325   \n10 -0.056266 -0.111825 -0.290910 -0.255087 -0.098079  0.103116 -0.100563   \n11 -0.092086  0.114808 -0.036472  0.042386 -0.186812 -0.127038  0.176661   \n12  0.123959 -0.157403 -0.020388  0.082493  0.223057 -0.040915 -0.130308   \n13  0.018291 -0.191254  0.218912  0.017262 -0.087468  0.036894  0.067105   \n14 -0.089259  0.252211 -0.107413 -0.088591  0.121157  0.071371 -0.415598   \n15 -0.108526  0.025045  0.056334 -0.031291 -0.035533  0.005171  0.005546   \n16  0.059510  0.017402 -0.040234 -0.073409 -0.016323  0.031774 -0.062413   \n17 -0.146675 -0.285724 -0.044472 -0.054032  0.064019 -0.045329 -0.111919   \n18 -0.035084 -0.324028  0.087531  0.045290  0.207850 -0.028972 -0.175184   \n19  0.120238 -0.048410  0.008829  0.121778  0.093783  0.044754 -0.003087   \n20  0.000903  0.012835 -0.021080  0.018742 -0.050483 -0.025394  0.034079   \n21  0.060751  0.162314  0.044612 -0.232241  0.094986 -0.106570 -0.051692   \n22 -0.020166  0.124409 -0.063425  0.004726  0.009683  0.028016 -0.018100   \n23 -0.083980  0.146907 -0.057422  0.006085  0.063240  0.086562 -0.132328   \n24 -0.049150  0.006252  0.020429  0.004349  0.028372  0.010227 -0.008233   \n\n    Factor14  Factor15  \n0  -0.118663 -0.039125  \n1   0.113671  0.179873  \n2   0.054471 -0.109552  \n3  -0.165438  0.050692  \n4   0.129063  0.102669  \n5   0.039873 -0.061857  \n6   0.065990  0.102776  \n7   0.043223 -0.006670  \n8   0.005318 -0.007983  \n9   0.181508  0.022357  \n10  0.100164  0.043196  \n11 -0.055812 -0.000042  \n12 -0.021816  0.034549  \n13 -0.016780 -0.029503  \n14 -0.022139 -0.183021  \n15  0.020780 -0.023623  \n16  0.107708  0.065081  \n17  0.066313  0.002395  \n18 -0.058283  0.147797  \n19  0.164487 -0.075231  \n20  0.038330 -0.001341  \n21 -0.093490  0.029534  \n22 -0.128452  0.069972  \n23  0.146198  0.029200  \n24 -0.029304  0.090511  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User</th>\n      <th>Factor1</th>\n      <th>Factor2</th>\n      <th>Factor3</th>\n      <th>Factor4</th>\n      <th>Factor5</th>\n      <th>Factor6</th>\n      <th>Factor7</th>\n      <th>Factor8</th>\n      <th>Factor9</th>\n      <th>Factor10</th>\n      <th>Factor11</th>\n      <th>Factor12</th>\n      <th>Factor13</th>\n      <th>Factor14</th>\n      <th>Factor15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4768</td>\n      <td>-0.204024</td>\n      <td>0.161079</td>\n      <td>-0.090447</td>\n      <td>0.138495</td>\n      <td>-0.162934</td>\n      <td>0.163894</td>\n      <td>0.051502</td>\n      <td>-0.088582</td>\n      <td>0.126829</td>\n      <td>0.065967</td>\n      <td>0.085008</td>\n      <td>0.355404</td>\n      <td>0.007108</td>\n      <td>-0.118663</td>\n      <td>-0.039125</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>156</td>\n      <td>-0.189652</td>\n      <td>-0.178979</td>\n      <td>-0.091490</td>\n      <td>-0.000823</td>\n      <td>-0.032646</td>\n      <td>0.177209</td>\n      <td>-0.098123</td>\n      <td>-0.068283</td>\n      <td>-0.011575</td>\n      <td>0.120866</td>\n      <td>-0.009931</td>\n      <td>-0.048606</td>\n      <td>0.045916</td>\n      <td>0.113671</td>\n      <td>0.179873</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5323</td>\n      <td>-0.115308</td>\n      <td>-0.090886</td>\n      <td>-0.053129</td>\n      <td>0.018472</td>\n      <td>-0.068081</td>\n      <td>-0.004828</td>\n      <td>0.113005</td>\n      <td>0.102107</td>\n      <td>0.034758</td>\n      <td>0.000693</td>\n      <td>-0.073712</td>\n      <td>-0.019460</td>\n      <td>0.108372</td>\n      <td>0.054471</td>\n      <td>-0.109552</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>174</td>\n      <td>-0.227462</td>\n      <td>-0.272532</td>\n      <td>-0.017231</td>\n      <td>0.054324</td>\n      <td>0.214755</td>\n      <td>-0.072639</td>\n      <td>-0.033122</td>\n      <td>-0.086508</td>\n      <td>-0.131479</td>\n      <td>0.180403</td>\n      <td>0.095890</td>\n      <td>-0.082396</td>\n      <td>0.036767</td>\n      <td>-0.165438</td>\n      <td>0.050692</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4529</td>\n      <td>-0.014616</td>\n      <td>-0.102218</td>\n      <td>-0.107935</td>\n      <td>0.155784</td>\n      <td>-0.123362</td>\n      <td>-0.118228</td>\n      <td>-0.013549</td>\n      <td>-0.050622</td>\n      <td>0.058698</td>\n      <td>-0.159600</td>\n      <td>-0.142382</td>\n      <td>-0.132836</td>\n      <td>-0.039897</td>\n      <td>0.129063</td>\n      <td>0.102669</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>783</td>\n      <td>-0.020301</td>\n      <td>-0.031919</td>\n      <td>-0.036955</td>\n      <td>0.033690</td>\n      <td>0.000174</td>\n      <td>-0.003178</td>\n      <td>0.054474</td>\n      <td>0.045424</td>\n      <td>-0.053308</td>\n      <td>0.003437</td>\n      <td>-0.041750</td>\n      <td>0.059725</td>\n      <td>-0.021647</td>\n      <td>0.039873</td>\n      <td>-0.061857</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3878</td>\n      <td>-0.091462</td>\n      <td>0.215879</td>\n      <td>-0.180453</td>\n      <td>0.085408</td>\n      <td>-0.321094</td>\n      <td>0.227947</td>\n      <td>0.053767</td>\n      <td>0.038017</td>\n      <td>0.097141</td>\n      <td>-0.139872</td>\n      <td>0.029253</td>\n      <td>0.214467</td>\n      <td>0.189250</td>\n      <td>0.065990</td>\n      <td>0.102776</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>768</td>\n      <td>0.000819</td>\n      <td>-0.009229</td>\n      <td>-0.019228</td>\n      <td>0.002703</td>\n      <td>0.012869</td>\n      <td>0.006655</td>\n      <td>0.007687</td>\n      <td>0.018747</td>\n      <td>0.014705</td>\n      <td>-0.009256</td>\n      <td>-0.010116</td>\n      <td>-0.010051</td>\n      <td>-0.002108</td>\n      <td>0.043223</td>\n      <td>-0.006670</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4469</td>\n      <td>-0.030528</td>\n      <td>-0.011537</td>\n      <td>-0.042822</td>\n      <td>-0.014378</td>\n      <td>0.031338</td>\n      <td>0.012297</td>\n      <td>-0.000038</td>\n      <td>-0.010264</td>\n      <td>-0.006781</td>\n      <td>-0.019950</td>\n      <td>-0.014435</td>\n      <td>0.010926</td>\n      <td>0.024400</td>\n      <td>0.005318</td>\n      <td>-0.007983</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1882</td>\n      <td>-0.083093</td>\n      <td>-0.029160</td>\n      <td>0.013748</td>\n      <td>0.022716</td>\n      <td>-0.062732</td>\n      <td>-0.080670</td>\n      <td>-0.019723</td>\n      <td>0.013253</td>\n      <td>-0.091305</td>\n      <td>-0.090687</td>\n      <td>0.030638</td>\n      <td>-0.113364</td>\n      <td>-0.021325</td>\n      <td>0.181508</td>\n      <td>0.022357</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4997</td>\n      <td>-0.185443</td>\n      <td>-0.276496</td>\n      <td>-0.781275</td>\n      <td>-0.240506</td>\n      <td>0.029611</td>\n      <td>-0.271814</td>\n      <td>-0.056266</td>\n      <td>-0.111825</td>\n      <td>-0.290910</td>\n      <td>-0.255087</td>\n      <td>-0.098079</td>\n      <td>0.103116</td>\n      <td>-0.100563</td>\n      <td>0.100164</td>\n      <td>0.043196</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2067</td>\n      <td>-0.083242</td>\n      <td>0.181171</td>\n      <td>-0.344267</td>\n      <td>-0.019713</td>\n      <td>-0.243199</td>\n      <td>0.039220</td>\n      <td>-0.092086</td>\n      <td>0.114808</td>\n      <td>-0.036472</td>\n      <td>0.042386</td>\n      <td>-0.186812</td>\n      <td>-0.127038</td>\n      <td>0.176661</td>\n      <td>-0.055812</td>\n      <td>-0.000042</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>3806</td>\n      <td>-0.042344</td>\n      <td>-0.040755</td>\n      <td>-0.055720</td>\n      <td>-0.073726</td>\n      <td>0.018203</td>\n      <td>0.091940</td>\n      <td>0.123959</td>\n      <td>-0.157403</td>\n      <td>-0.020388</td>\n      <td>0.082493</td>\n      <td>0.223057</td>\n      <td>-0.040915</td>\n      <td>-0.130308</td>\n      <td>-0.021816</td>\n      <td>0.034549</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2848</td>\n      <td>-0.113283</td>\n      <td>-0.098942</td>\n      <td>-0.040393</td>\n      <td>0.042180</td>\n      <td>-0.041068</td>\n      <td>-0.039568</td>\n      <td>0.018291</td>\n      <td>-0.191254</td>\n      <td>0.218912</td>\n      <td>0.017262</td>\n      <td>-0.087468</td>\n      <td>0.036894</td>\n      <td>0.067105</td>\n      <td>-0.016780</td>\n      <td>-0.029503</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4433</td>\n      <td>-0.298760</td>\n      <td>-0.290228</td>\n      <td>-0.160120</td>\n      <td>0.156277</td>\n      <td>-0.055364</td>\n      <td>-0.434205</td>\n      <td>-0.089259</td>\n      <td>0.252211</td>\n      <td>-0.107413</td>\n      <td>-0.088591</td>\n      <td>0.121157</td>\n      <td>0.071371</td>\n      <td>-0.415598</td>\n      <td>-0.022139</td>\n      <td>-0.183021</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>3519</td>\n      <td>-0.068454</td>\n      <td>0.020090</td>\n      <td>0.039336</td>\n      <td>0.002958</td>\n      <td>-0.018140</td>\n      <td>0.006501</td>\n      <td>-0.108526</td>\n      <td>0.025045</td>\n      <td>0.056334</td>\n      <td>-0.031291</td>\n      <td>-0.035533</td>\n      <td>0.005171</td>\n      <td>0.005546</td>\n      <td>0.020780</td>\n      <td>-0.023623</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>5338</td>\n      <td>-0.061259</td>\n      <td>0.014661</td>\n      <td>0.011412</td>\n      <td>0.001727</td>\n      <td>0.064996</td>\n      <td>-0.078448</td>\n      <td>0.059510</td>\n      <td>0.017402</td>\n      <td>-0.040234</td>\n      <td>-0.073409</td>\n      <td>-0.016323</td>\n      <td>0.031774</td>\n      <td>-0.062413</td>\n      <td>0.107708</td>\n      <td>0.065081</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>3947</td>\n      <td>-0.022340</td>\n      <td>-0.115285</td>\n      <td>-0.136980</td>\n      <td>0.038593</td>\n      <td>-0.003029</td>\n      <td>0.071770</td>\n      <td>-0.146675</td>\n      <td>-0.285724</td>\n      <td>-0.044472</td>\n      <td>-0.054032</td>\n      <td>0.064019</td>\n      <td>-0.045329</td>\n      <td>-0.111919</td>\n      <td>0.066313</td>\n      <td>0.002395</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>4373</td>\n      <td>-0.136550</td>\n      <td>-0.089406</td>\n      <td>-0.235399</td>\n      <td>0.120585</td>\n      <td>-0.168168</td>\n      <td>0.129990</td>\n      <td>-0.035084</td>\n      <td>-0.324028</td>\n      <td>0.087531</td>\n      <td>0.045290</td>\n      <td>0.207850</td>\n      <td>-0.028972</td>\n      <td>-0.175184</td>\n      <td>-0.058283</td>\n      <td>0.147797</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2092</td>\n      <td>-0.121763</td>\n      <td>0.011065</td>\n      <td>-0.037121</td>\n      <td>0.032568</td>\n      <td>0.017570</td>\n      <td>0.095802</td>\n      <td>0.120238</td>\n      <td>-0.048410</td>\n      <td>0.008829</td>\n      <td>0.121778</td>\n      <td>0.093783</td>\n      <td>0.044754</td>\n      <td>-0.003087</td>\n      <td>0.164487</td>\n      <td>-0.075231</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>525</td>\n      <td>-0.040290</td>\n      <td>0.014383</td>\n      <td>-0.098967</td>\n      <td>-0.018957</td>\n      <td>0.012388</td>\n      <td>0.035546</td>\n      <td>0.000903</td>\n      <td>0.012835</td>\n      <td>-0.021080</td>\n      <td>0.018742</td>\n      <td>-0.050483</td>\n      <td>-0.025394</td>\n      <td>0.034079</td>\n      <td>0.038330</td>\n      <td>-0.001341</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>4327</td>\n      <td>0.008227</td>\n      <td>0.073899</td>\n      <td>-0.323967</td>\n      <td>0.131203</td>\n      <td>-0.320862</td>\n      <td>0.054997</td>\n      <td>0.060751</td>\n      <td>0.162314</td>\n      <td>0.044612</td>\n      <td>-0.232241</td>\n      <td>0.094986</td>\n      <td>-0.106570</td>\n      <td>-0.051692</td>\n      <td>-0.093490</td>\n      <td>0.029534</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>3048</td>\n      <td>-0.320315</td>\n      <td>0.078290</td>\n      <td>-0.083182</td>\n      <td>-0.221577</td>\n      <td>-0.078184</td>\n      <td>-0.145306</td>\n      <td>-0.020166</td>\n      <td>0.124409</td>\n      <td>-0.063425</td>\n      <td>0.004726</td>\n      <td>0.009683</td>\n      <td>0.028016</td>\n      <td>-0.018100</td>\n      <td>-0.128452</td>\n      <td>0.069972</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2665</td>\n      <td>-0.076167</td>\n      <td>-0.006064</td>\n      <td>-0.001902</td>\n      <td>-0.053641</td>\n      <td>0.021751</td>\n      <td>0.048207</td>\n      <td>-0.083980</td>\n      <td>0.146907</td>\n      <td>-0.057422</td>\n      <td>0.006085</td>\n      <td>0.063240</td>\n      <td>0.086562</td>\n      <td>-0.132328</td>\n      <td>0.146198</td>\n      <td>0.029200</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>4940</td>\n      <td>-0.113099</td>\n      <td>0.047643</td>\n      <td>-0.053024</td>\n      <td>0.024834</td>\n      <td>0.010643</td>\n      <td>-0.012051</td>\n      <td>-0.049150</td>\n      <td>0.006252</td>\n      <td>0.020429</td>\n      <td>0.004349</td>\n      <td>0.028372</td>\n      <td>0.010227</td>\n      <td>-0.008233</td>\n      <td>-0.029304</td>\n      <td>0.090511</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_users: pd.DataFrame = pd.read_excel(\"movies_latent_factors.xlsx\",sheet_name=\"Users\")\n",
    "\n",
    "movies_users\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [
    {
     "data": {
      "text/plain": "    Factor14\n97 -1.355542",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Factor14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>97</th>\n      <td>-1.355542</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In the movies dataset, what's the loading (i.e., value) of\n",
    "# Factor14 for the movie with ID=24?\n",
    "\n",
    "movies_df.loc[movies_df['Movie ID'] == 36657, [\"Factor14\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [
    {
     "data": {
      "text/plain": "    Movie ID                       Title   Factor1  Factor2   Factor3  \\\n51       604  The Matrix Reloaded (2003)  0.503414 -2.00445  0.001084   \n\n     Factor4   Factor5  Factor6   Factor7   Factor8   Factor9  Factor10  \\\n51 -2.255945  0.882547  -0.1886 -0.235434  0.570028 -3.492897 -0.312214   \n\n    Factor11  Factor12  Factor13  Factor14  Factor15  \n51  0.902742 -2.063318 -1.895101  0.748458  2.120907  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Movie ID</th>\n      <th>Title</th>\n      <th>Factor1</th>\n      <th>Factor2</th>\n      <th>Factor3</th>\n      <th>Factor4</th>\n      <th>Factor5</th>\n      <th>Factor6</th>\n      <th>Factor7</th>\n      <th>Factor8</th>\n      <th>Factor9</th>\n      <th>Factor10</th>\n      <th>Factor11</th>\n      <th>Factor12</th>\n      <th>Factor13</th>\n      <th>Factor14</th>\n      <th>Factor15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>51</th>\n      <td>604</td>\n      <td>The Matrix Reloaded (2003)</td>\n      <td>0.503414</td>\n      <td>-2.00445</td>\n      <td>0.001084</td>\n      <td>-2.255945</td>\n      <td>0.882547</td>\n      <td>-0.1886</td>\n      <td>-0.235434</td>\n      <td>0.570028</td>\n      <td>-3.492897</td>\n      <td>-0.312214</td>\n      <td>0.902742</td>\n      <td>-2.063318</td>\n      <td>-1.895101</td>\n      <td>0.748458</td>\n      <td>2.120907</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In the movies dataset, which of the following titles\n",
    "# corresponds to the movie with the lowest loading of factor 12?\n",
    "\n",
    "movies_df.loc[movies_df['Factor15'] == np.max(movies_df['Factor15']), :]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_latent_factors = 15\n",
    "\n",
    "#user_ratings = movies_users.values\n",
    "# Initialise as random values\n",
    "latent_user_preferences: pd.DataFrame = movies_users.copy()\n",
    "latent_item_features: pd.DataFrame = movies_df.copy()\n",
    "\n",
    "latent_user_preferences.set_index(\"User\", inplace=True)\n",
    "latent_item_features.drop(\"Title\", axis=1,inplace=True)\n",
    "latent_item_features.set_index(\"Movie ID\", inplace=True)\n",
    "\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "data": {
      "text/plain": "           Factor1   Factor2   Factor3   Factor4   Factor5   Factor6  \\\nMovie ID                                                               \n11       -1.521848 -1.038507  2.027269  0.247933 -0.594548  2.513260   \n12       -0.342185 -0.296586 -0.385962  2.443297 -1.097015 -0.619465   \n13       -2.240888 -0.438815 -2.275177  0.614548  0.904469  0.711919   \n14       -0.634531  2.186059 -0.066681  0.086197  0.517558 -0.185319   \n22        0.517348 -1.456763  0.369161  0.073903 -0.098332 -0.594722   \n...            ...       ...       ...       ...       ...       ...   \n9806      0.159967 -0.051123  0.311183  1.841867 -1.952736 -0.836041   \n10020     1.286288  0.004957 -0.157640  2.579640 -0.042687 -0.256582   \n36657     0.811901 -0.893280  0.668953 -0.885074 -1.070468 -0.973154   \n36658     1.161006 -0.715613  0.712633 -0.688808 -0.717785 -1.007047   \n36955     1.734008  0.265436 -0.003391 -0.491754 -0.322739  0.850165   \n\n           Factor7   Factor8   Factor9  Factor10  Factor11  Factor12  \\\nMovie ID                                                               \n11       -1.848910  0.476710 -0.224146 -0.760681 -0.973915  0.862379   \n12        0.572887  0.329516 -0.712228  0.323554 -0.561948 -0.142405   \n13       -0.420876  1.302036 -0.868418 -0.160122  0.633667  0.133138   \n14       -0.412352  0.063841  0.075937 -0.577682  0.526803 -1.465557   \n22        0.828888  0.033626 -0.707414  0.717877  1.394326 -0.786986   \n...            ...       ...       ...       ...       ...       ...   \n9806      0.639252 -0.413082 -0.310868  0.448225 -0.846044 -0.158192   \n10020    -0.007971  0.458163  0.091394  0.323339 -0.862833 -0.508185   \n36657    -0.037449 -0.925609 -0.122112 -0.328822 -0.163103 -0.307299   \n36658    -0.267268 -0.802322 -0.249239 -0.540419 -0.291422 -0.240216   \n36955    -0.150377 -0.075895  1.373386  0.934767  0.489299 -0.062678   \n\n          Factor13  Factor14  Factor15  \nMovie ID                                \n11        0.403861  1.129616 -0.248806  \n12       -0.564415  0.506876  1.274993  \n13       -0.330276 -2.209004 -0.419092  \n14       -0.819682  0.549010 -0.681191  \n22        1.429191  0.855746 -2.292566  \n...            ...       ...       ...  \n9806     -0.649164  0.045580  1.017861  \n10020     0.994535  0.868700 -0.487076  \n36657     0.642105 -1.355542  0.067790  \n36658     0.290714 -1.217250 -0.288130  \n36955     0.333703 -0.223382 -0.022599  \n\n[100 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Factor1</th>\n      <th>Factor2</th>\n      <th>Factor3</th>\n      <th>Factor4</th>\n      <th>Factor5</th>\n      <th>Factor6</th>\n      <th>Factor7</th>\n      <th>Factor8</th>\n      <th>Factor9</th>\n      <th>Factor10</th>\n      <th>Factor11</th>\n      <th>Factor12</th>\n      <th>Factor13</th>\n      <th>Factor14</th>\n      <th>Factor15</th>\n    </tr>\n    <tr>\n      <th>Movie ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>-1.521848</td>\n      <td>-1.038507</td>\n      <td>2.027269</td>\n      <td>0.247933</td>\n      <td>-0.594548</td>\n      <td>2.513260</td>\n      <td>-1.848910</td>\n      <td>0.476710</td>\n      <td>-0.224146</td>\n      <td>-0.760681</td>\n      <td>-0.973915</td>\n      <td>0.862379</td>\n      <td>0.403861</td>\n      <td>1.129616</td>\n      <td>-0.248806</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>-0.342185</td>\n      <td>-0.296586</td>\n      <td>-0.385962</td>\n      <td>2.443297</td>\n      <td>-1.097015</td>\n      <td>-0.619465</td>\n      <td>0.572887</td>\n      <td>0.329516</td>\n      <td>-0.712228</td>\n      <td>0.323554</td>\n      <td>-0.561948</td>\n      <td>-0.142405</td>\n      <td>-0.564415</td>\n      <td>0.506876</td>\n      <td>1.274993</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>-2.240888</td>\n      <td>-0.438815</td>\n      <td>-2.275177</td>\n      <td>0.614548</td>\n      <td>0.904469</td>\n      <td>0.711919</td>\n      <td>-0.420876</td>\n      <td>1.302036</td>\n      <td>-0.868418</td>\n      <td>-0.160122</td>\n      <td>0.633667</td>\n      <td>0.133138</td>\n      <td>-0.330276</td>\n      <td>-2.209004</td>\n      <td>-0.419092</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>-0.634531</td>\n      <td>2.186059</td>\n      <td>-0.066681</td>\n      <td>0.086197</td>\n      <td>0.517558</td>\n      <td>-0.185319</td>\n      <td>-0.412352</td>\n      <td>0.063841</td>\n      <td>0.075937</td>\n      <td>-0.577682</td>\n      <td>0.526803</td>\n      <td>-1.465557</td>\n      <td>-0.819682</td>\n      <td>0.549010</td>\n      <td>-0.681191</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.517348</td>\n      <td>-1.456763</td>\n      <td>0.369161</td>\n      <td>0.073903</td>\n      <td>-0.098332</td>\n      <td>-0.594722</td>\n      <td>0.828888</td>\n      <td>0.033626</td>\n      <td>-0.707414</td>\n      <td>0.717877</td>\n      <td>1.394326</td>\n      <td>-0.786986</td>\n      <td>1.429191</td>\n      <td>0.855746</td>\n      <td>-2.292566</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9806</th>\n      <td>0.159967</td>\n      <td>-0.051123</td>\n      <td>0.311183</td>\n      <td>1.841867</td>\n      <td>-1.952736</td>\n      <td>-0.836041</td>\n      <td>0.639252</td>\n      <td>-0.413082</td>\n      <td>-0.310868</td>\n      <td>0.448225</td>\n      <td>-0.846044</td>\n      <td>-0.158192</td>\n      <td>-0.649164</td>\n      <td>0.045580</td>\n      <td>1.017861</td>\n    </tr>\n    <tr>\n      <th>10020</th>\n      <td>1.286288</td>\n      <td>0.004957</td>\n      <td>-0.157640</td>\n      <td>2.579640</td>\n      <td>-0.042687</td>\n      <td>-0.256582</td>\n      <td>-0.007971</td>\n      <td>0.458163</td>\n      <td>0.091394</td>\n      <td>0.323339</td>\n      <td>-0.862833</td>\n      <td>-0.508185</td>\n      <td>0.994535</td>\n      <td>0.868700</td>\n      <td>-0.487076</td>\n    </tr>\n    <tr>\n      <th>36657</th>\n      <td>0.811901</td>\n      <td>-0.893280</td>\n      <td>0.668953</td>\n      <td>-0.885074</td>\n      <td>-1.070468</td>\n      <td>-0.973154</td>\n      <td>-0.037449</td>\n      <td>-0.925609</td>\n      <td>-0.122112</td>\n      <td>-0.328822</td>\n      <td>-0.163103</td>\n      <td>-0.307299</td>\n      <td>0.642105</td>\n      <td>-1.355542</td>\n      <td>0.067790</td>\n    </tr>\n    <tr>\n      <th>36658</th>\n      <td>1.161006</td>\n      <td>-0.715613</td>\n      <td>0.712633</td>\n      <td>-0.688808</td>\n      <td>-0.717785</td>\n      <td>-1.007047</td>\n      <td>-0.267268</td>\n      <td>-0.802322</td>\n      <td>-0.249239</td>\n      <td>-0.540419</td>\n      <td>-0.291422</td>\n      <td>-0.240216</td>\n      <td>0.290714</td>\n      <td>-1.217250</td>\n      <td>-0.288130</td>\n    </tr>\n    <tr>\n      <th>36955</th>\n      <td>1.734008</td>\n      <td>0.265436</td>\n      <td>-0.003391</td>\n      <td>-0.491754</td>\n      <td>-0.322739</td>\n      <td>0.850165</td>\n      <td>-0.150377</td>\n      <td>-0.075895</td>\n      <td>1.373386</td>\n      <td>0.934767</td>\n      <td>0.489299</td>\n      <td>-0.062678</td>\n      <td>0.333703</td>\n      <td>-0.223382</td>\n      <td>-0.022599</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_item_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "data": {
      "text/plain": "       Factor1   Factor2   Factor3   Factor4   Factor5   Factor6   Factor7  \\\nUser                                                                         \n4768 -0.204024  0.161079 -0.090447  0.138495 -0.162934  0.163894  0.051502   \n156  -0.189652 -0.178979 -0.091490 -0.000823 -0.032646  0.177209 -0.098123   \n5323 -0.115308 -0.090886 -0.053129  0.018472 -0.068081 -0.004828  0.113005   \n174  -0.227462 -0.272532 -0.017231  0.054324  0.214755 -0.072639 -0.033122   \n4529 -0.014616 -0.102218 -0.107935  0.155784 -0.123362 -0.118228 -0.013549   \n783  -0.020301 -0.031919 -0.036955  0.033690  0.000174 -0.003178  0.054474   \n3878 -0.091462  0.215879 -0.180453  0.085408 -0.321094  0.227947  0.053767   \n768   0.000819 -0.009229 -0.019228  0.002703  0.012869  0.006655  0.007687   \n4469 -0.030528 -0.011537 -0.042822 -0.014378  0.031338  0.012297 -0.000038   \n1882 -0.083093 -0.029160  0.013748  0.022716 -0.062732 -0.080670 -0.019723   \n4997 -0.185443 -0.276496 -0.781275 -0.240506  0.029611 -0.271814 -0.056266   \n2067 -0.083242  0.181171 -0.344267 -0.019713 -0.243199  0.039220 -0.092086   \n3806 -0.042344 -0.040755 -0.055720 -0.073726  0.018203  0.091940  0.123959   \n2848 -0.113283 -0.098942 -0.040393  0.042180 -0.041068 -0.039568  0.018291   \n4433 -0.298760 -0.290228 -0.160120  0.156277 -0.055364 -0.434205 -0.089259   \n3519 -0.068454  0.020090  0.039336  0.002958 -0.018140  0.006501 -0.108526   \n5338 -0.061259  0.014661  0.011412  0.001727  0.064996 -0.078448  0.059510   \n3947 -0.022340 -0.115285 -0.136980  0.038593 -0.003029  0.071770 -0.146675   \n4373 -0.136550 -0.089406 -0.235399  0.120585 -0.168168  0.129990 -0.035084   \n2092 -0.121763  0.011065 -0.037121  0.032568  0.017570  0.095802  0.120238   \n525  -0.040290  0.014383 -0.098967 -0.018957  0.012388  0.035546  0.000903   \n4327  0.008227  0.073899 -0.323967  0.131203 -0.320862  0.054997  0.060751   \n3048 -0.320315  0.078290 -0.083182 -0.221577 -0.078184 -0.145306 -0.020166   \n2665 -0.076167 -0.006064 -0.001902 -0.053641  0.021751  0.048207 -0.083980   \n4940 -0.113099  0.047643 -0.053024  0.024834  0.010643 -0.012051 -0.049150   \n\n       Factor8   Factor9  Factor10  Factor11  Factor12  Factor13  Factor14  \\\nUser                                                                         \n4768 -0.088582  0.126829  0.065967  0.085008  0.355404  0.007108 -0.118663   \n156  -0.068283 -0.011575  0.120866 -0.009931 -0.048606  0.045916  0.113671   \n5323  0.102107  0.034758  0.000693 -0.073712 -0.019460  0.108372  0.054471   \n174  -0.086508 -0.131479  0.180403  0.095890 -0.082396  0.036767 -0.165438   \n4529 -0.050622  0.058698 -0.159600 -0.142382 -0.132836 -0.039897  0.129063   \n783   0.045424 -0.053308  0.003437 -0.041750  0.059725 -0.021647  0.039873   \n3878  0.038017  0.097141 -0.139872  0.029253  0.214467  0.189250  0.065990   \n768   0.018747  0.014705 -0.009256 -0.010116 -0.010051 -0.002108  0.043223   \n4469 -0.010264 -0.006781 -0.019950 -0.014435  0.010926  0.024400  0.005318   \n1882  0.013253 -0.091305 -0.090687  0.030638 -0.113364 -0.021325  0.181508   \n4997 -0.111825 -0.290910 -0.255087 -0.098079  0.103116 -0.100563  0.100164   \n2067  0.114808 -0.036472  0.042386 -0.186812 -0.127038  0.176661 -0.055812   \n3806 -0.157403 -0.020388  0.082493  0.223057 -0.040915 -0.130308 -0.021816   \n2848 -0.191254  0.218912  0.017262 -0.087468  0.036894  0.067105 -0.016780   \n4433  0.252211 -0.107413 -0.088591  0.121157  0.071371 -0.415598 -0.022139   \n3519  0.025045  0.056334 -0.031291 -0.035533  0.005171  0.005546  0.020780   \n5338  0.017402 -0.040234 -0.073409 -0.016323  0.031774 -0.062413  0.107708   \n3947 -0.285724 -0.044472 -0.054032  0.064019 -0.045329 -0.111919  0.066313   \n4373 -0.324028  0.087531  0.045290  0.207850 -0.028972 -0.175184 -0.058283   \n2092 -0.048410  0.008829  0.121778  0.093783  0.044754 -0.003087  0.164487   \n525   0.012835 -0.021080  0.018742 -0.050483 -0.025394  0.034079  0.038330   \n4327  0.162314  0.044612 -0.232241  0.094986 -0.106570 -0.051692 -0.093490   \n3048  0.124409 -0.063425  0.004726  0.009683  0.028016 -0.018100 -0.128452   \n2665  0.146907 -0.057422  0.006085  0.063240  0.086562 -0.132328  0.146198   \n4940  0.006252  0.020429  0.004349  0.028372  0.010227 -0.008233 -0.029304   \n\n      Factor15  \nUser            \n4768 -0.039125  \n156   0.179873  \n5323 -0.109552  \n174   0.050692  \n4529  0.102669  \n783  -0.061857  \n3878  0.102776  \n768  -0.006670  \n4469 -0.007983  \n1882  0.022357  \n4997  0.043196  \n2067 -0.000042  \n3806  0.034549  \n2848 -0.029503  \n4433 -0.183021  \n3519 -0.023623  \n5338  0.065081  \n3947  0.002395  \n4373  0.147797  \n2092 -0.075231  \n525  -0.001341  \n4327  0.029534  \n3048  0.069972  \n2665  0.029200  \n4940  0.090511  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Factor1</th>\n      <th>Factor2</th>\n      <th>Factor3</th>\n      <th>Factor4</th>\n      <th>Factor5</th>\n      <th>Factor6</th>\n      <th>Factor7</th>\n      <th>Factor8</th>\n      <th>Factor9</th>\n      <th>Factor10</th>\n      <th>Factor11</th>\n      <th>Factor12</th>\n      <th>Factor13</th>\n      <th>Factor14</th>\n      <th>Factor15</th>\n    </tr>\n    <tr>\n      <th>User</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4768</th>\n      <td>-0.204024</td>\n      <td>0.161079</td>\n      <td>-0.090447</td>\n      <td>0.138495</td>\n      <td>-0.162934</td>\n      <td>0.163894</td>\n      <td>0.051502</td>\n      <td>-0.088582</td>\n      <td>0.126829</td>\n      <td>0.065967</td>\n      <td>0.085008</td>\n      <td>0.355404</td>\n      <td>0.007108</td>\n      <td>-0.118663</td>\n      <td>-0.039125</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>-0.189652</td>\n      <td>-0.178979</td>\n      <td>-0.091490</td>\n      <td>-0.000823</td>\n      <td>-0.032646</td>\n      <td>0.177209</td>\n      <td>-0.098123</td>\n      <td>-0.068283</td>\n      <td>-0.011575</td>\n      <td>0.120866</td>\n      <td>-0.009931</td>\n      <td>-0.048606</td>\n      <td>0.045916</td>\n      <td>0.113671</td>\n      <td>0.179873</td>\n    </tr>\n    <tr>\n      <th>5323</th>\n      <td>-0.115308</td>\n      <td>-0.090886</td>\n      <td>-0.053129</td>\n      <td>0.018472</td>\n      <td>-0.068081</td>\n      <td>-0.004828</td>\n      <td>0.113005</td>\n      <td>0.102107</td>\n      <td>0.034758</td>\n      <td>0.000693</td>\n      <td>-0.073712</td>\n      <td>-0.019460</td>\n      <td>0.108372</td>\n      <td>0.054471</td>\n      <td>-0.109552</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>-0.227462</td>\n      <td>-0.272532</td>\n      <td>-0.017231</td>\n      <td>0.054324</td>\n      <td>0.214755</td>\n      <td>-0.072639</td>\n      <td>-0.033122</td>\n      <td>-0.086508</td>\n      <td>-0.131479</td>\n      <td>0.180403</td>\n      <td>0.095890</td>\n      <td>-0.082396</td>\n      <td>0.036767</td>\n      <td>-0.165438</td>\n      <td>0.050692</td>\n    </tr>\n    <tr>\n      <th>4529</th>\n      <td>-0.014616</td>\n      <td>-0.102218</td>\n      <td>-0.107935</td>\n      <td>0.155784</td>\n      <td>-0.123362</td>\n      <td>-0.118228</td>\n      <td>-0.013549</td>\n      <td>-0.050622</td>\n      <td>0.058698</td>\n      <td>-0.159600</td>\n      <td>-0.142382</td>\n      <td>-0.132836</td>\n      <td>-0.039897</td>\n      <td>0.129063</td>\n      <td>0.102669</td>\n    </tr>\n    <tr>\n      <th>783</th>\n      <td>-0.020301</td>\n      <td>-0.031919</td>\n      <td>-0.036955</td>\n      <td>0.033690</td>\n      <td>0.000174</td>\n      <td>-0.003178</td>\n      <td>0.054474</td>\n      <td>0.045424</td>\n      <td>-0.053308</td>\n      <td>0.003437</td>\n      <td>-0.041750</td>\n      <td>0.059725</td>\n      <td>-0.021647</td>\n      <td>0.039873</td>\n      <td>-0.061857</td>\n    </tr>\n    <tr>\n      <th>3878</th>\n      <td>-0.091462</td>\n      <td>0.215879</td>\n      <td>-0.180453</td>\n      <td>0.085408</td>\n      <td>-0.321094</td>\n      <td>0.227947</td>\n      <td>0.053767</td>\n      <td>0.038017</td>\n      <td>0.097141</td>\n      <td>-0.139872</td>\n      <td>0.029253</td>\n      <td>0.214467</td>\n      <td>0.189250</td>\n      <td>0.065990</td>\n      <td>0.102776</td>\n    </tr>\n    <tr>\n      <th>768</th>\n      <td>0.000819</td>\n      <td>-0.009229</td>\n      <td>-0.019228</td>\n      <td>0.002703</td>\n      <td>0.012869</td>\n      <td>0.006655</td>\n      <td>0.007687</td>\n      <td>0.018747</td>\n      <td>0.014705</td>\n      <td>-0.009256</td>\n      <td>-0.010116</td>\n      <td>-0.010051</td>\n      <td>-0.002108</td>\n      <td>0.043223</td>\n      <td>-0.006670</td>\n    </tr>\n    <tr>\n      <th>4469</th>\n      <td>-0.030528</td>\n      <td>-0.011537</td>\n      <td>-0.042822</td>\n      <td>-0.014378</td>\n      <td>0.031338</td>\n      <td>0.012297</td>\n      <td>-0.000038</td>\n      <td>-0.010264</td>\n      <td>-0.006781</td>\n      <td>-0.019950</td>\n      <td>-0.014435</td>\n      <td>0.010926</td>\n      <td>0.024400</td>\n      <td>0.005318</td>\n      <td>-0.007983</td>\n    </tr>\n    <tr>\n      <th>1882</th>\n      <td>-0.083093</td>\n      <td>-0.029160</td>\n      <td>0.013748</td>\n      <td>0.022716</td>\n      <td>-0.062732</td>\n      <td>-0.080670</td>\n      <td>-0.019723</td>\n      <td>0.013253</td>\n      <td>-0.091305</td>\n      <td>-0.090687</td>\n      <td>0.030638</td>\n      <td>-0.113364</td>\n      <td>-0.021325</td>\n      <td>0.181508</td>\n      <td>0.022357</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>-0.185443</td>\n      <td>-0.276496</td>\n      <td>-0.781275</td>\n      <td>-0.240506</td>\n      <td>0.029611</td>\n      <td>-0.271814</td>\n      <td>-0.056266</td>\n      <td>-0.111825</td>\n      <td>-0.290910</td>\n      <td>-0.255087</td>\n      <td>-0.098079</td>\n      <td>0.103116</td>\n      <td>-0.100563</td>\n      <td>0.100164</td>\n      <td>0.043196</td>\n    </tr>\n    <tr>\n      <th>2067</th>\n      <td>-0.083242</td>\n      <td>0.181171</td>\n      <td>-0.344267</td>\n      <td>-0.019713</td>\n      <td>-0.243199</td>\n      <td>0.039220</td>\n      <td>-0.092086</td>\n      <td>0.114808</td>\n      <td>-0.036472</td>\n      <td>0.042386</td>\n      <td>-0.186812</td>\n      <td>-0.127038</td>\n      <td>0.176661</td>\n      <td>-0.055812</td>\n      <td>-0.000042</td>\n    </tr>\n    <tr>\n      <th>3806</th>\n      <td>-0.042344</td>\n      <td>-0.040755</td>\n      <td>-0.055720</td>\n      <td>-0.073726</td>\n      <td>0.018203</td>\n      <td>0.091940</td>\n      <td>0.123959</td>\n      <td>-0.157403</td>\n      <td>-0.020388</td>\n      <td>0.082493</td>\n      <td>0.223057</td>\n      <td>-0.040915</td>\n      <td>-0.130308</td>\n      <td>-0.021816</td>\n      <td>0.034549</td>\n    </tr>\n    <tr>\n      <th>2848</th>\n      <td>-0.113283</td>\n      <td>-0.098942</td>\n      <td>-0.040393</td>\n      <td>0.042180</td>\n      <td>-0.041068</td>\n      <td>-0.039568</td>\n      <td>0.018291</td>\n      <td>-0.191254</td>\n      <td>0.218912</td>\n      <td>0.017262</td>\n      <td>-0.087468</td>\n      <td>0.036894</td>\n      <td>0.067105</td>\n      <td>-0.016780</td>\n      <td>-0.029503</td>\n    </tr>\n    <tr>\n      <th>4433</th>\n      <td>-0.298760</td>\n      <td>-0.290228</td>\n      <td>-0.160120</td>\n      <td>0.156277</td>\n      <td>-0.055364</td>\n      <td>-0.434205</td>\n      <td>-0.089259</td>\n      <td>0.252211</td>\n      <td>-0.107413</td>\n      <td>-0.088591</td>\n      <td>0.121157</td>\n      <td>0.071371</td>\n      <td>-0.415598</td>\n      <td>-0.022139</td>\n      <td>-0.183021</td>\n    </tr>\n    <tr>\n      <th>3519</th>\n      <td>-0.068454</td>\n      <td>0.020090</td>\n      <td>0.039336</td>\n      <td>0.002958</td>\n      <td>-0.018140</td>\n      <td>0.006501</td>\n      <td>-0.108526</td>\n      <td>0.025045</td>\n      <td>0.056334</td>\n      <td>-0.031291</td>\n      <td>-0.035533</td>\n      <td>0.005171</td>\n      <td>0.005546</td>\n      <td>0.020780</td>\n      <td>-0.023623</td>\n    </tr>\n    <tr>\n      <th>5338</th>\n      <td>-0.061259</td>\n      <td>0.014661</td>\n      <td>0.011412</td>\n      <td>0.001727</td>\n      <td>0.064996</td>\n      <td>-0.078448</td>\n      <td>0.059510</td>\n      <td>0.017402</td>\n      <td>-0.040234</td>\n      <td>-0.073409</td>\n      <td>-0.016323</td>\n      <td>0.031774</td>\n      <td>-0.062413</td>\n      <td>0.107708</td>\n      <td>0.065081</td>\n    </tr>\n    <tr>\n      <th>3947</th>\n      <td>-0.022340</td>\n      <td>-0.115285</td>\n      <td>-0.136980</td>\n      <td>0.038593</td>\n      <td>-0.003029</td>\n      <td>0.071770</td>\n      <td>-0.146675</td>\n      <td>-0.285724</td>\n      <td>-0.044472</td>\n      <td>-0.054032</td>\n      <td>0.064019</td>\n      <td>-0.045329</td>\n      <td>-0.111919</td>\n      <td>0.066313</td>\n      <td>0.002395</td>\n    </tr>\n    <tr>\n      <th>4373</th>\n      <td>-0.136550</td>\n      <td>-0.089406</td>\n      <td>-0.235399</td>\n      <td>0.120585</td>\n      <td>-0.168168</td>\n      <td>0.129990</td>\n      <td>-0.035084</td>\n      <td>-0.324028</td>\n      <td>0.087531</td>\n      <td>0.045290</td>\n      <td>0.207850</td>\n      <td>-0.028972</td>\n      <td>-0.175184</td>\n      <td>-0.058283</td>\n      <td>0.147797</td>\n    </tr>\n    <tr>\n      <th>2092</th>\n      <td>-0.121763</td>\n      <td>0.011065</td>\n      <td>-0.037121</td>\n      <td>0.032568</td>\n      <td>0.017570</td>\n      <td>0.095802</td>\n      <td>0.120238</td>\n      <td>-0.048410</td>\n      <td>0.008829</td>\n      <td>0.121778</td>\n      <td>0.093783</td>\n      <td>0.044754</td>\n      <td>-0.003087</td>\n      <td>0.164487</td>\n      <td>-0.075231</td>\n    </tr>\n    <tr>\n      <th>525</th>\n      <td>-0.040290</td>\n      <td>0.014383</td>\n      <td>-0.098967</td>\n      <td>-0.018957</td>\n      <td>0.012388</td>\n      <td>0.035546</td>\n      <td>0.000903</td>\n      <td>0.012835</td>\n      <td>-0.021080</td>\n      <td>0.018742</td>\n      <td>-0.050483</td>\n      <td>-0.025394</td>\n      <td>0.034079</td>\n      <td>0.038330</td>\n      <td>-0.001341</td>\n    </tr>\n    <tr>\n      <th>4327</th>\n      <td>0.008227</td>\n      <td>0.073899</td>\n      <td>-0.323967</td>\n      <td>0.131203</td>\n      <td>-0.320862</td>\n      <td>0.054997</td>\n      <td>0.060751</td>\n      <td>0.162314</td>\n      <td>0.044612</td>\n      <td>-0.232241</td>\n      <td>0.094986</td>\n      <td>-0.106570</td>\n      <td>-0.051692</td>\n      <td>-0.093490</td>\n      <td>0.029534</td>\n    </tr>\n    <tr>\n      <th>3048</th>\n      <td>-0.320315</td>\n      <td>0.078290</td>\n      <td>-0.083182</td>\n      <td>-0.221577</td>\n      <td>-0.078184</td>\n      <td>-0.145306</td>\n      <td>-0.020166</td>\n      <td>0.124409</td>\n      <td>-0.063425</td>\n      <td>0.004726</td>\n      <td>0.009683</td>\n      <td>0.028016</td>\n      <td>-0.018100</td>\n      <td>-0.128452</td>\n      <td>0.069972</td>\n    </tr>\n    <tr>\n      <th>2665</th>\n      <td>-0.076167</td>\n      <td>-0.006064</td>\n      <td>-0.001902</td>\n      <td>-0.053641</td>\n      <td>0.021751</td>\n      <td>0.048207</td>\n      <td>-0.083980</td>\n      <td>0.146907</td>\n      <td>-0.057422</td>\n      <td>0.006085</td>\n      <td>0.063240</td>\n      <td>0.086562</td>\n      <td>-0.132328</td>\n      <td>0.146198</td>\n      <td>0.029200</td>\n    </tr>\n    <tr>\n      <th>4940</th>\n      <td>-0.113099</td>\n      <td>0.047643</td>\n      <td>-0.053024</td>\n      <td>0.024834</td>\n      <td>0.010643</td>\n      <td>-0.012051</td>\n      <td>-0.049150</td>\n      <td>0.006252</td>\n      <td>0.020429</td>\n      <td>0.004349</td>\n      <td>0.028372</td>\n      <td>0.010227</td>\n      <td>-0.008233</td>\n      <td>-0.029304</td>\n      <td>0.090511</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_user_preferences\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "data": {
      "text/plain": "Factor1    -0.042344\nFactor2    -0.040755\nFactor3    -0.055720\nFactor4    -0.073726\nFactor5     0.018203\nFactor6     0.091940\nFactor7     0.123959\nFactor8    -0.157403\nFactor9    -0.020388\nFactor10    0.082493\nFactor11    0.223057\nFactor12   -0.040915\nFactor13   -0.130308\nFactor14   -0.021816\nFactor15    0.034549\nName: 3806, dtype: float64"
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "latent_item_features.loc[11]\n",
    "\n",
    "latent_user_preferences.loc[3806]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.07799268400487341"
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_rating(user_id, item_id):\n",
    "    \"\"\" Predict a rating given a user_id and an item_id.\n",
    "    \"\"\"\n",
    "    user_preference = latent_user_preferences.loc[user_id]\n",
    "    item_preference = latent_item_features.loc[item_id]\n",
    "    return user_preference.dot(item_preference)\n",
    "\n",
    "predict_rating(4768,786)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [
    {
     "data": {
      "text/plain": "0.08617567851569355"
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rating(4768,14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [],
   "source": [
    "def get_ratings(\n",
    "        user_id,\n",
    "        show_top: Optional[int] = None,\n",
    "        descending: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Attempts to work out what ratings a user would give a movie\n",
    "    :param user_id: the user\n",
    "    :param show_top: give this value to only show the top [whatever] movies\n",
    "    :param descending: sort in descending order (top rated first)\n",
    "    \"\"\"\n",
    "\n",
    "    predict_ratings = dict(\n",
    "        (i, predict_rating(user_id, i))\n",
    "        for i in latent_item_features.T.columns.values\n",
    "    )\n",
    "\n",
    "    sorted_ratings = sorted(\n",
    "        [*predict_ratings.items()],\n",
    "        key=lambda kv: kv[1],\n",
    "        reverse=descending\n",
    "    )\n",
    "\n",
    "    if show_top is None:\n",
    "        show_top = len(sorted_ratings)\n",
    "\n",
    "    for kv in sorted_ratings[:show_top]:\n",
    "        print(f\"{kv[0]}: {movies_df.loc[movies_df['Movie ID'] == kv[0], ['Title'][0]].values}\")\n",
    "        print(f\"\\t{kv[1]}\")\n",
    "\n",
    "    return sorted_ratings\n",
    "\n",
    "    #for i in latent_item_features.T.columns.values:\n",
    "    #    print(f\"{i}: {movies_df.loc[movies_df['Movie ID'] == i, ['Title']]}\")\n",
    "    #    print(f\"\\t{predict_rating(user_id, i)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597: ['Titanic (1997)']\n",
      "\t1.0404564360144615\n",
      "238: ['The Godfather (1972)']\n",
      "\t0.674625860954049\n",
      "278: ['The Shawshank Redemption (1994)']\n",
      "\t0.6486912913595948\n",
      "155: ['The Dark Knight (2008)']\n",
      "\t0.6033013587670666\n",
      "424: [\"Schindler's List (1993)\"]\n",
      "\t0.5218542511897091\n",
      "13: ['Forrest Gump (1994)']\n",
      "\t0.4832062579101699\n",
      "603: ['The Matrix (1999)']\n",
      "\t0.4780317054931237\n",
      "274: ['The Silence of the Lambs (1991)']\n",
      "\t0.4545784969134926\n",
      "272: ['Batman Begins (2005)']\n",
      "\t0.44718028305733837\n",
      "680: ['Pulp Fiction (1994)']\n",
      "\t0.42149755921629606\n",
      "557: ['Spider-Man (2002)']\n",
      "\t0.4189097741243446\n",
      "857: ['Saving Private Ryan (1998)']\n",
      "\t0.4010316072745454\n",
      "453: ['A Beautiful Mind (2001)']\n",
      "\t0.39291053678619675\n",
      "558: ['Spider-Man 2 (2004)']\n",
      "\t0.3704292728612526\n",
      "280: ['Terminator 2: Judgment Day (1991)']\n",
      "\t0.3438621395970047\n",
      "329: ['Jurassic Park (1993)']\n",
      "\t0.33784818715566267\n",
      "11: ['Star Wars: Episode IV - A New Hope (1977)']\n",
      "\t0.32232658528473557\n",
      "1891: ['Star Wars: Episode V - The Empire Strikes Back (1980)']\n",
      "\t0.31577146202964645\n",
      "98: ['Gladiator (2000)']\n",
      "\t0.308050661518798\n",
      "24: ['Kill Bill: Vol. 1 (2003)']\n",
      "\t0.3064118094316456\n",
      "601: ['E.T. the Extra-Terrestrial (1982)']\n",
      "\t0.2673617271417039\n",
      "77: ['Memento (2000)']\n",
      "\t0.2659339612108913\n",
      "745: ['The Sixth Sense (1999)']\n",
      "\t0.2478040783957579\n",
      "550: ['Fight Club (1999)']\n",
      "\t0.22037374037284851\n",
      "1892: ['Star Wars: Episode VI - Return of the Jedi (1983)']\n",
      "\t0.21194991368985946\n",
      "14: ['American Beauty (1999)']\n",
      "\t0.20851476068962088\n",
      "1422: ['The Departed (2006)']\n",
      "\t0.20835793275512582\n",
      "629: ['The Usual Suspects (1995)']\n",
      "\t0.20412452160652758\n",
      "393: ['Kill Bill: Vol. 2 (2004)']\n",
      "\t0.19738455304068764\n",
      "197: ['Braveheart (1995)']\n",
      "\t0.19080642729889935\n",
      "38: ['Eternal Sunshine of the Spotless Mind (2004)']\n",
      "\t0.18381530490830245\n",
      "194: ['Amelie (2001)']\n",
      "\t0.15210270939218234\n",
      "807: ['Seven (a.k.a. Se7en) (1995)']\n",
      "\t0.13346157467172545\n",
      "275: ['Fargo (1996)']\n",
      "\t0.11773099754824232\n",
      "105: ['Back to the Future (1985)']\n",
      "\t0.10840220758561081\n",
      "268: ['Batman (1989)']\n",
      "\t0.08589961385575846\n",
      "8587: ['The Lion King (1994)']\n",
      "\t0.05693614019937252\n",
      "85: ['Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)']\n",
      "\t0.05538637716169989\n",
      "36657: ['X-Men (2000)']\n",
      "\t0.052154660182154616\n",
      "604: ['The Matrix Reloaded (2003)']\n",
      "\t0.04816682059701288\n",
      "8358: ['Cast Away (2000)']\n",
      "\t0.04758736591091624\n",
      "602: ['Independence Day (a.k.a. ID4) (1996)']\n",
      "\t0.03285488437358297\n",
      "640: ['Catch Me If You Can (2002)']\n",
      "\t0.030560458471228888\n",
      "146: ['Crouching Tiger Hidden Dragon (Wo hu cang long) (2000)']\n",
      "\t0.030471408379602223\n",
      "641: ['Requiem for a Dream (2000)']\n",
      "\t0.022388224219744315\n",
      "36658: ['X2: X-Men United (2003)']\n",
      "\t0.017755647590510265\n",
      "568: ['Apollo 13 (1995)']\n",
      "\t0.01591024243115477\n",
      "63: ['Twelve Monkeys (a.k.a. 12 Monkeys) (1995)']\n",
      "\t0.01227442985300118\n",
      "671: [\"Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\"]\n",
      "\t0.00043628570281478707\n",
      "153: ['Lost in Translation (2003)']\n",
      "\t-0.0034249171133680922\n",
      "581: ['Dances with Wolves (1990)']\n",
      "\t-0.007157083451603319\n",
      "114: ['Pretty Woman (1990)']\n",
      "\t-0.00844724260060116\n",
      "180: ['Minority Report (2002)']\n",
      "\t-0.012225986922145101\n",
      "752: ['V for Vendetta (2006)']\n",
      "\t-0.018347473826638053\n",
      "954: ['Mission: Impossible (1996)']\n",
      "\t-0.04169102729636829\n",
      "672: ['Harry Potter and the Chamber of Secrets (2002)']\n",
      "\t-0.05214916095532168\n",
      "2501: ['The Bourne Identity (2002)']\n",
      "\t-0.057227088840433815\n",
      "122: ['The Lord of the Rings: The Return of the King (2003)']\n",
      "\t-0.06977895021407193\n",
      "141: ['Donnie Darko (2001)']\n",
      "\t-0.07635625841816551\n",
      "134: ['O Brother Where Art Thou? (2000)']\n",
      "\t-0.08521329300314218\n",
      "1900: ['Traffic (2000)']\n",
      "\t-0.08813947847072715\n",
      "120: ['The Lord of the Rings: The Fellowship of the Ring (2001)']\n",
      "\t-0.10199076838317384\n",
      "2502: ['The Bourne Supremacy (2004)']\n",
      "\t-0.10395809794529996\n",
      "5503: ['The Fugitive (1993)']\n",
      "\t-0.11266596669316312\n",
      "121: ['The Lord of the Rings: The Two Towers (2002)']\n",
      "\t-0.11617743146089186\n",
      "1894: ['Star Wars: Episode II - Attack of the Clones (2002)']\n",
      "\t-0.12994077112647245\n",
      "12: ['Finding Nemo (2003)']\n",
      "\t-0.13335297737721924\n",
      "862: ['Toy Story (1995)']\n",
      "\t-0.14282773264810117\n",
      "955: ['Mission: Impossible II (2000)']\n",
      "\t-0.1471408743180213\n",
      "107: ['Snatch (2000)']\n",
      "\t-0.1489540471694201\n",
      "161: [\"Ocean's Eleven (2001)\"]\n",
      "\t-0.1638412334820083\n",
      "462: ['Erin Brockovich (2000)']\n",
      "\t-0.18189279106383552\n",
      "786: ['Almost Famous (2000)']\n",
      "\t-0.1903449420351469\n",
      "2024: ['The Patriot (2000)']\n",
      "\t-0.1979127513679796\n",
      "243: ['High Fidelity (2000)']\n",
      "\t-0.20905089448408193\n",
      "1572: ['Die Hard: With a Vengeance (1995)']\n",
      "\t-0.2130514630568657\n",
      "10020: ['Beauty and the Beast (1991)']\n",
      "\t-0.22536125923094064\n",
      "1637: ['Speed (1994)']\n",
      "\t-0.2261505762149501\n",
      "9806: ['The Incredibles (2004)']\n",
      "\t-0.22657539750797248\n",
      "9331: ['Clear and Present Danger (1994)']\n",
      "\t-0.22817113151424706\n",
      "2164: ['Stargate (1994)']\n",
      "\t-0.24456911830982103\n",
      "22: ['Pirates of the Caribbean: The Curse of the Black Pearl (2003)']\n",
      "\t-0.2702705358213843\n",
      "9741: ['Unbreakable (2000)']\n",
      "\t-0.2729122632422629\n",
      "187: ['Sin City (2005)']\n",
      "\t-0.27400181029132264\n",
      "812: ['Aladdin (1992)']\n",
      "\t-0.27936342755272686\n",
      "414: ['Batman Forever (1995)']\n",
      "\t-0.3240483607912214\n",
      "9802: ['The Rock (1996)']\n",
      "\t-0.33710910833259833\n",
      "607: ['Men in Black (a.k.a. MIB) (1997)']\n",
      "\t-0.3464185652334957\n",
      "36955: ['True Lies (1994)']\n",
      "\t-0.34970452846464484\n",
      "664: ['Twister (1996)']\n",
      "\t-0.3721635287716946\n",
      "585: ['Monsters Inc. (2001)']\n",
      "\t-0.3729480058918645\n",
      "7443: ['Chicken Run (2000)']\n",
      "\t-0.48317397120029537\n",
      "788: ['Mrs. Doubtfire (1993)']\n",
      "\t-0.49257674940245977\n",
      "1597: ['Meet the Parents (2000)']\n",
      "\t-0.5422576153898802\n",
      "854: ['The Mask (1994)']\n",
      "\t-0.5850291447035443\n",
      "3049: ['Ace Ventura: Pet Detective (1994)']\n",
      "\t-0.6016831940558961\n",
      "4327: [\"Charlie's Angels (2000)\"]\n",
      "\t-0.6463070614322054\n",
      "808: ['Shrek (2001)']\n",
      "\t-0.679360180234334\n",
      "8467: ['Dumb & Dumber (1994)']\n",
      "\t-0.7336908359191853\n",
      "809: ['Shrek 2 (2004)']\n",
      "\t-0.7530376796150027\n"
     ]
    },
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ratings(4529)\n",
    "\n",
    "\n",
    "\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597: ['Titanic (1997)']\n",
      "\t1.0404564360144615\n",
      "238: ['The Godfather (1972)']\n",
      "\t0.674625860954049\n",
      "278: ['The Shawshank Redemption (1994)']\n",
      "\t0.6486912913595948\n",
      "155: ['The Dark Knight (2008)']\n",
      "\t0.6033013587670666\n",
      "424: [\"Schindler's List (1993)\"]\n",
      "\t0.5218542511897091\n",
      "13: ['Forrest Gump (1994)']\n",
      "\t0.4832062579101699\n",
      "603: ['The Matrix (1999)']\n",
      "\t0.4780317054931237\n",
      "274: ['The Silence of the Lambs (1991)']\n",
      "\t0.4545784969134926\n",
      "272: ['Batman Begins (2005)']\n",
      "\t0.44718028305733837\n",
      "680: ['Pulp Fiction (1994)']\n",
      "\t0.42149755921629606\n",
      "557: ['Spider-Man (2002)']\n",
      "\t0.4189097741243446\n",
      "857: ['Saving Private Ryan (1998)']\n",
      "\t0.4010316072745454\n",
      "453: ['A Beautiful Mind (2001)']\n",
      "\t0.39291053678619675\n",
      "558: ['Spider-Man 2 (2004)']\n",
      "\t0.3704292728612526\n",
      "280: ['Terminator 2: Judgment Day (1991)']\n",
      "\t0.3438621395970047\n",
      "329: ['Jurassic Park (1993)']\n",
      "\t0.33784818715566267\n",
      "11: ['Star Wars: Episode IV - A New Hope (1977)']\n",
      "\t0.32232658528473557\n",
      "1891: ['Star Wars: Episode V - The Empire Strikes Back (1980)']\n",
      "\t0.31577146202964645\n",
      "98: ['Gladiator (2000)']\n",
      "\t0.308050661518798\n",
      "24: ['Kill Bill: Vol. 1 (2003)']\n",
      "\t0.3064118094316456\n",
      "601: ['E.T. the Extra-Terrestrial (1982)']\n",
      "\t0.2673617271417039\n",
      "77: ['Memento (2000)']\n",
      "\t0.2659339612108913\n",
      "745: ['The Sixth Sense (1999)']\n",
      "\t0.2478040783957579\n",
      "550: ['Fight Club (1999)']\n",
      "\t0.22037374037284851\n",
      "1892: ['Star Wars: Episode VI - Return of the Jedi (1983)']\n",
      "\t0.21194991368985946\n",
      "14: ['American Beauty (1999)']\n",
      "\t0.20851476068962088\n",
      "1422: ['The Departed (2006)']\n",
      "\t0.20835793275512582\n",
      "629: ['The Usual Suspects (1995)']\n",
      "\t0.20412452160652758\n",
      "393: ['Kill Bill: Vol. 2 (2004)']\n",
      "\t0.19738455304068764\n",
      "197: ['Braveheart (1995)']\n",
      "\t0.19080642729889935\n",
      "38: ['Eternal Sunshine of the Spotless Mind (2004)']\n",
      "\t0.18381530490830245\n",
      "194: ['Amelie (2001)']\n",
      "\t0.15210270939218234\n",
      "807: ['Seven (a.k.a. Se7en) (1995)']\n",
      "\t0.13346157467172545\n",
      "275: ['Fargo (1996)']\n",
      "\t0.11773099754824232\n",
      "105: ['Back to the Future (1985)']\n",
      "\t0.10840220758561081\n",
      "268: ['Batman (1989)']\n",
      "\t0.08589961385575846\n",
      "8587: ['The Lion King (1994)']\n",
      "\t0.05693614019937252\n",
      "85: ['Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)']\n",
      "\t0.05538637716169989\n",
      "36657: ['X-Men (2000)']\n",
      "\t0.052154660182154616\n",
      "604: ['The Matrix Reloaded (2003)']\n",
      "\t0.04816682059701288\n",
      "8358: ['Cast Away (2000)']\n",
      "\t0.04758736591091624\n",
      "602: ['Independence Day (a.k.a. ID4) (1996)']\n",
      "\t0.03285488437358297\n",
      "640: ['Catch Me If You Can (2002)']\n",
      "\t0.030560458471228888\n",
      "146: ['Crouching Tiger Hidden Dragon (Wo hu cang long) (2000)']\n",
      "\t0.030471408379602223\n",
      "641: ['Requiem for a Dream (2000)']\n",
      "\t0.022388224219744315\n",
      "36658: ['X2: X-Men United (2003)']\n",
      "\t0.017755647590510265\n",
      "568: ['Apollo 13 (1995)']\n",
      "\t0.01591024243115477\n",
      "63: ['Twelve Monkeys (a.k.a. 12 Monkeys) (1995)']\n",
      "\t0.01227442985300118\n",
      "671: [\"Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\"]\n",
      "\t0.00043628570281478707\n",
      "153: ['Lost in Translation (2003)']\n",
      "\t-0.0034249171133680922\n",
      "581: ['Dances with Wolves (1990)']\n",
      "\t-0.007157083451603319\n",
      "114: ['Pretty Woman (1990)']\n",
      "\t-0.00844724260060116\n",
      "180: ['Minority Report (2002)']\n",
      "\t-0.012225986922145101\n",
      "752: ['V for Vendetta (2006)']\n",
      "\t-0.018347473826638053\n",
      "954: ['Mission: Impossible (1996)']\n",
      "\t-0.04169102729636829\n",
      "672: ['Harry Potter and the Chamber of Secrets (2002)']\n",
      "\t-0.05214916095532168\n",
      "2501: ['The Bourne Identity (2002)']\n",
      "\t-0.057227088840433815\n",
      "122: ['The Lord of the Rings: The Return of the King (2003)']\n",
      "\t-0.06977895021407193\n",
      "141: ['Donnie Darko (2001)']\n",
      "\t-0.07635625841816551\n",
      "134: ['O Brother Where Art Thou? (2000)']\n",
      "\t-0.08521329300314218\n",
      "1900: ['Traffic (2000)']\n",
      "\t-0.08813947847072715\n",
      "120: ['The Lord of the Rings: The Fellowship of the Ring (2001)']\n",
      "\t-0.10199076838317384\n",
      "2502: ['The Bourne Supremacy (2004)']\n",
      "\t-0.10395809794529996\n",
      "5503: ['The Fugitive (1993)']\n",
      "\t-0.11266596669316312\n",
      "121: ['The Lord of the Rings: The Two Towers (2002)']\n",
      "\t-0.11617743146089186\n",
      "1894: ['Star Wars: Episode II - Attack of the Clones (2002)']\n",
      "\t-0.12994077112647245\n",
      "12: ['Finding Nemo (2003)']\n",
      "\t-0.13335297737721924\n",
      "862: ['Toy Story (1995)']\n",
      "\t-0.14282773264810117\n",
      "955: ['Mission: Impossible II (2000)']\n",
      "\t-0.1471408743180213\n",
      "107: ['Snatch (2000)']\n",
      "\t-0.1489540471694201\n",
      "161: [\"Ocean's Eleven (2001)\"]\n",
      "\t-0.1638412334820083\n",
      "462: ['Erin Brockovich (2000)']\n",
      "\t-0.18189279106383552\n",
      "786: ['Almost Famous (2000)']\n",
      "\t-0.1903449420351469\n",
      "2024: ['The Patriot (2000)']\n",
      "\t-0.1979127513679796\n",
      "243: ['High Fidelity (2000)']\n",
      "\t-0.20905089448408193\n",
      "1572: ['Die Hard: With a Vengeance (1995)']\n",
      "\t-0.2130514630568657\n",
      "10020: ['Beauty and the Beast (1991)']\n",
      "\t-0.22536125923094064\n",
      "1637: ['Speed (1994)']\n",
      "\t-0.2261505762149501\n",
      "9806: ['The Incredibles (2004)']\n",
      "\t-0.22657539750797248\n",
      "9331: ['Clear and Present Danger (1994)']\n",
      "\t-0.22817113151424706\n",
      "2164: ['Stargate (1994)']\n",
      "\t-0.24456911830982103\n",
      "22: ['Pirates of the Caribbean: The Curse of the Black Pearl (2003)']\n",
      "\t-0.2702705358213843\n",
      "9741: ['Unbreakable (2000)']\n",
      "\t-0.2729122632422629\n",
      "187: ['Sin City (2005)']\n",
      "\t-0.27400181029132264\n",
      "812: ['Aladdin (1992)']\n",
      "\t-0.27936342755272686\n",
      "414: ['Batman Forever (1995)']\n",
      "\t-0.3240483607912214\n",
      "9802: ['The Rock (1996)']\n",
      "\t-0.33710910833259833\n",
      "607: ['Men in Black (a.k.a. MIB) (1997)']\n",
      "\t-0.3464185652334957\n",
      "36955: ['True Lies (1994)']\n",
      "\t-0.34970452846464484\n",
      "664: ['Twister (1996)']\n",
      "\t-0.3721635287716946\n",
      "585: ['Monsters Inc. (2001)']\n",
      "\t-0.3729480058918645\n",
      "7443: ['Chicken Run (2000)']\n",
      "\t-0.48317397120029537\n",
      "788: ['Mrs. Doubtfire (1993)']\n",
      "\t-0.49257674940245977\n",
      "1597: ['Meet the Parents (2000)']\n",
      "\t-0.5422576153898802\n",
      "854: ['The Mask (1994)']\n",
      "\t-0.5850291447035443\n",
      "3049: ['Ace Ventura: Pet Detective (1994)']\n",
      "\t-0.6016831940558961\n",
      "4327: [\"Charlie's Angels (2000)\"]\n",
      "\t-0.6463070614322054\n",
      "808: ['Shrek (2001)']\n",
      "\t-0.679360180234334\n",
      "8467: ['Dumb & Dumber (1994)']\n",
      "\t-0.7336908359191853\n",
      "809: ['Shrek 2 (2004)']\n",
      "\t-0.7530376796150027\n",
      "['Titanic (1997)']\n",
      "['The Dark Knight (2008)']\n",
      "['Amelie (2001)']\n",
      "['Independence Day (a.k.a. ID4) (1996)']\n",
      "['Traffic (2000)']\n",
      "['The Bourne Supremacy (2004)']\n",
      "['Finding Nemo (2003)']\n"
     ]
    }
   ],
   "source": [
    "titles_5429 = [\n",
    "    k for k, v in get_ratings(4529)\n",
    "    if movies_df.loc[movies_df['Movie ID'] == k, ['Title'][0]].values[0] in [\n",
    "        \"Finding Nemo (2003)\",\n",
    "        \"Titanic (1997)\",\n",
    "        \"Traffic (2000)\",\n",
    "        \"The Bourne Supremacy (2004)\",\n",
    "        \"Independence Day (a.k.a. ID4) (1996)\",\n",
    "        \"Amelie (2001)\",\n",
    "        \"The Dark Knight (2008)\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "for t in titles_5429:\n",
    "    print(movies_df.loc[movies_df['Movie ID'] == t, ['Title'][0]].values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603: ['The Matrix (1999)']\n",
      "\t1.0968619041820322\n",
      "604: ['The Matrix Reloaded (2003)']\n",
      "\t0.9723078744163969\n",
      "550: ['Fight Club (1999)']\n",
      "\t0.7485962942696884\n",
      "77: ['Memento (2000)']\n",
      "\t0.5595789697982286\n",
      "752: ['V for Vendetta (2006)']\n",
      "\t0.5380181093411116\n",
      "453: ['A Beautiful Mind (2001)']\n",
      "\t0.5190045658417152\n",
      "14: ['American Beauty (1999)']\n",
      "\t0.48695683674275264\n",
      "38: ['Eternal Sunshine of the Spotless Mind (2004)']\n",
      "\t0.47941200994272004\n",
      "11: ['Star Wars: Episode IV - A New Hope (1977)']\n",
      "\t0.4376003692163438\n",
      "1891: ['Star Wars: Episode V - The Empire Strikes Back (1980)']\n",
      "\t0.4333784457885115\n",
      "1892: ['Star Wars: Episode VI - Return of the Jedi (1983)']\n",
      "\t0.43235455739042533\n",
      "641: ['Requiem for a Dream (2000)']\n",
      "\t0.4308545633814643\n",
      "155: ['The Dark Knight (2008)']\n",
      "\t0.41131169022089153\n",
      "194: ['Amelie (2001)']\n",
      "\t0.3942138535665135\n",
      "680: ['Pulp Fiction (1994)']\n",
      "\t0.3630360306104313\n",
      "153: ['Lost in Translation (2003)']\n",
      "\t0.3564673830870303\n",
      "597: ['Titanic (1997)']\n",
      "\t0.32264086403256864\n",
      "63: ['Twelve Monkeys (a.k.a. 12 Monkeys) (1995)']\n",
      "\t0.30193940609349035\n",
      "1894: ['Star Wars: Episode II - Attack of the Clones (2002)']\n",
      "\t0.26749187300133814\n",
      "13: ['Forrest Gump (1994)']\n",
      "\t0.25892965283398317\n",
      "807: ['Seven (a.k.a. Se7en) (1995)']\n",
      "\t0.2548785680433772\n",
      "180: ['Minority Report (2002)']\n",
      "\t0.2542570021276855\n",
      "141: ['Donnie Darko (2001)']\n",
      "\t0.24748812920636049\n",
      "238: ['The Godfather (1972)']\n",
      "\t0.2371665793366614\n",
      "278: ['The Shawshank Redemption (1994)']\n",
      "\t0.2363802790907233\n",
      "629: ['The Usual Suspects (1995)']\n",
      "\t0.23454083044421709\n",
      "424: [\"Schindler's List (1993)\"]\n",
      "\t0.23338292402816185\n",
      "274: ['The Silence of the Lambs (1991)']\n",
      "\t0.22357259987016076\n",
      "187: ['Sin City (2005)']\n",
      "\t0.20992897792052204\n",
      "161: [\"Ocean's Eleven (2001)\"]\n",
      "\t0.20565648133736303\n",
      "107: ['Snatch (2000)']\n",
      "\t0.19247967890646794\n",
      "12: ['Finding Nemo (2003)']\n",
      "\t0.18082998241873255\n",
      "640: ['Catch Me If You Can (2002)']\n",
      "\t0.17850611317477366\n",
      "98: ['Gladiator (2000)']\n",
      "\t0.16710062175546334\n",
      "122: ['The Lord of the Rings: The Return of the King (2003)']\n",
      "\t0.15604999164563754\n",
      "329: ['Jurassic Park (1993)']\n",
      "\t0.15438601478739108\n",
      "745: ['The Sixth Sense (1999)']\n",
      "\t0.15113420930891747\n",
      "1422: ['The Departed (2006)']\n",
      "\t0.1483642054513929\n",
      "585: ['Monsters Inc. (2001)']\n",
      "\t0.1370355086846618\n",
      "8587: ['The Lion King (1994)']\n",
      "\t0.13433810745124647\n",
      "120: ['The Lord of the Rings: The Fellowship of the Ring (2001)']\n",
      "\t0.13423708546430652\n",
      "602: ['Independence Day (a.k.a. ID4) (1996)']\n",
      "\t0.12239962291417007\n",
      "272: ['Batman Begins (2005)']\n",
      "\t0.11853587103301727\n",
      "275: ['Fargo (1996)']\n",
      "\t0.11632857643746823\n",
      "105: ['Back to the Future (1985)']\n",
      "\t0.11381678324155349\n",
      "121: ['The Lord of the Rings: The Two Towers (2002)']\n",
      "\t0.10735220550360774\n",
      "146: ['Crouching Tiger Hidden Dragon (Wo hu cang long) (2000)']\n",
      "\t0.10403462525023044\n",
      "862: ['Toy Story (1995)']\n",
      "\t0.06227503841503139\n",
      "243: ['High Fidelity (2000)']\n",
      "\t0.03224197804877559\n",
      "134: ['O Brother Where Art Thou? (2000)']\n",
      "\t0.02646787420487253\n",
      "2164: ['Stargate (1994)']\n",
      "\t0.026087421170325198\n",
      "857: ['Saving Private Ryan (1998)']\n",
      "\t0.023228596946529678\n",
      "568: ['Apollo 13 (1995)']\n",
      "\t0.008920430554136029\n",
      "1900: ['Traffic (2000)']\n",
      "\t0.008040819821630261\n",
      "601: ['E.T. the Extra-Terrestrial (1982)']\n",
      "\t-0.002338320728143089\n",
      "2501: ['The Bourne Identity (2002)']\n",
      "\t-0.018819927876622067\n",
      "280: ['Terminator 2: Judgment Day (1991)']\n",
      "\t-0.04027499415699071\n",
      "8358: ['Cast Away (2000)']\n",
      "\t-0.04210566951739514\n",
      "22: ['Pirates of the Caribbean: The Curse of the Black Pearl (2003)']\n",
      "\t-0.04328791594078771\n",
      "9741: ['Unbreakable (2000)']\n",
      "\t-0.04543321246941497\n",
      "2502: ['The Bourne Supremacy (2004)']\n",
      "\t-0.0518978500544614\n",
      "581: ['Dances with Wolves (1990)']\n",
      "\t-0.05805080487452277\n",
      "24: ['Kill Bill: Vol. 1 (2003)']\n",
      "\t-0.06253254140090006\n",
      "85: ['Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)']\n",
      "\t-0.06537249479022057\n",
      "462: ['Erin Brockovich (2000)']\n",
      "\t-0.07650877935305109\n",
      "607: ['Men in Black (a.k.a. MIB) (1997)']\n",
      "\t-0.07889530096484765\n",
      "786: ['Almost Famous (2000)']\n",
      "\t-0.08685791027022524\n",
      "114: ['Pretty Woman (1990)']\n",
      "\t-0.09719466568591176\n",
      "393: ['Kill Bill: Vol. 2 (2004)']\n",
      "\t-0.145060485000712\n",
      "9806: ['The Incredibles (2004)']\n",
      "\t-0.14801051525216607\n",
      "812: ['Aladdin (1992)']\n",
      "\t-0.1524661858419853\n",
      "954: ['Mission: Impossible (1996)']\n",
      "\t-0.17757739847933485\n",
      "197: ['Braveheart (1995)']\n",
      "\t-0.18059830551307585\n",
      "5503: ['The Fugitive (1993)']\n",
      "\t-0.20188294403498497\n",
      "10020: ['Beauty and the Beast (1991)']\n",
      "\t-0.21868583862470053\n",
      "664: ['Twister (1996)']\n",
      "\t-0.2187945304166271\n",
      "808: ['Shrek (2001)']\n",
      "\t-0.2404086707633229\n",
      "9331: ['Clear and Present Danger (1994)']\n",
      "\t-0.2534549016701415\n",
      "7443: ['Chicken Run (2000)']\n",
      "\t-0.25705748497727005\n",
      "2024: ['The Patriot (2000)']\n",
      "\t-0.2933248125329121\n",
      "1637: ['Speed (1994)']\n",
      "\t-0.3698235539021508\n",
      "955: ['Mission: Impossible II (2000)']\n",
      "\t-0.3844311496922525\n",
      "36955: ['True Lies (1994)']\n",
      "\t-0.3929094548461224\n",
      "788: ['Mrs. Doubtfire (1993)']\n",
      "\t-0.3930074344617936\n",
      "9802: ['The Rock (1996)']\n",
      "\t-0.39487894020654796\n",
      "1572: ['Die Hard: With a Vengeance (1995)']\n",
      "\t-0.4026898464665906\n",
      "1597: ['Meet the Parents (2000)']\n",
      "\t-0.40810410066286196\n",
      "36657: ['X-Men (2000)']\n",
      "\t-0.44792167246409625\n",
      "809: ['Shrek 2 (2004)']\n",
      "\t-0.46674198759444085\n",
      "854: ['The Mask (1994)']\n",
      "\t-0.49380253346135106\n",
      "268: ['Batman (1989)']\n",
      "\t-0.5083878847493668\n",
      "3049: ['Ace Ventura: Pet Detective (1994)']\n",
      "\t-0.5263010460662828\n",
      "36658: ['X2: X-Men United (2003)']\n",
      "\t-0.5312404004330995\n",
      "8467: ['Dumb & Dumber (1994)']\n",
      "\t-0.6030588133120589\n",
      "671: [\"Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\"]\n",
      "\t-0.6058371238130723\n",
      "672: ['Harry Potter and the Chamber of Secrets (2002)']\n",
      "\t-0.643577155312671\n",
      "414: ['Batman Forever (1995)']\n",
      "\t-0.7625217109849597\n",
      "557: ['Spider-Man (2002)']\n",
      "\t-0.9509241857159675\n",
      "4327: [\"Charlie's Angels (2000)\"]\n",
      "\t-0.9574352590838108\n",
      "558: ['Spider-Man 2 (2004)']\n",
      "\t-1.1494587039946285\n",
      "[603, 1891, 63]\n"
     ]
    }
   ],
   "source": [
    "ids_3806 = [\n",
    "    k for k, v in get_ratings(156)\n",
    "    if k in [\n",
    "        68,\n",
    "        63,\n",
    "        1891,\n",
    "        603,\n",
    "        99,\n",
    "        43\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "print(ids_3806)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4768  156 5323  174 4529  783 3878  768 4469 1882 4997 2067 3806 2848\n",
      " 4433 3519 5338 3947 4373 2092  525 4327 3048 2665 4940]\n"
     ]
    }
   ],
   "source": [
    "print(latent_user_preferences.T.columns.values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   11    12    13    14    22    24    38    63    77    85    98   105\n",
      "   107   114   120   121   122   134   141   146   153   155   161   180\n",
      "   187   194   197   238   243   268   272   274   275   278   280   329\n",
      "   393   414   424   453   462   550   557   558   568   581   585   597\n",
      "   601   602   603   604   607   629   640   641   664   671   672   680\n",
      "   745   752   786   788   807   808   809   812   854   857   862   954\n",
      "   955  1422  1572  1597  1637  1891  1892  1894  1900  2024  2164  2501\n",
      "  2502  3049  4327  5503  7443  8358  8467  8587  9331  9741  9802  9806\n",
      " 10020 36657 36658 36955]\n"
     ]
    }
   ],
   "source": [
    "print(latent_item_features.T.columns.values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_ratings: pd.DataFrame = pd.DataFrame(\n",
    "    columns=latent_item_features.T.columns.values,\n",
    ")\n",
    "user_ratings.index.name='User ID'\n",
    "\n",
    "print(latent_user_preferences.T.columns.values)\n",
    "\n",
    "\n",
    "for u in latent_user_preferences.T.columns.values:\n",
    "    user_ratings.loc[u] = pd.Series(\n",
    "        [\n",
    "            #_rng.random()\n",
    "            predict_rating(u, i)\n",
    "            for i in latent_item_features.T.columns.values\n",
    "        ],\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [
    {
     "data": {
      "text/plain": "            11        12        13        14        22        24        38     \\\nUser ID                                                                         \n4768     1.075866  0.490713 -0.514578 -0.370327 -0.088369 -0.171628  0.593612   \n156      0.510767 -0.125068 -0.151969  0.517930  0.189687 -0.260572  0.199863   \n5323     0.045008 -0.059968 -0.036395  0.247560  0.265635 -0.153931  0.271648   \n174     -0.075722 -0.052166 -0.353584  1.858963 -0.063346  0.000219  0.558233   \n4529    -0.211549 -0.511296  0.149259 -0.215623  0.003485 -0.564633 -0.017807   \n783     -0.128225 -0.055324 -0.017890  0.018573  0.161786 -0.105386  0.152208   \n3878     0.928983  0.326437 -0.065310 -1.992433  0.032120 -0.113857  0.345319   \n768     -0.039545 -0.047596  0.099078  0.017030  0.050608 -0.055531  0.014937   \n4469    -0.060360  0.019270  0.010936  0.021893  0.038589 -0.054131  0.158589   \n1882    -0.148604 -0.077960 -0.116153 -0.094700  0.267774 -0.040307 -0.021478   \n4997    -1.007403 -0.618366  0.116358 -1.325000  1.168161 -1.365896  1.361673   \n2067     0.282444  0.167582  0.487497 -1.959577  0.222063  0.001253  0.418074   \n3806     0.401531  0.095293 -0.417779  0.474225  0.101211  0.041517 -0.049956   \n2848     0.170633 -0.025721 -0.227568  0.788244  0.054609 -0.446208  0.098217   \n4433     0.095530 -0.786122 -0.197755  0.877729  0.341580 -1.056308  1.055216   \n3519     0.178407  0.034079  0.016657  0.045533 -0.065205 -0.085974  0.120133   \n5338    -0.327231 -0.035768 -0.129199  0.232442  0.125014 -0.010514  0.112833   \n3947     0.125262 -0.143949 -0.124911  0.007842  0.080374 -0.524426  0.090392   \n4373     1.065579 -0.134338 -0.424483  0.014997 -0.103470 -0.610555  0.210089   \n2092     0.225971  0.253235 -0.143679  0.487785  0.414680  0.039114  0.088530   \n525     -0.055370  0.034809  0.132021 -0.186088  0.138906 -0.028076  0.170086   \n4327     0.804538 -0.365379  0.335829 -2.000204 -0.278712 -0.448454  0.474781   \n3048     0.307641  0.273976 -0.603444 -0.109916  0.236619  0.154224  0.687846   \n2665     0.212213 -0.082370  0.059706 -0.053417  0.223374 -0.106200  0.180821   \n4940     0.212651  0.074959 -0.029705  0.004693 -0.092700 -0.006127  0.291180   \n\n            63        77        85     ...  8467   8587   9331   9741   9802   \\\nUser ID                                ...                                      \n4768     0.149423  0.416629  0.129791  ...    NaN    NaN    NaN    NaN    NaN   \n156     -0.136578  0.910234 -0.637950  ...    NaN    NaN    NaN    NaN    NaN   \n5323    -0.302412  0.186516 -0.199164  ...    NaN    NaN    NaN    NaN    NaN   \n174     -0.097778 -0.091951 -1.233248  ...    NaN    NaN    NaN    NaN    NaN   \n4529    -0.236235  0.060928 -0.399136  ...    NaN    NaN    NaN    NaN    NaN   \n783     -0.043136  0.027045  0.101489  ...    NaN    NaN    NaN    NaN    NaN   \n3878     0.071474  0.562888  0.670933  ...    NaN    NaN    NaN    NaN    NaN   \n768      0.002273  0.012196  0.048750  ...    NaN    NaN    NaN    NaN    NaN   \n4469    -0.018854  0.008534 -0.002490  ...    NaN    NaN    NaN    NaN    NaN   \n1882    -0.506743  0.261646 -0.431739  ...    NaN    NaN    NaN    NaN    NaN   \n4997    -0.448088 -1.332194 -0.930954  ...    NaN    NaN    NaN    NaN    NaN   \n2067     0.072365 -0.257828 -0.796918  ...    NaN    NaN    NaN    NaN    NaN   \n3806     0.040278 -0.451167  0.627290  ...    NaN    NaN    NaN    NaN    NaN   \n2848    -0.135390  0.165383 -0.411212  ...    NaN    NaN    NaN    NaN    NaN   \n4433    -0.878664 -0.283878 -2.451230  ...    NaN    NaN    NaN    NaN    NaN   \n3519    -0.184785  0.503005 -0.533195  ...    NaN    NaN    NaN    NaN    NaN   \n5338    -0.264502 -0.046568  0.065235  ...    NaN    NaN    NaN    NaN    NaN   \n3947     0.033255  0.234648 -0.137978  ...    NaN    NaN    NaN    NaN    NaN   \n4373     0.157245 -0.083689 -0.138122  ...    NaN    NaN    NaN    NaN    NaN   \n2092    -0.058911  0.123355  0.308150  ...    NaN    NaN    NaN    NaN    NaN   \n525      0.017266 -0.031659 -0.042254  ...    NaN    NaN    NaN    NaN    NaN   \n4327     0.107432 -0.546254  0.267519  ...    NaN    NaN    NaN    NaN    NaN   \n3048    -0.819597 -0.105569 -1.346810  ...    NaN    NaN    NaN    NaN    NaN   \n2665    -0.201176  0.516400 -0.295822  ...    NaN    NaN    NaN    NaN    NaN   \n4940    -0.052899  0.023834 -0.476892  ...    NaN    NaN    NaN    NaN    NaN   \n\n         9806   10020  36657  36658  36955  \nUser ID                                     \n4768       NaN    NaN    NaN    NaN    NaN  \n156        NaN    NaN    NaN    NaN    NaN  \n5323       NaN    NaN    NaN    NaN    NaN  \n174        NaN    NaN    NaN    NaN    NaN  \n4529       NaN    NaN    NaN    NaN    NaN  \n783        NaN    NaN    NaN    NaN    NaN  \n3878       NaN    NaN    NaN    NaN    NaN  \n768        NaN    NaN    NaN    NaN    NaN  \n4469       NaN    NaN    NaN    NaN    NaN  \n1882       NaN    NaN    NaN    NaN    NaN  \n4997       NaN    NaN    NaN    NaN    NaN  \n2067       NaN    NaN    NaN    NaN    NaN  \n3806       NaN    NaN    NaN    NaN    NaN  \n2848       NaN    NaN    NaN    NaN    NaN  \n4433       NaN    NaN    NaN    NaN    NaN  \n3519       NaN    NaN    NaN    NaN    NaN  \n5338       NaN    NaN    NaN    NaN    NaN  \n3947       NaN    NaN    NaN    NaN    NaN  \n4373       NaN    NaN    NaN    NaN    NaN  \n2092       NaN    NaN    NaN    NaN    NaN  \n525        NaN    NaN    NaN    NaN    NaN  \n4327       NaN    NaN    NaN    NaN    NaN  \n3048       NaN    NaN    NaN    NaN    NaN  \n2665       NaN    NaN    NaN    NaN    NaN  \n4940       NaN    NaN    NaN    NaN    NaN  \n\n[25 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>22</th>\n      <th>24</th>\n      <th>38</th>\n      <th>63</th>\n      <th>77</th>\n      <th>85</th>\n      <th>...</th>\n      <th>8467</th>\n      <th>8587</th>\n      <th>9331</th>\n      <th>9741</th>\n      <th>9802</th>\n      <th>9806</th>\n      <th>10020</th>\n      <th>36657</th>\n      <th>36658</th>\n      <th>36955</th>\n    </tr>\n    <tr>\n      <th>User ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4768</th>\n      <td>1.075866</td>\n      <td>0.490713</td>\n      <td>-0.514578</td>\n      <td>-0.370327</td>\n      <td>-0.088369</td>\n      <td>-0.171628</td>\n      <td>0.593612</td>\n      <td>0.149423</td>\n      <td>0.416629</td>\n      <td>0.129791</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>0.510767</td>\n      <td>-0.125068</td>\n      <td>-0.151969</td>\n      <td>0.517930</td>\n      <td>0.189687</td>\n      <td>-0.260572</td>\n      <td>0.199863</td>\n      <td>-0.136578</td>\n      <td>0.910234</td>\n      <td>-0.637950</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5323</th>\n      <td>0.045008</td>\n      <td>-0.059968</td>\n      <td>-0.036395</td>\n      <td>0.247560</td>\n      <td>0.265635</td>\n      <td>-0.153931</td>\n      <td>0.271648</td>\n      <td>-0.302412</td>\n      <td>0.186516</td>\n      <td>-0.199164</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>-0.075722</td>\n      <td>-0.052166</td>\n      <td>-0.353584</td>\n      <td>1.858963</td>\n      <td>-0.063346</td>\n      <td>0.000219</td>\n      <td>0.558233</td>\n      <td>-0.097778</td>\n      <td>-0.091951</td>\n      <td>-1.233248</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4529</th>\n      <td>-0.211549</td>\n      <td>-0.511296</td>\n      <td>0.149259</td>\n      <td>-0.215623</td>\n      <td>0.003485</td>\n      <td>-0.564633</td>\n      <td>-0.017807</td>\n      <td>-0.236235</td>\n      <td>0.060928</td>\n      <td>-0.399136</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>783</th>\n      <td>-0.128225</td>\n      <td>-0.055324</td>\n      <td>-0.017890</td>\n      <td>0.018573</td>\n      <td>0.161786</td>\n      <td>-0.105386</td>\n      <td>0.152208</td>\n      <td>-0.043136</td>\n      <td>0.027045</td>\n      <td>0.101489</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3878</th>\n      <td>0.928983</td>\n      <td>0.326437</td>\n      <td>-0.065310</td>\n      <td>-1.992433</td>\n      <td>0.032120</td>\n      <td>-0.113857</td>\n      <td>0.345319</td>\n      <td>0.071474</td>\n      <td>0.562888</td>\n      <td>0.670933</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>768</th>\n      <td>-0.039545</td>\n      <td>-0.047596</td>\n      <td>0.099078</td>\n      <td>0.017030</td>\n      <td>0.050608</td>\n      <td>-0.055531</td>\n      <td>0.014937</td>\n      <td>0.002273</td>\n      <td>0.012196</td>\n      <td>0.048750</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4469</th>\n      <td>-0.060360</td>\n      <td>0.019270</td>\n      <td>0.010936</td>\n      <td>0.021893</td>\n      <td>0.038589</td>\n      <td>-0.054131</td>\n      <td>0.158589</td>\n      <td>-0.018854</td>\n      <td>0.008534</td>\n      <td>-0.002490</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1882</th>\n      <td>-0.148604</td>\n      <td>-0.077960</td>\n      <td>-0.116153</td>\n      <td>-0.094700</td>\n      <td>0.267774</td>\n      <td>-0.040307</td>\n      <td>-0.021478</td>\n      <td>-0.506743</td>\n      <td>0.261646</td>\n      <td>-0.431739</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>-1.007403</td>\n      <td>-0.618366</td>\n      <td>0.116358</td>\n      <td>-1.325000</td>\n      <td>1.168161</td>\n      <td>-1.365896</td>\n      <td>1.361673</td>\n      <td>-0.448088</td>\n      <td>-1.332194</td>\n      <td>-0.930954</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2067</th>\n      <td>0.282444</td>\n      <td>0.167582</td>\n      <td>0.487497</td>\n      <td>-1.959577</td>\n      <td>0.222063</td>\n      <td>0.001253</td>\n      <td>0.418074</td>\n      <td>0.072365</td>\n      <td>-0.257828</td>\n      <td>-0.796918</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3806</th>\n      <td>0.401531</td>\n      <td>0.095293</td>\n      <td>-0.417779</td>\n      <td>0.474225</td>\n      <td>0.101211</td>\n      <td>0.041517</td>\n      <td>-0.049956</td>\n      <td>0.040278</td>\n      <td>-0.451167</td>\n      <td>0.627290</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2848</th>\n      <td>0.170633</td>\n      <td>-0.025721</td>\n      <td>-0.227568</td>\n      <td>0.788244</td>\n      <td>0.054609</td>\n      <td>-0.446208</td>\n      <td>0.098217</td>\n      <td>-0.135390</td>\n      <td>0.165383</td>\n      <td>-0.411212</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4433</th>\n      <td>0.095530</td>\n      <td>-0.786122</td>\n      <td>-0.197755</td>\n      <td>0.877729</td>\n      <td>0.341580</td>\n      <td>-1.056308</td>\n      <td>1.055216</td>\n      <td>-0.878664</td>\n      <td>-0.283878</td>\n      <td>-2.451230</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3519</th>\n      <td>0.178407</td>\n      <td>0.034079</td>\n      <td>0.016657</td>\n      <td>0.045533</td>\n      <td>-0.065205</td>\n      <td>-0.085974</td>\n      <td>0.120133</td>\n      <td>-0.184785</td>\n      <td>0.503005</td>\n      <td>-0.533195</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5338</th>\n      <td>-0.327231</td>\n      <td>-0.035768</td>\n      <td>-0.129199</td>\n      <td>0.232442</td>\n      <td>0.125014</td>\n      <td>-0.010514</td>\n      <td>0.112833</td>\n      <td>-0.264502</td>\n      <td>-0.046568</td>\n      <td>0.065235</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3947</th>\n      <td>0.125262</td>\n      <td>-0.143949</td>\n      <td>-0.124911</td>\n      <td>0.007842</td>\n      <td>0.080374</td>\n      <td>-0.524426</td>\n      <td>0.090392</td>\n      <td>0.033255</td>\n      <td>0.234648</td>\n      <td>-0.137978</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4373</th>\n      <td>1.065579</td>\n      <td>-0.134338</td>\n      <td>-0.424483</td>\n      <td>0.014997</td>\n      <td>-0.103470</td>\n      <td>-0.610555</td>\n      <td>0.210089</td>\n      <td>0.157245</td>\n      <td>-0.083689</td>\n      <td>-0.138122</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2092</th>\n      <td>0.225971</td>\n      <td>0.253235</td>\n      <td>-0.143679</td>\n      <td>0.487785</td>\n      <td>0.414680</td>\n      <td>0.039114</td>\n      <td>0.088530</td>\n      <td>-0.058911</td>\n      <td>0.123355</td>\n      <td>0.308150</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>525</th>\n      <td>-0.055370</td>\n      <td>0.034809</td>\n      <td>0.132021</td>\n      <td>-0.186088</td>\n      <td>0.138906</td>\n      <td>-0.028076</td>\n      <td>0.170086</td>\n      <td>0.017266</td>\n      <td>-0.031659</td>\n      <td>-0.042254</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4327</th>\n      <td>0.804538</td>\n      <td>-0.365379</td>\n      <td>0.335829</td>\n      <td>-2.000204</td>\n      <td>-0.278712</td>\n      <td>-0.448454</td>\n      <td>0.474781</td>\n      <td>0.107432</td>\n      <td>-0.546254</td>\n      <td>0.267519</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3048</th>\n      <td>0.307641</td>\n      <td>0.273976</td>\n      <td>-0.603444</td>\n      <td>-0.109916</td>\n      <td>0.236619</td>\n      <td>0.154224</td>\n      <td>0.687846</td>\n      <td>-0.819597</td>\n      <td>-0.105569</td>\n      <td>-1.346810</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2665</th>\n      <td>0.212213</td>\n      <td>-0.082370</td>\n      <td>0.059706</td>\n      <td>-0.053417</td>\n      <td>0.223374</td>\n      <td>-0.106200</td>\n      <td>0.180821</td>\n      <td>-0.201176</td>\n      <td>0.516400</td>\n      <td>-0.295822</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4940</th>\n      <td>0.212651</td>\n      <td>0.074959</td>\n      <td>-0.029705</td>\n      <td>0.004693</td>\n      <td>-0.092700</td>\n      <td>-0.006127</td>\n      <td>0.291180</td>\n      <td>-0.052899</td>\n      <td>0.023834</td>\n      <td>-0.476892</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>25 rows × 100 columns</p>\n</div>"
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_ratings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "data": {
      "text/plain": "0.10121064592445786"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_ratings[22][3806]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "data": {
      "text/plain": "nan"
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_ratings[278][3878]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "data": {
      "text/plain": "Factor1    -0.042344\nFactor2    -0.040755\nFactor3    -0.055720\nFactor4    -0.073726\nFactor5     0.018203\nFactor6     0.091940\nFactor7     0.123959\nFactor8    -0.157403\nFactor9    -0.020388\nFactor10    0.082493\nFactor11    0.223057\nFactor12   -0.040915\nFactor13   -0.130308\nFactor14   -0.021816\nFactor15    0.034549\nName: 3806, dtype: float64"
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#latent_user_preferences.loc[3806]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [],
   "source": [
    "\n",
    "def train(user_id, item_id, rating, l_user_prefs, l_item_feats, alpha=0.0001, ):\n",
    "    #print(item_id)\n",
    "    predicted_rating = predict_rating(user_id, item_id)\n",
    "    err =  predicted_rating - rating\n",
    "    #print(err)\n",
    "    user_pref_values = l_user_prefs.loc[user_id]\n",
    "    l_user_prefs.loc[user_id] -= alpha * err * l_item_feats.loc[item_id]\n",
    "    l_item_feats.loc[item_id] -= alpha * err * user_pref_values\n",
    "    return err\n",
    "\n",
    "\n",
    "def sgd(iterations, l_user_prefs, l_item_feats, u_ratings):\n",
    "    \"\"\" Iterate over all users and all items and train for\n",
    "        a certain number of iterations\n",
    "    \"\"\"\n",
    "    mse_history = []\n",
    "    for iteration in range(iterations):\n",
    "        error = []\n",
    "        for user_id in l_user_prefs.T.columns:\n",
    "            for item_id in l_item_feats.T.columns:\n",
    "                rating = u_ratings[item_id][user_id]\n",
    "                if not np.isnan(rating):\n",
    "                    err = train(user_id, item_id, rating, l_user_prefs, l_item_feats)\n",
    "                    error.append(err)\n",
    "        mse = np.square(np.array(error)).mean()\n",
    "        if (iteration % 10000) == 0:\n",
    "            print('Iteration %d/%d:\\tMSE=%.6f' % (iteration, iterations, mse))\n",
    "            mse_history.append(mse)\n",
    "    return mse_history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0/30000:\tMSE=0.298896\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-260-52e2e7ebdc54>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mnum_iter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m30000\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mhist\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msgd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_iter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlatent_user_preferences\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlatent_item_features\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muser_ratings\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# Note how the MSE decreases with the number of iterations\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_iter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m10000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mxlabel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Iterations\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-259-b2ef9f109cd2>\u001B[0m in \u001B[0;36msgd\u001B[0;34m(iterations, l_user_prefs, l_item_feats, u_ratings)\u001B[0m\n\u001B[1;32m     21\u001B[0m                 \u001B[0mrating\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mu_ratings\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mitem_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0muser_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misnan\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrating\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m                     \u001B[0merr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muser_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitem_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrating\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ml_user_prefs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ml_item_feats\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m                     \u001B[0merror\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0mmse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msquare\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merror\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-259-b2ef9f109cd2>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(user_id, item_id, rating, l_user_prefs, l_item_feats, alpha)\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;31m#print(err)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0muser_pref_values\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0ml_user_prefs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0muser_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0ml_user_prefs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0muser_id\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m-=\u001B[0m \u001B[0malpha\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0merr\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0ml_item_feats\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mitem_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m     \u001B[0ml_item_feats\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mitem_id\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m-=\u001B[0m \u001B[0malpha\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0merr\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0muser_pref_values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3/dist-packages/pandas/core/ops/__init__.py\u001B[0m in \u001B[0;36mf\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    828\u001B[0m             \u001B[0;31m# we are updating inplace so we want to ignore is_copy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    829\u001B[0m             self._update_inplace(\n\u001B[0;32m--> 830\u001B[0;31m                 \u001B[0mresult\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreindex_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_is_copy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    831\u001B[0m             )\n\u001B[1;32m    832\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3/dist-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36mreindex_like\u001B[0;34m(self, other, method, copy, limit, tolerance)\u001B[0m\n\u001B[1;32m   3879\u001B[0m         )\n\u001B[1;32m   3880\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3881\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreindex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3882\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3883\u001B[0m     def drop(\n",
      "\u001B[0;32m/usr/lib/python3/dist-packages/pandas/core/series.py\u001B[0m in \u001B[0;36mreindex\u001B[0;34m(self, index, **kwargs)\u001B[0m\n\u001B[1;32m   4219\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mAppender\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgeneric\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNDFrame\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreindex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__doc__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4220\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mreindex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4221\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreindex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   4222\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4223\u001B[0m     def drop(\n",
      "\u001B[0;32m/usr/lib/python3/dist-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36mreindex\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   4490\u001B[0m             )\n\u001B[1;32m   4491\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4492\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_consolidate_inplace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   4493\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4494\u001B[0m         \u001B[0;31m# if all axes that are requested to reindex are equal, then only copy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3/dist-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m_consolidate_inplace\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   5250\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconsolidate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5251\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5252\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_protect_consolidate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5253\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5254\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_consolidate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3/dist-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m_protect_consolidate\u001B[0;34m(self, f)\u001B[0m\n\u001B[1;32m   5239\u001B[0m         \"\"\"\n\u001B[1;32m   5240\u001B[0m         \u001B[0mblocks_before\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mblocks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5241\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5242\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mblocks\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mblocks_before\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5243\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_clear_item_cache\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3/dist-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36mf\u001B[0;34m()\u001B[0m\n\u001B[1;32m   5248\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5249\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5250\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconsolidate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5251\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5252\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_protect_consolidate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3/dist-packages/pandas/core/internals/managers.py\u001B[0m in \u001B[0;36mconsolidate\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    917\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    918\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 919\u001B[0;31m     \u001B[0;32mdef\u001B[0m \u001B[0mconsolidate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    920\u001B[0m         \"\"\"\n\u001B[1;32m    921\u001B[0m         \u001B[0mJoin\u001B[0m \u001B[0mtogether\u001B[0m \u001B[0mblocks\u001B[0m \u001B[0mhaving\u001B[0m \u001B[0msame\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "num_iter = 30000\n",
    "hist = sgd(num_iter, latent_user_preferences, latent_item_features, user_ratings)  # Note how the MSE decreases with the number of iterations\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, num_iter, 10000), hist)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = latent_user_preferences.dot(latent_item_features.T)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "values = [\n",
    "    zip(user_ratings.loc[i], predictions[i])\n",
    "    for i in range(predictions.shape[0])\n",
    "]\n",
    "comparison_data: pd.DataFrame = pd.DataFrame(values)\n",
    "comparison_data.columns = data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comparison_data\n",
    "# For each data point, the number on the left is the original value from the dataset, the number on the right is the prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-b1666b00",
   "language": "python",
   "display_name": "PyCharm (ce888)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}