{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import traceback\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Final, List, TypeVar, Dict, Tuple, Any, Optional\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#print(sns.plotting_context())\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\",context=\"paper\")\n",
    "\n",
    "import matplotlib.style\n",
    "if \"seaborn-darkgrid\" in matplotlib.style.available:\n",
    "    matplotlib.style.use(\"seaborn-darkgrid\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_seed: Final[int] = 42\n",
    "\"Using the meaning of life, the universe, and everything as the seed for RNG\"\n",
    "\n",
    "_rng: Final[np.random.Generator] = np.random.default_rng(seed=_seed)\n",
    "\"and creating a numpy random generator, using our set seed of 42\"\n",
    "\n",
    "\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IHDP dataset processing\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "def turn_01_columns_into_int(\n",
    "        dataframe_to_edit: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Finds all of the columns that just contain values of 0 and 1,\n",
    "    and converts all of those columns to ints.\n",
    "\n",
    "    Dataframe will have an '01' and 'not_01' attr added to it.\n",
    "    Labels for series that only contain values 0 and 1 will be in the '01' tuple\n",
    "    Labels for every other series will be in the 'not_01' tuple\n",
    "\n",
    "    MODIFIES THE GIVEN DATAFRAME!\n",
    "    :param dataframe_to_edit: the dataframe that is being edited\n",
    "    :return: The modified dataframe.\n",
    "    DOES NOT COPY THE GIVEN ORIGINAL DATAFRAME.\n",
    "\n",
    "    >>> import pandas as pd\n",
    "    >>> print(pd.__version__)\n",
    "    1.4.1\n",
    "    >>> before: pd.DataFrame = pd.DataFrame.from_dict(data={\"int01\":[0,1,1,0],\"flt01\":[0.0, 1.0, 0.0, 1.0], \"intNo\": [-1,0,1,2], \"fltNo\":[-1.0, 0.0, 1.0, 2.0], \"intNan\": [0,1,None,0], \"fltNan\":[0.0,1.0,None,0.0]})\n",
    "    >>> before_types = before.dtypes.values\n",
    "    >>> after: pd.DataFrame = turn_01_columns_into_int(before.copy())\n",
    "    >>> after_types = after.dtypes.values\n",
    "    >>> print(after_types[0])\n",
    "    uint8\n",
    "    >>> print(after_types[1])\n",
    "    uint8\n",
    "    >>> print(f\"{before_types[2] == after_types[2]} {before_types[3] == after_types[3]} {before_types[4] == after_types[4]} {before_types[5] == after_types[5]}\")\n",
    "    True True True True\n",
    "    >>> print(f\"{after.attrs['01']}\")\n",
    "    ('int01', 'flt01')\n",
    "    >>> print(f\"{after.attrs['not_01']} \")\n",
    "    ('intNo', 'fltNo', 'intNan', 'fltNan')\n",
    "    \"\"\"\n",
    "    cols_01: List[str] = []\n",
    "    not_01:  List[str] = []\n",
    "    for c in dataframe_to_edit.columns:\n",
    "        #if dataframe_to_edit[c].dtype == np.uint8:\n",
    "        #    continue\n",
    "        if dataframe_to_edit[c].isin([0,1]).all():\n",
    "            dataframe_to_edit[c] = dataframe_to_edit[c].astype(np.uint8)\n",
    "            cols_01.append(c)\n",
    "        else:\n",
    "            not_01.append(c)\n",
    "    dataframe_to_edit.attrs[\"01\"] = tuple(cols_01)\n",
    "    dataframe_to_edit.attrs[\"not_01\"] = tuple(not_01)\n",
    "    return dataframe_to_edit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "         x0        x1        x2        x3        x4        x5  x6  x7  x8  x9  \\\n0  1.397395  0.996346 -1.105624 -0.879606  0.308569 -1.023402   1   0   0   0   \n1  0.269033  0.196818  0.383828  0.161703 -0.629189  1.460832   1   0   1   0   \n2  1.051537  1.795874 -1.105624  0.161703 -0.629189  0.963985   1   0   1   1   \n3  0.662446  0.196818 -0.733261 -0.879606  0.371086 -0.692171   1   0   0   0   \n4  0.856992  1.795874  0.011465 -0.879606  0.558638  0.301522   0   1   1   0   \n\n   ...  x21  x22  x23  x24  t        yf       ycf       ite        t0  \\\n0  ...    0    0    0    1  1  4.771232 -0.298509  4.657928 -0.298509   \n1  ...    0    0    0    0  0  2.956273  5.783770  3.428604  2.956273   \n2  ...    0    0    0    1  0  4.164164  7.055789  3.658195  4.164164   \n3  ...    0    0    0    0  1  6.172307  1.379697  4.585505  1.379697   \n4  ...    0    0    0    0  1  7.834469  2.747986  4.265591  2.747986   \n\n         t1  \n0  4.771232  \n1  5.783770  \n2  7.055789  \n3  6.172307  \n4  7.834469  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x0</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n      <th>x5</th>\n      <th>x6</th>\n      <th>x7</th>\n      <th>x8</th>\n      <th>x9</th>\n      <th>...</th>\n      <th>x21</th>\n      <th>x22</th>\n      <th>x23</th>\n      <th>x24</th>\n      <th>t</th>\n      <th>yf</th>\n      <th>ycf</th>\n      <th>ite</th>\n      <th>t0</th>\n      <th>t1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.397395</td>\n      <td>0.996346</td>\n      <td>-1.105624</td>\n      <td>-0.879606</td>\n      <td>0.308569</td>\n      <td>-1.023402</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.771232</td>\n      <td>-0.298509</td>\n      <td>4.657928</td>\n      <td>-0.298509</td>\n      <td>4.771232</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.269033</td>\n      <td>0.196818</td>\n      <td>0.383828</td>\n      <td>0.161703</td>\n      <td>-0.629189</td>\n      <td>1.460832</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.956273</td>\n      <td>5.783770</td>\n      <td>3.428604</td>\n      <td>2.956273</td>\n      <td>5.783770</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.051537</td>\n      <td>1.795874</td>\n      <td>-1.105624</td>\n      <td>0.161703</td>\n      <td>-0.629189</td>\n      <td>0.963985</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.164164</td>\n      <td>7.055789</td>\n      <td>3.658195</td>\n      <td>4.164164</td>\n      <td>7.055789</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.662446</td>\n      <td>0.196818</td>\n      <td>-0.733261</td>\n      <td>-0.879606</td>\n      <td>0.371086</td>\n      <td>-0.692171</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6.172307</td>\n      <td>1.379697</td>\n      <td>4.585505</td>\n      <td>1.379697</td>\n      <td>6.172307</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.856992</td>\n      <td>1.795874</td>\n      <td>0.011465</td>\n      <td>-0.879606</td>\n      <td>0.558638</td>\n      <td>0.301522</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7.834469</td>\n      <td>2.747986</td>\n      <td>4.265591</td>\n      <td>2.747986</td>\n      <td>7.834469</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ihdp_full: pd.DataFrame = turn_01_columns_into_int(pd.read_csv(\"ihdp_full.csv\"))\n",
    "\"The full IHDP dataset (with supplementary t0 and t1 info) as a dataframe\"\n",
    "\n",
    "ihdp_full.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 747 entries, 0 to 746\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x0      747 non-null    float64\n",
      " 1   x1      747 non-null    float64\n",
      " 2   x2      747 non-null    float64\n",
      " 3   x3      747 non-null    float64\n",
      " 4   x4      747 non-null    float64\n",
      " 5   x5      747 non-null    float64\n",
      " 6   x6      747 non-null    uint8  \n",
      " 7   x7      747 non-null    uint8  \n",
      " 8   x8      747 non-null    uint8  \n",
      " 9   x9      747 non-null    uint8  \n",
      " 10  x10     747 non-null    uint8  \n",
      " 11  x11     747 non-null    uint8  \n",
      " 12  x12     747 non-null    uint8  \n",
      " 13  x13     747 non-null    uint8  \n",
      " 14  x14     747 non-null    uint8  \n",
      " 15  x15     747 non-null    uint8  \n",
      " 16  x16     747 non-null    uint8  \n",
      " 17  x17     747 non-null    uint8  \n",
      " 18  x18     747 non-null    uint8  \n",
      " 19  x19     747 non-null    uint8  \n",
      " 20  x20     747 non-null    uint8  \n",
      " 21  x21     747 non-null    uint8  \n",
      " 22  x22     747 non-null    uint8  \n",
      " 23  x23     747 non-null    uint8  \n",
      " 24  x24     747 non-null    uint8  \n",
      " 25  t       747 non-null    uint8  \n",
      " 26  yf      747 non-null    float64\n",
      " 27  ycf     747 non-null    float64\n",
      " 28  ite     747 non-null    float64\n",
      " 29  t0      747 non-null    float64\n",
      " 30  t1      747 non-null    float64\n",
      "dtypes: float64(11), uint8(20)\n",
      "memory usage: 78.9 KB\n"
     ]
    }
   ],
   "source": [
    "ihdp_full.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihdp_factuals: pd.DataFrame = ihdp_full.loc[:, ~ihdp_full.columns.isin(\n",
    "    [\"ycf\",\"ite\",\"t0\",\"t1\"]\n",
    ")]\n",
    "\"A version of the IHDP dataset containing ONLY the factual data\"\n",
    "\n",
    "ihdp_factuals_no_y: pd.DataFrame = ihdp_factuals.loc[:, ihdp_factuals.columns != \"yf\"]\n",
    "\"IHDP dataset with the factual Y omitted\"\n",
    "\n",
    "ihdp_factuals_y: pd.DataFrame = ihdp_factuals.loc[:, ihdp_factuals.columns == \"yf\"]\n",
    "\"Only the Y data from the IHDP dataset\"\n",
    "\n",
    "\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "ihdp_learn_validation_skf: StratifiedKFold = StratifiedKFold(n_splits=10, shuffle=True, random_state=_seed)\n",
    "\"Using this to remove 10% of the treated/untreated factuals from ihdp for use as part of the validation dataset later on\"\n",
    "\n",
    "ihdp_learn_indices, ihdp_validation_indices = [i for i in ihdp_learn_validation_skf.split(ihdp_factuals, ihdp_factuals[\"t\"])][0]\n",
    "\n",
    "ihdp_learn_df: pd.DataFrame = ihdp_factuals.iloc[ihdp_learn_indices]\n",
    "\"The dataframe that is the subset of the IHDP factual data which will be used for learning feature importances etc\"\n",
    "\n",
    "ihdp_learn_df_x: pd.DataFrame = ihdp_learn_df.loc[:, ihdp_learn_df.columns != \"yf\"]\n",
    "\"X/T info for the dataframe that is the subset of the IHDP factual data which will be used for learning feature importances etc\"\n",
    "ihdp_learn_df_y: pd.DataFrame = ihdp_learn_df.loc[:, ihdp_learn_df.columns == \"yf\"]\n",
    "\"Y info for the dataframe that is the subset of the IHDP factual data which will be used for learning feature importances etc\"\n",
    "\n",
    "ihdp_validation_factual_df: pd.DataFrame = ihdp_factuals.iloc[ihdp_validation_indices]\n",
    "ihdp_validation_factual_df_x: pd.DataFrame = ihdp_validation_factual_df.loc[:, ihdp_validation_factual_df.columns != \"yf\"]\n",
    "ihdp_validation_factual_df_y: pd.DataFrame = ihdp_validation_factual_df.loc[:, ihdp_validation_factual_df.columns == \"yf\"]\n",
    "\n",
    "\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._validation import NotFittedError\n",
    "from sklearn.base import RegressorMixin, TransformerMixin\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from math import inf\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "R = TypeVar('R', bound=RegressorMixin)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "def np_data_and_targets(df: pd.DataFrame, targetname: str = \"yf\") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Converts dataframe into a couple of numpy ndarrays for the data without the labels,\n",
    "    and the labels by themselves.\n",
    "    :param df: the Dataframe\n",
    "    :param targetname: The name of the column holding the targets\n",
    "    :return: tuple of [ndarray of the values without the targets, just the class labels]\n",
    "    \"\"\"\n",
    "\n",
    "    inputs:  np.ndarray = df.loc[:,df.columns != targetname].to_numpy()\n",
    "    outputs: np.ndarray =  df.loc[:,targetname].to_numpy()\n",
    "\n",
    "    return inputs, outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "def halving_grid_searcher(\n",
    "        regressor: R,\n",
    "        param_grid: Dict[str, List[Any]],\n",
    "        train_data: np.ndarray,\n",
    "        train_targets: np.ndarray,\n",
    "        k_fold_NO_SHUFFLE: KFold = KFold(n_splits=5, shuffle=False),\n",
    "        class_weights: Optional[np.ndarray] = None\n",
    ") -> HalvingGridSearchCV:\n",
    "\n",
    "    pipe: Pipeline = Pipeline([\n",
    "        (\"scaler\", QuantileTransformer(output_distribution=\"normal\")),\n",
    "        #(\"imputer\",KNNImputer(add_indicator=False, weights=\"distance\")),\n",
    "        (\"regressor\",regressor)\n",
    "    ])\n",
    "\n",
    "    h_grid_search: HalvingGridSearchCV = HalvingGridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        factor=3,\n",
    "        cv=k_fold_NO_SHUFFLE,\n",
    "        scoring=make_scorer(r2_score),\n",
    "        refit=True,\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        error_score=-1000000000000\n",
    "        # I wanted to make this error score negative infinity, however, doing so caused a lot of\n",
    "        # particularly unsightly warning messages to appear.\n",
    "\n",
    "        # So, to save everyone involved from having to look at at a buttload of them with a buttload of numbers in them,\n",
    "        # I'm just setting this to an incredibly low finite number which should be rather hard to reach.\n",
    "        # And if this score (or an even lower score) somehow is reached legitimately, chances are that\n",
    "        # the legitimate score being lower than the error score will be the least of one's concerns.\n",
    "    )\n",
    "\n",
    "    if class_weights is not None:\n",
    "\n",
    "        h_grid_search.fit(\n",
    "            train_data, train_targets, sample_weight=class_weights\n",
    "        )\n",
    "    else:\n",
    "        h_grid_search.fit(\n",
    "            train_data, train_targets\n",
    "        )\n",
    "\n",
    "    return h_grid_search\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "def nested_halving_grid_searcher(\n",
    "        regressor: R,\n",
    "        param_grid: Dict[str, List[Any]],\n",
    "        train_data: np.ndarray,\n",
    "        train_targets: np.ndarray,\n",
    "        kfold_splits: int = 6,\n",
    "        classes_ndarray: Optional[np.ndarray] = None\n",
    ") -> Dict[HalvingGridSearchCV, float]:\n",
    "\n",
    "    h_grid_search_dicts: Dict[HalvingGridSearchCV, float] = {}\n",
    "\n",
    "    kf: KFold = KFold(n_splits=kfold_splits, shuffle=True, random_state=_seed)\n",
    "\n",
    "    for i, (train_indices, test_indices) in enumerate(kf.split(train_data, train_targets), 1):\n",
    "        print(f\"-- {i}/{kfold_splits} start --\")\n",
    "        try:\n",
    "            if classes_ndarray is not None:\n",
    "\n",
    "                train_classes: np.ndarray = np.take(classes_ndarray, train_indices)\n",
    "\n",
    "                train_classes = train_classes / np.sum(train_classes)\n",
    "\n",
    "                test_classes: np.ndarray = np.take(classes_ndarray, test_indices)\n",
    "                test_classes = test_classes / np.sum(test_classes)\n",
    "\n",
    "                current_search: HalvingGridSearchCV = halving_grid_searcher(\n",
    "                    regressor,\n",
    "                    param_grid,\n",
    "                    train_data[train_indices],\n",
    "                    train_targets[train_indices],\n",
    "                    KFold(n_splits=max(1, kfold_splits-1), shuffle=False),\n",
    "                    class_weights = train_classes\n",
    "                )\n",
    "\n",
    "                current_score: float = current_search.score(\n",
    "                    train_data[test_indices],\n",
    "                    train_targets[test_indices]\n",
    "                )\n",
    "\n",
    "                h_grid_search_dicts[current_search] = current_score\n",
    "\n",
    "            else:\n",
    "\n",
    "\n",
    "                current_search: HalvingGridSearchCV = halving_grid_searcher(\n",
    "                    regressor,\n",
    "                    param_grid,\n",
    "                    train_data[train_indices],\n",
    "                    train_targets[train_indices],\n",
    "                    KFold(n_splits=max(1, kfold_splits-1), shuffle=False)\n",
    "                )\n",
    "\n",
    "                current_score: float = current_search.score(\n",
    "                    train_data[test_indices],\n",
    "                    train_targets[test_indices]\n",
    "                )\n",
    "\n",
    "                h_grid_search_dicts[current_search] = current_score\n",
    "\n",
    "            print(f\"-- {i}/{kfold_splits} done --\")\n",
    "\n",
    "        except NotFittedError as e:\n",
    "            print(\"oh no! there was a not fitted error!\", sys.stderr)\n",
    "            print(e, sys.stderr)\n",
    "            print(traceback.format_exc(), sys.stderr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return h_grid_search_dicts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('scaler', QuantileTransformer()),\n                ('learner', RandomForestRegressor())])",
      "text/html": "<style>#sk-5aa62442-bb22-4d18-a531-995276f2a250 {color: black;background-color: white;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 pre{padding: 0;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-toggleable {background-color: white;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-estimator:hover {background-color: #d4ebff;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-item {z-index: 1;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-parallel-item:only-child::after {width: 0;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-5aa62442-bb22-4d18-a531-995276f2a250 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-5aa62442-bb22-4d18-a531-995276f2a250\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, QuantileTransformer()),\n                (&#x27;learner&#x27;, RandomForestRegressor())])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d2075060-f37c-4c9e-8367-8a29730bd324\" type=\"checkbox\" ><label for=\"d2075060-f37c-4c9e-8367-8a29730bd324\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, QuantileTransformer()),\n                (&#x27;learner&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"289d8648-17d0-4eb2-b0a1-f92d9df3cf12\" type=\"checkbox\" ><label for=\"289d8648-17d0-4eb2-b0a1-f92d9df3cf12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8470ad65-708a-4ab2-9814-cea49232c559\" type=\"checkbox\" ><label for=\"8470ad65-708a-4ab2-9814-cea49232c559\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\",QuantileTransformer()),\n",
    "        (\"learner\",RandomForestRegressor())\n",
    "        #(\"learner\",ARDRegression())\n",
    "        #(\"learner\",AdaBoostRegressor(base_estimator=ARDRegression()))\n",
    "        #(\"learner\",LinearRegression())\n",
    "    ]\n",
    ")\n",
    "learner = fpipeline[\"learner\"]\n",
    "fpipeline.fit(ihdp_learn_df_x.to_numpy(), ihdp_learn_df_y.to_numpy())\n",
    "\n",
    "fpipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6928530080365853"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpipeline.score(ihdp_validation_factual_df_x.to_numpy(), ihdp_validation_factual_df_y.to_numpy())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 1/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 120\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 40\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 14\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 5\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "-- 1/6 done --\n",
      "-- 2/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 120\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 40\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 14\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 5\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "-- 2/6 done --\n",
      "-- 3/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 120\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 40\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 14\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 5\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "-- 3/6 done --\n",
      "-- 4/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 120\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 40\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 14\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 5\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "-- 4/6 done --\n",
      "-- 5/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 120\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 40\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 14\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 5\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "-- 5/6 done --\n",
      "-- 6/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 120\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 40\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 14\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 5\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "-- 6/6 done --\n"
     ]
    }
   ],
   "source": [
    "random_forest_searched_dict: Dict[\n",
    "    HalvingGridSearchCV, float\n",
    "] = nested_halving_grid_searcher(\n",
    "    RandomForestRegressor(criterion=\"squared_error\"),\n",
    "    {\n",
    "        #\"regressor__criterion\": [\"squared_error\", \"poisson\"],\n",
    "        \"regressor__n_estimators\": [75,100,125],\n",
    "        \"regressor__min_samples_split\": [2,4,6,8],\n",
    "        #\"regressor__min_impurity_decrease\": [0, *np.geomspace(0.00001,0.2,6)[1:]],\n",
    "        \"regressor__max_features\": [None,\"sqrt\",\"log2\",1,2],\n",
    "        \"regressor__oob_score\": [False, True],\n",
    "        #\"regressor__ccp_alpha\": [0, *np.geomspace(0.00001,0.2,6)[1:]]\n",
    "    },\n",
    "    ihdp_learn_df_x.values,\n",
    "    ihdp_learn_df_y.values,\n",
    "    kfold_splits=6,\n",
    "    classes_ndarray=None #classes_ndarray=ihdp_learn_df_x[\"t\"].to_numpy()\n",
    ")\n",
    "\n",
    "rf_searched: HalvingGridSearchCV = max(\n",
    "    random_forest_searched_dict.keys(),\n",
    "    key=lambda k: random_forest_searched_dict[k]\n",
    ")\n",
    "\n",
    "best_rf: Tuple[HalvingGridSearchCV, float] = (\n",
    "    rf_searched,\n",
    "    random_forest_searched_dict[rf_searched]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(HalvingGridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
      "                    error_score=-1000000000000,\n",
      "                    estimator=Pipeline(steps=[('scaler',\n",
      "                                               QuantileTransformer(output_distribution='normal')),\n",
      "                                              ('regressor',\n",
      "                                               RandomForestRegressor())]),\n",
      "                    n_jobs=-1,\n",
      "                    param_grid={'regressor__max_features': [None, 'sqrt',\n",
      "                                                            'log2', 1, 2],\n",
      "                                'regressor__min_samples_split': [2, 4, 6, 8],\n",
      "                                'regressor__n_estimators': [75, 100, 125],\n",
      "                                'regressor__oob_score': [False, True]},\n",
      "                    scoring=make_scorer(r2_score), verbose=1), 0.7744807092877399)\n",
      "0.7744807092877399\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pipeline(steps=[('scaler', QuantileTransformer(output_distribution='normal')),\n                ('regressor',\n                 RandomForestRegressor(max_features=None, n_estimators=125,\n                                       oob_score=True))])",
      "text/html": "<style>#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 {color: black;background-color: white;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 pre{padding: 0;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-toggleable {background-color: white;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-estimator:hover {background-color: #d4ebff;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-item {z-index: 1;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-parallel-item:only-child::after {width: 0;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-64701bde-82d8-49c3-a2b3-b9f68688ae35 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-64701bde-82d8-49c3-a2b3-b9f68688ae35\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, QuantileTransformer(output_distribution=&#x27;normal&#x27;)),\n                (&#x27;regressor&#x27;,\n                 RandomForestRegressor(max_features=None, n_estimators=125,\n                                       oob_score=True))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6fd85e32-8203-4d44-b88d-a238cd5dbe4b\" type=\"checkbox\" ><label for=\"6fd85e32-8203-4d44-b88d-a238cd5dbe4b\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, QuantileTransformer(output_distribution=&#x27;normal&#x27;)),\n                (&#x27;regressor&#x27;,\n                 RandomForestRegressor(max_features=None, n_estimators=125,\n                                       oob_score=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"cc724e39-b5e6-4b8a-9d47-96f83363c340\" type=\"checkbox\" ><label for=\"cc724e39-b5e6-4b8a-9d47-96f83363c340\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer(output_distribution=&#x27;normal&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a27aacea-9c99-4e92-a966-688de9d67288\" type=\"checkbox\" ><label for=\"a27aacea-9c99-4e92-a966-688de9d67288\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_features=None, n_estimators=125, oob_score=True)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_rf)\n",
    "\n",
    "print(best_rf[1])\n",
    "\n",
    "rf_searched.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 1/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 729\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 243\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 81\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 27\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "-- 1/6 done --\n",
      "-- 2/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 729\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 243\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 81\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 27\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "-- 2/6 done --\n",
      "-- 3/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 729\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 243\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 81\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 27\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "-- 3/6 done --\n",
      "-- 4/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 729\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 243\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 81\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 27\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "-- 4/6 done --\n",
      "-- 5/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 729\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 243\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 81\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 27\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "-- 5/6 done --\n",
      "-- 6/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 729\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 243\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 81\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 27\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "-- 6/6 done --\n"
     ]
    }
   ],
   "source": [
    "ard_iter: List[int] = [200,300,400]\n",
    "ard_tol: List[float] = [1e-2, 1e-3, 1e-4]\n",
    "ard_alpha_lambda: List[float] = [1e-5, 1e-6, 1e-7]\n",
    "ard_thresh_lambda: List[float] = [1e3, 1e4, 1e5]\n",
    "\n",
    "ard_searched_dict: Dict[\n",
    "    HalvingGridSearchCV, float\n",
    "] = nested_halving_grid_searcher(\n",
    "    ARDRegression(),\n",
    "    {\n",
    "        \"regressor__n_iter\": ard_iter,\n",
    "        \"regressor__tol\": ard_tol,\n",
    "        \"regressor__alpha_1\" : ard_alpha_lambda,\n",
    "        \"regressor__alpha_2\" : ard_alpha_lambda,\n",
    "        \"regressor__lambda_1\" : ard_alpha_lambda,\n",
    "        \"regressor__lambda_2\" : ard_alpha_lambda,\n",
    "        \"regressor__threshold_lambda\": ard_thresh_lambda\n",
    "    },\n",
    "    ihdp_learn_df_x.values,\n",
    "    ihdp_learn_df_y.values,\n",
    "    kfold_splits=6,\n",
    "    classes_ndarray=None\n",
    ")\n",
    "\n",
    "ard_searched: HalvingGridSearchCV = max(\n",
    "    ard_searched_dict.keys(),\n",
    "    key=lambda k: ard_searched_dict[k]\n",
    ")\n",
    "\n",
    "best_ard: Tuple[HalvingGridSearchCV, float] = (\n",
    "    ard_searched,\n",
    "    ard_searched_dict[ard_searched]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(HalvingGridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
      "                    error_score=-1000000000000,\n",
      "                    estimator=Pipeline(steps=[('scaler',\n",
      "                                               QuantileTransformer(output_distribution='normal')),\n",
      "                                              ('regressor', ARDRegression())]),\n",
      "                    n_jobs=-1,\n",
      "                    param_grid={'regressor__alpha_1': [1e-05, 1e-06, 1e-07],\n",
      "                                'regressor__alpha_2': [1e-05, 1e-06, 1e-07],\n",
      "                                'regressor__lambda_1': [1e-05, 1e-06, 1e-07],\n",
      "                                'regressor__lambda_2': [1e-05, 1e-06, 1e-07],\n",
      "                                'regressor__threshold_lambda': [1000.0, 10000.0,\n",
      "                                                                100000.0],\n",
      "                                'regressor__tol': [0.01, 0.001, 0.0001]},\n",
      "                    scoring=make_scorer(r2_score), verbose=1), 0.7798079864859973)\n",
      "0.7798079864859973\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pipeline(steps=[('scaler', QuantileTransformer(output_distribution='normal')),\n                ('regressor',\n                 ARDRegression(alpha_1=1e-07, alpha_2=1e-05, lambda_1=1e-05,\n                               lambda_2=1e-07, threshold_lambda=1000.0,\n                               tol=0.01))])",
      "text/html": "<style>#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 {color: black;background-color: white;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 pre{padding: 0;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-toggleable {background-color: white;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-estimator:hover {background-color: #d4ebff;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-item {z-index: 1;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-parallel-item:only-child::after {width: 0;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-934b1578-1c6e-46c0-93c4-1e18e668a717 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-934b1578-1c6e-46c0-93c4-1e18e668a717\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, QuantileTransformer(output_distribution=&#x27;normal&#x27;)),\n                (&#x27;regressor&#x27;,\n                 ARDRegression(alpha_1=1e-07, alpha_2=1e-05, lambda_1=1e-05,\n                               lambda_2=1e-07, threshold_lambda=1000.0,\n                               tol=0.01))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6dabc189-0d4f-4493-8b61-8b906b94658e\" type=\"checkbox\" ><label for=\"6dabc189-0d4f-4493-8b61-8b906b94658e\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, QuantileTransformer(output_distribution=&#x27;normal&#x27;)),\n                (&#x27;regressor&#x27;,\n                 ARDRegression(alpha_1=1e-07, alpha_2=1e-05, lambda_1=1e-05,\n                               lambda_2=1e-07, threshold_lambda=1000.0,\n                               tol=0.01))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"857ab9a0-9c83-452a-a7d9-3de5ca8d8642\" type=\"checkbox\" ><label for=\"857ab9a0-9c83-452a-a7d9-3de5ca8d8642\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer(output_distribution=&#x27;normal&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c3933043-3925-4a2b-ae3e-8acbf4075ef3\" type=\"checkbox\" ><label for=\"c3933043-3925-4a2b-ae3e-8acbf4075ef3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ARDRegression</label><div class=\"sk-toggleable__content\"><pre>ARDRegression(alpha_1=1e-07, alpha_2=1e-05, lambda_1=1e-05, lambda_2=1e-07,\n              threshold_lambda=1000.0, tol=0.01)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_ard)\n",
    "\n",
    "print(best_ard[1])\n",
    "\n",
    "ard_searched.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}