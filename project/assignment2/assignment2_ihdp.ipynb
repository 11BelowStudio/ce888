{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import traceback\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Final, List, TypeVar, Dict, Tuple, Any, Optional, Iterable, Union\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#print(sns.plotting_context())\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\",context=\"paper\")\n",
    "\n",
    "import matplotlib.style\n",
    "if \"seaborn-darkgrid\" in matplotlib.style.available:\n",
    "    matplotlib.style.use(\"seaborn-darkgrid\")\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_seed: Final[int] = 42\n",
    "\"Using the meaning of life, the universe, and everything as the seed for RNG\"\n",
    "\n",
    "def rng() -> np.random.Generator:\n",
    "    \"\"\"\n",
    "    Creates a new numpy random generator with a seed of 42.\n",
    "    :return: a new numpy random generator with a seed of 42\n",
    "    \"\"\"\n",
    "    return np.random.default_rng(seed=_seed)\n",
    "\n",
    "def rng_state() -> np.random.RandomState:\n",
    "    \"\"\"\n",
    "    Creates a new numpy randomstate with a seed of 42\n",
    "    :return: a new numpy randomstate with a seed of 42\n",
    "    \"\"\"\n",
    "    return np.random.RandomState(seed=_seed)\n",
    "\n",
    "\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IHDP dataset processing\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "def turn_01_columns_into_int(\n",
    "        dataframe_to_edit: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Finds all of the columns that just contain values of 0 and 1,\n",
    "    and converts all of those columns to ints.\n",
    "\n",
    "    Dataframe will have an '01' and 'not_01' attr added to it.\n",
    "    Labels for series that only contain values 0 and 1 will be in the '01' tuple\n",
    "    Labels for every other series will be in the 'not_01' tuple\n",
    "\n",
    "    MODIFIES THE GIVEN DATAFRAME!\n",
    "    :param dataframe_to_edit: the dataframe that is being edited\n",
    "    :return: The modified dataframe.\n",
    "    DOES NOT COPY THE GIVEN ORIGINAL DATAFRAME.\n",
    "\n",
    "    >>> import pandas as pd\n",
    "    >>> print(pd.__version__)\n",
    "    1.4.1\n",
    "    >>> before: pd.DataFrame = pd.DataFrame.from_dict(data={\"int01\":[0,1,1,0],\"flt01\":[0.0, 1.0, 0.0, 1.0], \"intNo\": [-1,0,1,2], \"fltNo\":[-1.0, 0.0, 1.0, 2.0], \"intNan\": [0,1,None,0], \"fltNan\":[0.0,1.0,None,0.0]})\n",
    "    >>> before_types = before.dtypes.values\n",
    "    >>> after: pd.DataFrame = turn_01_columns_into_int(before.copy())\n",
    "    >>> after_types = after.dtypes.values\n",
    "    >>> print(after_types[0])\n",
    "    uint8\n",
    "    >>> print(after_types[1])\n",
    "    uint8\n",
    "    >>> print(f\"{before_types[2] == after_types[2]} {before_types[3] == after_types[3]} {before_types[4] == after_types[4]} {before_types[5] == after_types[5]}\")\n",
    "    True True True True\n",
    "    >>> print(f\"{after.attrs['01']}\")\n",
    "    ('int01', 'flt01')\n",
    "    >>> print(f\"{after.attrs['not_01']} \")\n",
    "    ('intNo', 'fltNo', 'intNan', 'fltNan')\n",
    "    \"\"\"\n",
    "    cols_01: List[str] = []\n",
    "    not_01:  List[str] = []\n",
    "    for c in dataframe_to_edit.columns:\n",
    "        #if dataframe_to_edit[c].dtype == np.uint8:\n",
    "        #    continue\n",
    "        if dataframe_to_edit[c].isin([0,1]).all():\n",
    "            dataframe_to_edit[c] = dataframe_to_edit[c].astype(np.uint8)\n",
    "            cols_01.append(c)\n",
    "        else:\n",
    "            not_01.append(c)\n",
    "    dataframe_to_edit.attrs[\"01\"] = tuple(cols_01)\n",
    "    dataframe_to_edit.attrs[\"not_01\"] = tuple(not_01)\n",
    "    return dataframe_to_edit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "         x0        x1        x2        x3        x4        x5  x6  x7  x8  x9  \\\n0  1.397395  0.996346 -1.105624 -0.879606  0.308569 -1.023402   1   0   0   0   \n1  0.269033  0.196818  0.383828  0.161703 -0.629189  1.460832   1   0   1   0   \n2  1.051537  1.795874 -1.105624  0.161703 -0.629189  0.963985   1   0   1   1   \n3  0.662446  0.196818 -0.733261 -0.879606  0.371086 -0.692171   1   0   0   0   \n4  0.856992  1.795874  0.011465 -0.879606  0.558638  0.301522   0   1   1   0   \n\n   ...  x21  x22  x23  x24  t        yf       ycf       ite        t0  \\\n0  ...    0    0    0    1  1  4.771232 -0.298509  4.657928 -0.298509   \n1  ...    0    0    0    0  0  2.956273  5.783770  3.428604  2.956273   \n2  ...    0    0    0    1  0  4.164164  7.055789  3.658195  4.164164   \n3  ...    0    0    0    0  1  6.172307  1.379697  4.585505  1.379697   \n4  ...    0    0    0    0  1  7.834469  2.747986  4.265591  2.747986   \n\n         t1  \n0  4.771232  \n1  5.783770  \n2  7.055789  \n3  6.172307  \n4  7.834469  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x0</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n      <th>x5</th>\n      <th>x6</th>\n      <th>x7</th>\n      <th>x8</th>\n      <th>x9</th>\n      <th>...</th>\n      <th>x21</th>\n      <th>x22</th>\n      <th>x23</th>\n      <th>x24</th>\n      <th>t</th>\n      <th>yf</th>\n      <th>ycf</th>\n      <th>ite</th>\n      <th>t0</th>\n      <th>t1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.397395</td>\n      <td>0.996346</td>\n      <td>-1.105624</td>\n      <td>-0.879606</td>\n      <td>0.308569</td>\n      <td>-1.023402</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.771232</td>\n      <td>-0.298509</td>\n      <td>4.657928</td>\n      <td>-0.298509</td>\n      <td>4.771232</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.269033</td>\n      <td>0.196818</td>\n      <td>0.383828</td>\n      <td>0.161703</td>\n      <td>-0.629189</td>\n      <td>1.460832</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.956273</td>\n      <td>5.783770</td>\n      <td>3.428604</td>\n      <td>2.956273</td>\n      <td>5.783770</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.051537</td>\n      <td>1.795874</td>\n      <td>-1.105624</td>\n      <td>0.161703</td>\n      <td>-0.629189</td>\n      <td>0.963985</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.164164</td>\n      <td>7.055789</td>\n      <td>3.658195</td>\n      <td>4.164164</td>\n      <td>7.055789</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.662446</td>\n      <td>0.196818</td>\n      <td>-0.733261</td>\n      <td>-0.879606</td>\n      <td>0.371086</td>\n      <td>-0.692171</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6.172307</td>\n      <td>1.379697</td>\n      <td>4.585505</td>\n      <td>1.379697</td>\n      <td>6.172307</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.856992</td>\n      <td>1.795874</td>\n      <td>0.011465</td>\n      <td>-0.879606</td>\n      <td>0.558638</td>\n      <td>0.301522</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7.834469</td>\n      <td>2.747986</td>\n      <td>4.265591</td>\n      <td>2.747986</td>\n      <td>7.834469</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ihdp_full: pd.DataFrame = turn_01_columns_into_int(pd.read_csv(\"ihdp_full.csv\"))\n",
    "\"The full IHDP dataset (with supplementary t0 and t1 info) as a dataframe\"\n",
    "\n",
    "ihdp_full.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 747 entries, 0 to 746\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x0      747 non-null    float64\n",
      " 1   x1      747 non-null    float64\n",
      " 2   x2      747 non-null    float64\n",
      " 3   x3      747 non-null    float64\n",
      " 4   x4      747 non-null    float64\n",
      " 5   x5      747 non-null    float64\n",
      " 6   x6      747 non-null    uint8  \n",
      " 7   x7      747 non-null    uint8  \n",
      " 8   x8      747 non-null    uint8  \n",
      " 9   x9      747 non-null    uint8  \n",
      " 10  x10     747 non-null    uint8  \n",
      " 11  x11     747 non-null    uint8  \n",
      " 12  x12     747 non-null    uint8  \n",
      " 13  x13     747 non-null    uint8  \n",
      " 14  x14     747 non-null    uint8  \n",
      " 15  x15     747 non-null    uint8  \n",
      " 16  x16     747 non-null    uint8  \n",
      " 17  x17     747 non-null    uint8  \n",
      " 18  x18     747 non-null    uint8  \n",
      " 19  x19     747 non-null    uint8  \n",
      " 20  x20     747 non-null    uint8  \n",
      " 21  x21     747 non-null    uint8  \n",
      " 22  x22     747 non-null    uint8  \n",
      " 23  x23     747 non-null    uint8  \n",
      " 24  x24     747 non-null    uint8  \n",
      " 25  t       747 non-null    uint8  \n",
      " 26  yf      747 non-null    float64\n",
      " 27  ycf     747 non-null    float64\n",
      " 28  ite     747 non-null    float64\n",
      " 29  t0      747 non-null    float64\n",
      " 30  t1      747 non-null    float64\n",
      "dtypes: float64(11), uint8(20)\n",
      "memory usage: 78.9 KB\n"
     ]
    }
   ],
   "source": [
    "ihdp_full.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihdp_factuals: pd.DataFrame = ihdp_full.loc[:, ~ihdp_full.columns.isin(\n",
    "    [\"ycf\",\"ite\",\"t0\",\"t1\"]\n",
    ")]\n",
    "\"A version of the IHDP dataset containing ONLY the factual data\"\n",
    "\n",
    "ihdp_factuals_no_y: pd.DataFrame = ihdp_factuals.loc[:, ihdp_factuals.columns != \"yf\"]\n",
    "\"IHDP dataset with the factual Y omitted\"\n",
    "\n",
    "ihdp_factuals_y: pd.DataFrame = ihdp_factuals.loc[:, ihdp_factuals.columns == \"yf\"]\n",
    "\"Only the Y data from the IHDP dataset\"\n",
    "\n",
    "\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "#ihdp_learn_validation_skf: StratifiedKFold = StratifiedKFold(n_splits=10, shuffle=True, random_state=_seed)\n",
    "\"Using this to remove 10% of the treated/untreated factuals from ihdp for use as part of the validation dataset later on\"\n",
    "\n",
    "#ihdp_learn_indices, ihdp_validation_indices = [i for i in ihdp_learn_validation_skf.split(ihdp_factuals, ihdp_factuals[\"t\"])][0]\n",
    "\n",
    "ihdp_learn_indices, ihdp_validation_indices = train_test_split(\n",
    "    ihdp_factuals,\n",
    "    test_size=0.1,\n",
    "    random_state=rng(),\n",
    "    shuffle=True,\n",
    "    stratify=ihdp_factuals[\"t\"]\n",
    ")\n",
    "\n",
    "ihdp_learn_df: pd.DataFrame = ihdp_factuals.iloc[ihdp_learn_indices]\n",
    "\"The dataframe that is the subset of the IHDP factual data which will be used for learning feature importances etc\"\n",
    "\n",
    "ihdp_learn_df_x: pd.DataFrame = ihdp_learn_df.loc[:, ihdp_learn_df.columns != \"yf\"]\n",
    "\"X/T info for the dataframe that is the subset of the IHDP factual data which will be used for learning feature importances etc\"\n",
    "ihdp_learn_df_y: pd.DataFrame = ihdp_learn_df.loc[:, ihdp_learn_df.columns == \"yf\"]\n",
    "\"Y info for the dataframe that is the subset of the IHDP factual data which will be used for learning feature importances etc\"\n",
    "\n",
    "ihdp_validation_factual_df: pd.DataFrame = ihdp_factuals.iloc[ihdp_validation_indices]\n",
    "ihdp_validation_factual_df_x: pd.DataFrame = ihdp_validation_factual_df.loc[:, ihdp_validation_factual_df.columns != \"yf\"]\n",
    "ihdp_validation_factual_df_y: pd.DataFrame = ihdp_validation_factual_df.loc[:, ihdp_validation_factual_df.columns == \"yf\"]\n",
    "\n",
    "\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._validation import NotFittedError\n",
    "from sklearn.base import RegressorMixin, TransformerMixin\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn import set_config\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from math import inf\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "R = TypeVar('R', bound=RegressorMixin)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "def np_data_and_targets(\n",
    "        df: pd.DataFrame,\n",
    "        targetname: str = \"yf\"\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Converts dataframe into a couple of numpy ndarrays for the data without the labels,\n",
    "    and the labels by themselves.\n",
    "    :param df: the Dataframe\n",
    "    :param targetname: The name of the column holding the targets\n",
    "    :return: tuple of [ndarray of the values without the targets, just the class labels]\n",
    "    \"\"\"\n",
    "\n",
    "    inputs:  np.ndarray = df.loc[:,df.columns != targetname].to_numpy()\n",
    "    outputs: np.ndarray =  df.loc[:,targetname].to_numpy()\n",
    "\n",
    "    return inputs, outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def halving_grid_searcher(\n",
    "        regressor: R,\n",
    "        param_grid: Dict[str, List[Any]],\n",
    "        train_data: np.ndarray,\n",
    "        train_targets: np.ndarray,\n",
    "        k_folds: Union[KFold, Iterable[Tuple[np.ndarray, np.ndarray]]] = KFold(n_splits=5, shuffle=False),\n",
    "        class_weights: Optional[np.ndarray] = None\n",
    ") -> HalvingGridSearchCV:\n",
    "\n",
    "    pipe: Pipeline = Pipeline([\n",
    "        (\"scaler\", QuantileTransformer(output_distribution=\"normal\")),\n",
    "        (\"imputer\",KNNImputer(add_indicator=False, weights=\"distance\")),\n",
    "        (\"regressor\",regressor)\n",
    "    ])\n",
    "\n",
    "    h_grid_search: HalvingGridSearchCV = HalvingGridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        factor=3,\n",
    "        cv=k_folds,\n",
    "        scoring=make_scorer(r2_score),\n",
    "        refit=True,\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        error_score=-1000000000000\n",
    "        # I wanted to make this error score negative infinity, however, doing so caused a lot of\n",
    "        # particularly unsightly warning messages to appear.\n",
    "\n",
    "        # So, to save everyone involved from having to look at at a buttload of them with a buttload of numbers in them,\n",
    "        # I'm just setting this to an incredibly low finite number which should be rather hard to reach.\n",
    "        # And if this score (or an even lower score) somehow is reached legitimately, chances are that\n",
    "        # the legitimate score being lower than the error score will be the least of one's concerns.\n",
    "    )\n",
    "\n",
    "    if class_weights is not None:\n",
    "\n",
    "        h_grid_search.fit(\n",
    "            train_data, train_targets, sample_weight=class_weights\n",
    "        )\n",
    "    else:\n",
    "        h_grid_search.fit(\n",
    "            train_data, train_targets\n",
    "        )\n",
    "\n",
    "    return h_grid_search\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "def nested_halving_grid_searcher(\n",
    "        regressor: R,\n",
    "        param_grid: Dict[str, List[Any]],\n",
    "        learn_data: np.ndarray,\n",
    "        learn_targets: np.ndarray,\n",
    "        kfold_splits: int = 6,\n",
    "        learn_classes: Optional[np.ndarray] = None,\n",
    "        using_class_weights: bool = False,\n",
    "        nested_rng_generator: Optional[np.random.RandomState] = None\n",
    ") -> Dict[HalvingGridSearchCV, float]:\n",
    "\n",
    "    if nested_rng_generator is None:\n",
    "        nested_rng_generator = rng_state()\n",
    "\n",
    "    h_grid_search_dicts: Dict[HalvingGridSearchCV, float] = {}\n",
    "\n",
    "    the_splits: Iterable[np.ndarray, np.ndarray] = []\n",
    "\n",
    "    child_splits: int = max(1, kfold_splits-1)\n",
    "    child_kf: Union[KFold, Iterable[Tuple[np.ndarray, np.ndarray]]] = KFold(n_splits=child_splits, shuffle=False)\n",
    "\n",
    "    if learn_classes is None:\n",
    "\n",
    "        using_class_weights = False\n",
    "\n",
    "        my_kf: KFold = KFold(\n",
    "            n_splits=kfold_splits,\n",
    "            shuffle=True,\n",
    "            random_state=nested_rng_generator\n",
    "        )\n",
    "        the_splits = my_kf.split(learn_data, learn_targets)\n",
    "\n",
    "    else:\n",
    "\n",
    "        my_kf: StratifiedKFold = StratifiedKFold(\n",
    "            n_splits=kfold_splits,\n",
    "            shuffle=True,\n",
    "            random_state=nested_rng_generator\n",
    "        )\n",
    "\n",
    "        the_splits = my_kf.split(np.zeros_like(learn_classes), learn_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i, (train_indices, test_indices) in enumerate(the_splits, 1):\n",
    "        print(f\"-- {i}/{kfold_splits} start --\")\n",
    "        try:\n",
    "\n",
    "\n",
    "            if learn_classes is not None:\n",
    "                child_kf = [\n",
    "                    i for i in StratifiedKFold(\n",
    "                        n_splits=child_splits,\n",
    "                        shuffle=False\n",
    "                    ).split(\n",
    "                        X = np.zeros_like(train_indices),\n",
    "                        y = learn_classes[train_indices]\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "            if using_class_weights:\n",
    "\n",
    "                train_classes: np.ndarray = np.take(learn_classes, train_indices)\n",
    "\n",
    "                train_classes = train_classes / np.sum(train_classes)\n",
    "\n",
    "                test_classes: np.ndarray = np.take(learn_classes, test_indices)\n",
    "                test_classes = test_classes / np.sum(test_classes)\n",
    "\n",
    "                current_search: HalvingGridSearchCV = halving_grid_searcher(\n",
    "                    regressor,\n",
    "                    param_grid,\n",
    "                    learn_data[train_indices],\n",
    "                    learn_targets[train_indices],\n",
    "                    child_kf,\n",
    "                    class_weights = train_classes\n",
    "                )\n",
    "\n",
    "                current_score: float = current_search.score(\n",
    "                    learn_data[test_indices],\n",
    "                    learn_targets[test_indices]\n",
    "                )\n",
    "\n",
    "                h_grid_search_dicts[current_search] = current_score\n",
    "\n",
    "            else:\n",
    "\n",
    "\n",
    "                current_search: HalvingGridSearchCV = halving_grid_searcher(\n",
    "                    regressor,\n",
    "                    param_grid,\n",
    "                    learn_data[train_indices],\n",
    "                    learn_targets[train_indices],\n",
    "                    child_kf\n",
    "                )\n",
    "\n",
    "                current_score: float = current_search.score(\n",
    "                    learn_data[test_indices],\n",
    "                    learn_targets[test_indices]\n",
    "                )\n",
    "\n",
    "                h_grid_search_dicts[current_search] = current_score\n",
    "\n",
    "            print(f\"-- {i}/{kfold_splits} done. Score: {current_score} --\")\n",
    "\n",
    "        except NotFittedError as e:\n",
    "            print(\"oh no! there was a not fitted error!\", sys.stderr)\n",
    "            print(e, sys.stderr)\n",
    "            print(traceback.format_exc(), sys.stderr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return h_grid_search_dicts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('scaler', QuantileTransformer()),\n                ('learner', RandomForestRegressor())])",
      "text/html": "<style>#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd {color: black;background-color: white;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd pre{padding: 0;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-toggleable {background-color: white;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-estimator:hover {background-color: #d4ebff;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-item {z-index: 1;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-parallel-item:only-child::after {width: 0;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-d8053f96-e364-4ec6-b928-9fb4e0ca66fd\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, QuantileTransformer()),\n                (&#x27;learner&#x27;, RandomForestRegressor())])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a5c09eec-0cec-44f2-943d-8613c5d505ab\" type=\"checkbox\" ><label for=\"a5c09eec-0cec-44f2-943d-8613c5d505ab\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, QuantileTransformer()),\n                (&#x27;learner&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e363361b-be49-499e-8030-284019181351\" type=\"checkbox\" ><label for=\"e363361b-be49-499e-8030-284019181351\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"969c15ee-1fd8-41ec-b455-28889b2acaf9\" type=\"checkbox\" ><label for=\"969c15ee-1fd8-41ec-b455-28889b2acaf9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\",QuantileTransformer()),\n",
    "        (\"learner\",RandomForestRegressor())\n",
    "        #(\"learner\",ARDRegression())\n",
    "        #(\"learner\",AdaBoostRegressor(base_estimator=ARDRegression()))\n",
    "        #(\"learner\",LinearRegression())\n",
    "    ]\n",
    ")\n",
    "learner = fpipeline[\"learner\"]\n",
    "fpipeline.fit(ihdp_learn_df_x.to_numpy(), ihdp_learn_df_y.to_numpy())\n",
    "\n",
    "fpipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6981076040869733"
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpipeline.score(ihdp_validation_factual_df_x.to_numpy(), ihdp_validation_factual_df_y.to_numpy())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 1/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 60\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 20\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 7\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "-- 1/6 done. Score: 0.7408418710769594 --\n",
      "-- 2/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 60\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 20\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 7\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "-- 2/6 done. Score: 0.7281904547438132 --\n",
      "-- 3/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 60\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 20\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 7\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "-- 3/6 done. Score: 0.7912196701085774 --\n",
      "-- 4/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 60\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 20\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 7\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "-- 4/6 done. Score: 0.7250552885724484 --\n",
      "-- 5/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 60\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 20\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 7\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "-- 5/6 done. Score: 0.7980133874187758 --\n",
      "-- 6/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 20\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 60\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 20\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 7\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "-- 6/6 done. Score: 0.739494260634832 --\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_forest_searched_dict: Dict[\n",
    "    HalvingGridSearchCV, float\n",
    "] = nested_halving_grid_searcher(\n",
    "    RandomForestRegressor(criterion=\"squared_error\"),\n",
    "    {\n",
    "        \"regressor__n_estimators\": [75,100,125],\n",
    "        \"regressor__min_samples_split\": [2,4,6,8],\n",
    "        #\"regressor__min_impurity_decrease\": [0, *np.geomspace(0.00001,0.2,6)[1:]],\n",
    "        \"regressor__max_features\": [None,\"sqrt\",\"log2\",1,2],\n",
    "        #\"regressor__oob_score\": [False, True],\n",
    "        #\"regressor__ccp_alpha\": [0, *np.geomspace(0.00001,0.2,6)[1:]]\n",
    "    },\n",
    "    ihdp_learn_df_x.values,\n",
    "    ihdp_learn_df_y.values,\n",
    "    learn_classes = ihdp_learn_df_x[\"t\"].to_numpy(),\n",
    "    kfold_splits=6,\n",
    "    #classes_ndarray=ihdp_learn_df_x[\"t\"].to_numpy()\n",
    ")\n",
    "\n",
    "rf_searched: HalvingGridSearchCV = max(\n",
    "    random_forest_searched_dict.keys(),\n",
    "    key=lambda k: random_forest_searched_dict[k]\n",
    ")\n",
    "\n",
    "best_rf: Tuple[HalvingGridSearchCV, float] = (\n",
    "    rf_searched,\n",
    "    random_forest_searched_dict[rf_searched]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(HalvingGridSearchCV(cv=[(array([103, 104, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "       125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\n",
      "       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,\n",
      "       164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
      "       177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,\n",
      "       190, 19...\n",
      "                    estimator=Pipeline(steps=[('scaler',\n",
      "                                               QuantileTransformer(output_distribution='normal')),\n",
      "                                              ('imputer',\n",
      "                                               KNNImputer(weights='distance')),\n",
      "                                              ('regressor',\n",
      "                                               RandomForestRegressor())]),\n",
      "                    n_jobs=-1,\n",
      "                    param_grid={'regressor__max_features': [None, 'sqrt',\n",
      "                                                            'log2', 1, 2],\n",
      "                                'regressor__min_samples_split': [2, 4, 6, 8],\n",
      "                                'regressor__n_estimators': [75, 100, 125]},\n",
      "                    scoring=make_scorer(r2_score), verbose=1), 0.7980133874187758)\n",
      "0.7980133874187758\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pipeline(steps=[('scaler', QuantileTransformer(output_distribution='normal')),\n                ('imputer', KNNImputer(weights='distance')),\n                ('regressor',\n                 RandomForestRegressor(max_features=None, min_samples_split=4,\n                                       n_estimators=75))])",
      "text/html": "<style>#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 {color: black;background-color: white;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 pre{padding: 0;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-toggleable {background-color: white;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-estimator:hover {background-color: #d4ebff;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-item {z-index: 1;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-parallel-item:only-child::after {width: 0;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-313b24f2-a1f4-44a9-85bb-1f895a7f3b63\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, QuantileTransformer(output_distribution=&#x27;normal&#x27;)),\n                (&#x27;imputer&#x27;, KNNImputer(weights=&#x27;distance&#x27;)),\n                (&#x27;regressor&#x27;,\n                 RandomForestRegressor(max_features=None, min_samples_split=4,\n                                       n_estimators=75))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8f202327-5843-456b-81ae-e3c65c811b0c\" type=\"checkbox\" ><label for=\"8f202327-5843-456b-81ae-e3c65c811b0c\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, QuantileTransformer(output_distribution=&#x27;normal&#x27;)),\n                (&#x27;imputer&#x27;, KNNImputer(weights=&#x27;distance&#x27;)),\n                (&#x27;regressor&#x27;,\n                 RandomForestRegressor(max_features=None, min_samples_split=4,\n                                       n_estimators=75))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"621fa43e-b037-4325-b68d-49ed4650a0c6\" type=\"checkbox\" ><label for=\"621fa43e-b037-4325-b68d-49ed4650a0c6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer(output_distribution=&#x27;normal&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a839f6a1-be1e-4a7c-b8c0-db47f2038352\" type=\"checkbox\" ><label for=\"a839f6a1-be1e-4a7c-b8c0-db47f2038352\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer(weights=&#x27;distance&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a4e4bedc-ad4e-4854-9284-54553ce98afb\" type=\"checkbox\" ><label for=\"a4e4bedc-ad4e-4854-9284-54553ce98afb\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_features=None, min_samples_split=4, n_estimators=75)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_rf)\n",
    "\n",
    "print(best_rf[1])\n",
    "\n",
    "rf_searched.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 1/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 8\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2187\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 2187 candidates, totalling 10935 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 729\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 243\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 81\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "-- 1/6 done. Score: 0.7097435041911326 --\n",
      "-- 2/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 8\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2187\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 2187 candidates, totalling 10935 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 729\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 243\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 81\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "-- 2/6 done. Score: 0.720982312306641 --\n",
      "-- 3/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 8\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2187\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 2187 candidates, totalling 10935 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 729\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 243\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 81\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "-- 3/6 done. Score: 0.6427325474140977 --\n",
      "-- 4/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 8\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2187\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 2187 candidates, totalling 10935 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 729\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 243\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 81\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "-- 4/6 done. Score: 0.7060260750257823 --\n",
      "-- 5/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 8\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2187\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 2187 candidates, totalling 10935 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 729\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 243\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 81\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "-- 5/6 done. Score: 0.7680389575506759 --\n",
      "-- 6/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 8\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2187\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 2187 candidates, totalling 10935 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 729\n",
      "n_resources: 30\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 243\n",
      "n_resources: 90\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 81\n",
      "n_resources: 270\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "-- 6/6 done. Score: 0.7133910019178752 --\n"
     ]
    }
   ],
   "source": [
    "ard_iter: List[int] = [200,300,400]\n",
    "ard_tol: List[float] = [1e-2, 1e-3, 1e-4]\n",
    "ard_alpha_lambda: List[float] = [1e-5, 1e-6, 1e-7]\n",
    "ard_thresh_lambda: List[float] = [1e3, 1e4, 1e5]\n",
    "\n",
    "\n",
    "\n",
    "ard_searched_dict: Dict[\n",
    "    HalvingGridSearchCV, float\n",
    "] = nested_halving_grid_searcher(\n",
    "    ARDRegression(),\n",
    "    {\n",
    "        \"regressor__n_iter\": ard_iter,\n",
    "        \"regressor__tol\": ard_tol,\n",
    "        \"regressor__alpha_1\" : ard_alpha_lambda,\n",
    "        \"regressor__alpha_2\" : ard_alpha_lambda,\n",
    "        \"regressor__lambda_1\" : ard_alpha_lambda,\n",
    "        \"regressor__lambda_2\" : ard_alpha_lambda,\n",
    "        \"regressor__threshold_lambda\": ard_thresh_lambda\n",
    "    },\n",
    "    ihdp_learn_df_x.values,\n",
    "    ihdp_learn_df_y.values,\n",
    "    learn_classes = ihdp_learn_df_x[\"t\"].to_numpy(),\n",
    "    kfold_splits=6\n",
    ")\n",
    "\n",
    "ard_searched: HalvingGridSearchCV = max(\n",
    "    ard_searched_dict.keys(),\n",
    "    key=lambda k: ard_searched_dict[k]\n",
    ")\n",
    "\n",
    "best_ard: Tuple[HalvingGridSearchCV, float] = (\n",
    "    ard_searched,\n",
    "    ard_searched_dict[ard_searched]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(HalvingGridSearchCV(cv=[(array([103, 104, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "       125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\n",
      "       138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,\n",
      "       164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
      "       177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,\n",
      "       190, 19...\n",
      "                    n_jobs=-1,\n",
      "                    param_grid={'regressor__alpha_1': [1e-05, 1e-06, 1e-07],\n",
      "                                'regressor__alpha_2': [1e-05, 1e-06, 1e-07],\n",
      "                                'regressor__lambda_1': [1e-05, 1e-06, 1e-07],\n",
      "                                'regressor__lambda_2': [1e-05, 1e-06, 1e-07],\n",
      "                                'regressor__n_iter': [200, 300, 400],\n",
      "                                'regressor__threshold_lambda': [1000.0, 10000.0,\n",
      "                                                                100000.0],\n",
      "                                'regressor__tol': [0.01, 0.001, 0.0001]},\n",
      "                    scoring=make_scorer(r2_score), verbose=1), 0.7680389575506759)\n",
      "0.7680389575506759\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pipeline(steps=[('scaler', QuantileTransformer(output_distribution='normal')),\n                ('imputer', KNNImputer(weights='distance')),\n                ('regressor',\n                 ARDRegression(alpha_1=1e-07, alpha_2=1e-05, lambda_1=1e-05,\n                               lambda_2=1e-05, n_iter=200,\n                               threshold_lambda=100000.0, tol=0.0001))])",
      "text/html": "<style>#sk-ad332681-f5eb-43b7-b2be-09d219fd545c {color: black;background-color: white;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c pre{padding: 0;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-toggleable {background-color: white;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-estimator:hover {background-color: #d4ebff;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-item {z-index: 1;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-parallel-item:only-child::after {width: 0;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-ad332681-f5eb-43b7-b2be-09d219fd545c div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-ad332681-f5eb-43b7-b2be-09d219fd545c\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, QuantileTransformer(output_distribution=&#x27;normal&#x27;)),\n                (&#x27;imputer&#x27;, KNNImputer(weights=&#x27;distance&#x27;)),\n                (&#x27;regressor&#x27;,\n                 ARDRegression(alpha_1=1e-07, alpha_2=1e-05, lambda_1=1e-05,\n                               lambda_2=1e-05, n_iter=200,\n                               threshold_lambda=100000.0, tol=0.0001))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f9559987-7f18-4e4e-a256-fa8d53247ce5\" type=\"checkbox\" ><label for=\"f9559987-7f18-4e4e-a256-fa8d53247ce5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, QuantileTransformer(output_distribution=&#x27;normal&#x27;)),\n                (&#x27;imputer&#x27;, KNNImputer(weights=&#x27;distance&#x27;)),\n                (&#x27;regressor&#x27;,\n                 ARDRegression(alpha_1=1e-07, alpha_2=1e-05, lambda_1=1e-05,\n                               lambda_2=1e-05, n_iter=200,\n                               threshold_lambda=100000.0, tol=0.0001))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5ef97b1c-7715-4e5c-aaf5-ccdc703f2fb4\" type=\"checkbox\" ><label for=\"5ef97b1c-7715-4e5c-aaf5-ccdc703f2fb4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer(output_distribution=&#x27;normal&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ff34298c-5fbf-425a-8ec7-e98a6b508842\" type=\"checkbox\" ><label for=\"ff34298c-5fbf-425a-8ec7-e98a6b508842\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer(weights=&#x27;distance&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7b309717-b262-4a0b-b5bd-675a72c9ce04\" type=\"checkbox\" ><label for=\"7b309717-b262-4a0b-b5bd-675a72c9ce04\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ARDRegression</label><div class=\"sk-toggleable__content\"><pre>ARDRegression(alpha_1=1e-07, alpha_2=1e-05, lambda_1=1e-05, lambda_2=1e-05,\n              n_iter=200, threshold_lambda=100000.0, tol=0.0001)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_ard)\n",
    "\n",
    "print(best_ard[1])\n",
    "\n",
    "ard_searched.best_estimator_\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 1/6 start --\n",
      "n_iterations: 4\n",
      "n_required_iterations: 6\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 10\n",
      "max_resources_: 560\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 270\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8520/3055973665.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m rf_ada_searched_dict: Dict[\n\u001B[0;32m      6\u001B[0m     \u001B[0mHalvingGridSearchCV\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfloat\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnested_halving_grid_searcher\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m     \u001B[0mAdaBoostRegressor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0m_seed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m     {\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8520/362814237.py\u001B[0m in \u001B[0;36mnested_halving_grid_searcher\u001B[1;34m(regressor, param_grid, learn_data, learn_targets, kfold_splits, learn_classes, using_class_weights, nested_rng_generator)\u001B[0m\n\u001B[0;32m     88\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 90\u001B[1;33m                 current_search: HalvingGridSearchCV = halving_grid_searcher(\n\u001B[0m\u001B[0;32m     91\u001B[0m                     \u001B[0mregressor\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     92\u001B[0m                     \u001B[0mparam_grid\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8520/2035554886.py\u001B[0m in \u001B[0;36mhalving_grid_searcher\u001B[1;34m(regressor, param_grid, train_data, train_targets, k_folds, class_weights)\u001B[0m\n\u001B[0;32m     39\u001B[0m         )\n\u001B[0;32m     40\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 41\u001B[1;33m         h_grid_search.fit(\n\u001B[0m\u001B[0;32m     42\u001B[0m             \u001B[0mtrain_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_targets\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m         )\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_samples_orig\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_num_samples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgroups\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgroups\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    263\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    264\u001B[0m         \u001B[1;31m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    889\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    890\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 891\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    892\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    893\u001B[0m             \u001B[1;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py\u001B[0m in \u001B[0;36m_run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m    365\u001B[0m             }\n\u001B[0;32m    366\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 367\u001B[1;33m             results = evaluate_candidates(\n\u001B[0m\u001B[0;32m    368\u001B[0m                 \u001B[0mcandidate_params\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmore_results\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmore_results\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    369\u001B[0m             )\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    836\u001B[0m                     )\n\u001B[0;32m    837\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 838\u001B[1;33m                 out = parallel(\n\u001B[0m\u001B[0;32m    839\u001B[0m                     delayed(_fit_and_score)(\n\u001B[0;32m    840\u001B[0m                         \u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbase_estimator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1054\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1055\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1056\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1057\u001B[0m             \u001B[1;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1058\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    933\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    934\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'supports_timeout'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 935\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    936\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    937\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mwrap_future_result\u001B[1;34m(future, timeout)\u001B[0m\n\u001B[0;32m    540\u001B[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001B[0;32m    541\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 542\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfuture\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    543\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mCfTimeoutError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\python3\\lib\\concurrent\\futures\\_base.py\u001B[0m in \u001B[0;36mresult\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    438\u001B[0m                     \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    439\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 440\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_condition\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    441\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    442\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mCANCELLED\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mCANCELLED_AND_NOTIFIED\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\python3\\lib\\threading.py\u001B[0m in \u001B[0;36mwait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    310\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m    \u001B[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    311\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 312\u001B[1;33m                 \u001B[0mwaiter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    313\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "adaboost_estimators: List[int] = [40, 50, 60]\n",
    "adaboost_learn_rate: List[float] = [0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "adaboost_loss: List[str]= [\"linear\", \"square\", \"exponential\"]\n",
    "\n",
    "rf_ada_searched_dict: Dict[\n",
    "    HalvingGridSearchCV, float\n",
    "] = nested_halving_grid_searcher(\n",
    "    AdaBoostRegressor(random_state=_seed),\n",
    "    {\n",
    "        \"regressor__base_estimator\": [\n",
    "            Pipeline(\n",
    "                steps = [i for i in rf.best_estimator_.named_steps.items()]\n",
    "            ) for rf in random_forest_searched_dict.keys()\n",
    "        ],\n",
    "        \"regressor__n_estimators\": adaboost_estimators,\n",
    "        \"regressor__learning_rate\": adaboost_learn_rate,\n",
    "        \"regressor__loss\": adaboost_loss\n",
    "    },\n",
    "    ihdp_learn_df_x.values,\n",
    "    ihdp_learn_df_y.values,\n",
    "    learn_classes = ihdp_learn_df_x[\"t\"].to_numpy(),\n",
    "    kfold_splits=6\n",
    ")\n",
    "\n",
    "rf_ada_searched: HalvingGridSearchCV = max(\n",
    "    rf_ada_searched_dict.keys(),\n",
    "    key=lambda k: rf_ada_searched_dict[k]\n",
    ")\n",
    "\n",
    "best_rf_ada: Tuple[HalvingGridSearchCV, float] = (\n",
    "    rf_ada_searched,\n",
    "    rf_ada_searched_dict[rf_ada_searched]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(best_rf_ada)\n",
    "\n",
    "print(best_rf_ada[1])\n",
    "\n",
    "rf_ada_searched.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}