
@Misc{Gross1993,
author={Ruth T. Gross and others},
title={Infant Health and Development Program (IHDP): Enhancing the Outcomes of Low Birth Weight, Premature Infants in the United States, 1985-1988},
year={1993},
publisher={Inter-university Consortium for Political and Social Research [ICPSR]},
doi={10.3886/ICPSR09795.v1},
url={https://doi.org/10.3886/ICPSR09795.v1}
}


@article{BROOKSGUNN1992350,
title = {Effects of early intervention on cognitive function of low birth weight preterm infants},
journal = {The Journal of Pediatrics},
volume = {120},
number = {3},
pages = {350-359},
year = {1992},
issn = {0022-3476},
doi = {https://doi.org/10.1016/S0022-3476(05)80896-0},
url = {https://www.sciencedirect.com/science/article/pii/S0022347605808960},
author = {Jeanne Brooks-Gunn and Fong-ruey Liaw and Pamela Kato Klebanov},
abstract = {
        The Infant Health and Development Program is a randomized clinical trial to test the efficacy of educational and family support services and pediatric follow-up, offered during the first 3 years of life, in reducing the incidence of developmental delay in low birth weight preterm infants at eight clinical sites (N=985). It was hypothesized that larger intervention effects would be found for the domains in which low birth weight preterm infants are known to have problems, specifically visual-motor and spatial skills and receptive language skills. These analyses explore the effects of the Infant Health and Development Program on different domains of cognitive functioning. Cognitive domains are identified by means of factor analysis of the intelligence tests used at 12,24, and 36 months (Bayley Scales of infant Development (including the Mental and Motor scales) at 12 and 24 months; the Stanford-Binet, Peabody Picture Vocabulary Test, and Beery Test of Visual motor integration at 36 months). Our results reveal that, although intervention benefits accrue across cognitive domains at 24 and 36 months, gains are most pronounced for receptive language and visual-motor and spatial skills.
    }
}


@unpublished{CE888_causal,
    author={Damian Machlanski},
    title={CE888: Data Science and Decision Making Lecture 4: Causal Inference},
    year={2022},
    Institution = {University of Essex},
    howpublished = {University Lecture},
    note = {Lecture delivered on: {2022–8-2}}
}



@article{JOBS_LaLonde,
 ISSN = {00028282},
 URL = {http://www.jstor.org/stable/1806062},
 abstract = {This paper compares the effect on trainee earnings of an employment program that was run as a field experiment where participants were randomly assigned to treatment and control groups with the estimates that would have been produced by an econometrician. This comparison shows that many of the econometric procedures do not replicate the experimentally determined results, and it suggests that researchers should be aware of the potential for specification errors in other nonexperimental evaluations.},
 author = {Robert J. LaLonde},
 journal = {The American Economic Review},
 number = {4},
 pages = {604--620},
 publisher = {American Economic Association},
 title = {Evaluating the Econometric Evaluations of Training Programs with Experimental Data},
 volume = {76},
 year = {1986}
}


@techreport{JOBS2,
 title = "Propensity Score Matching Methods for Non-experimental Causal Studies",
 author = "Dehejia, Rajeev H and Wahba, Sadek",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "6829",
 year = "1998",
 month = "December",
 doi = {10.3386/w6829},
 URL = "http://www.nber.org/papers/w6829",
 abstract = {This paper considers causal inference and sample selection bias in non-experimental settings in which: (i) few units in the non-experimental comparison group are comparable to the treatment units, and (ii) selecting a subset of comparison units similar to the treatment units is difficult because units must be compared across a high-dimensional set of pre-treatment characteristics. We propose the use of propensity score matching methods and implement them using data from the NSW experiment.  Following Lalonde (1986), we pair the experimental treated units with non-experimental comparison units from the CPS and PSID and compare the estimates of the treatment effect obtained using our methods to the benchmark results from the experiment.  We show that the methods succeed in focusing attention on the small subset of the comparison units comparable to the treated units and, hence, in alleviating the bias due to systematic differences between the treated and comparison units.},
}



@software{econml,
  author={Keith Battocchi, Eleanor Dillon, Maggie Hei, Greg Lewis, Paul Oka, Miruna Oprescu, Vasilis Syrgkanis},
  title={{EconML}: {A Python Package for ML-Based Heterogeneous Treatment Effects Estimation}},
  howpublished={https://github.com/microsoft/EconML},
  note={Version 0.13},
  year={2019}
}

@article{sklearn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@inproceedings{sklearn_api,
  author    = {Lars Buitinck and Gilles Louppe and Mathieu Blondel and
               Fabian Pedregosa and Andreas Mueller and Olivier Grisel and
               Vlad Niculae and Peter Prettenhofer and Alexandre Gramfort
               and Jaques Grobler and Robert Layton and Jake VanderPlas and
               Arnaud Joly and Brian Holt and Ga{\"{e}}l Varoquaux},
  title     = {{API} design for machine learning software: experiences from the scikit-learn
               project},
  booktitle = {ECML PKDD Workshop: Languages for Data Mining and Machine Learning},
  year      = {2013},
  pages = {108--122},
}

@software{pd1,
    author       = {The pandas development team},
    title        = {pandas-dev/pandas: Pandas},
    month        = feb,
    year         = 2020,
    publisher    = {Zenodo},
    version      = {latest},
    doi          = {10.5281/zenodo.3509134},
    url          = {https://doi.org/10.5281/zenodo.3509134}
}

@InProceedings{ pd2,
  author    = { {W}es {M}c{K}inney },
  title     = { {D}ata {S}tructures for {S}tatistical {C}omputing in {P}ython },
  booktitle = { {P}roceedings of the 9th {P}ython in {S}cience {C}onference },
  pages     = { 56 - 61 },
  year      = { 2010 },
  editor    = { {S}t\'efan van der {W}alt and {J}arrod {M}illman },
  doi       = { 10.25080/Majora-92bf1922-00a }
}

@Article{         np,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}

@Article{plt,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python for
  application development, interactive scripting, and publication-quality
  image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = 2007
}

@incollection{shap,
title = {A Unified Approach to Interpreting Model Predictions},
author = {Lundberg, Scott M and Lee, Su-In},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {4765--4774},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf}
}

@article{shaptree,
  title={From local explanations to global understanding with explainable AI for trees},
  author={Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
  journal={Nature Machine Intelligence},
  volume={2},
  number={1},
  pages={2522-5839},
  year={2020},
  publisher={Nature Publishing Group}
}


@Online {sklearnmetricsr2scorescikitlearn102documentation,  title = {\texttt{sklearn.metrics.r2_score — scikit-learn 1.0.2 documentation}},  date = {2022-02-23},  year = {2022},  file = {:./references/stable-modules-generated-sklearn.metrics.r2_score.html.html:html},  url = {https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html},  urldate = {2022-02-23}}


@Misc{Fletcher10relevancevector, author = {Tristan Fletcher}, title = {Relevance Vector Machines Explained}, year = {2010}}

@Online {sklearnlinearmodelARDRegressionscikitlearn102documentation,  title = {\texttt{sklearn.linear_model.ARDRegression — scikit-learn 1.0.2 documentation}},  date = {2022-02-23},  year = {2022},  file = {:./references/stable-modules-generated-sklearn.linear_model.ARDRegression.html.html:html},  url = {https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ARDRegression.html#sklearn.linear_model.ARDRegression},  urldate = {2022-02-24}}

@Online {sklearnensembleAdaBoostRegressorscikitlearn102documentation,  title = {\texttt{sklearn.ensemble.AdaBoostRegressor — scikit-learn 1.0.2 documentation}},  date = {2022-02-23},  year = {2022},  file = {:./references/stable-modules-generated-sklearn.ensemble.AdaBoostRegressor.html.html:html},  url = {https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html?highlight=adaboostregressor#sklearn.ensemble.AdaBoostRegressor},  urldate = {2022-02-24}}

@Online {sklearnensembleRandomForestRegressorscikitlearn102documentation,  title = {\texttt{sklearn.ensemble.RandomForestRegressor — scikit-learn 1.0.2 documentation}},  date = {2022-02-24},  year = {2022},  file = {:./references/stable-modules-generated-sklearn.ensemble.RandomForestRegressor.html.html:html},  url = {\url{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html?highlight=randomforestregressor#sklearn.ensemble.RandomForestRegressor}},  urldate = {2022-02-24}}

@Online {sklearnlinearmodelLogisticRegressionscikitlearn102documentation,  title = {\texttt{sklearn.linear_model.LogisticRegression — scikit-learn 1.0.2 documentation}},  date = {2022-02-24},  year = {2022},  file = {:./references/stable-modules-generated-sklearn.linear_model.LogisticRegression.html.html:html},  url = {\url{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression}},  urldate = {2022-02-24}}

@Online {sklearnmetricsloglossscikitlearn102documentation,  title = {\texttt{sklearn.metrics.log_loss — scikit-learn 1.0.2 documentation}},  date = {2022-02-24},  year = {2022},  file = {:./references/stable-modules-generated-sklearn.metrics.log_loss.html.html:html},  url = {\url{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss}},  urldate = {2022-02-24}}

@Online {sklearnlinearmodelBayesianRidgescikitlearn102documentation,  title = {\texttt{sklearn.linear_model.BayesianRidge — scikit-learn 1.0.2 documentation}},  date = {2022-02-24},  year = {2022},  file = {:./references/stable-modules-generated-sklearn.linear_model.BayesianRidge.html.html:html},  url = {\url{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge}},  urldate = {2022-02-24}}

@Online {econmlmetalearnersXLearnereconml0130documentation,  title = {\texttt{econml.metalearners.XLearner — econml 0.13.0 documentation}},  date = {2022-02-14},  year = {2022},  file = {:./references/_autosummary-econml.metalearners.XLearner.html.html:html},  url = {https://econml.azurewebsites.net/_autosummary/econml.metalearners.XLearner.html},  urldate = {2022-02-24}}

@Online {econmldmlCausalForestDMLeconml0130documentation,  title = {\texttt{econml.dml.CausalForestDML — econml 0.13.0 documentation}},  date = {2022-02-14},  year = {2022},  file = {:./references/_autosummary-econml.dml.CausalForestDML.html.html:html},  url = {\url{https://econml.azurewebsites.net/_autosummary/econml.dml.CausalForestDML.html}},  urldate = {2022-02-24}}

@Online {econmldrForestDRLearnereconml0130documentation,  title = {\texttt{econml.dr.ForestDRLearner — econml 0.13.0 documentation}},  date = {2022-02-14},  year = {2022},  file = {:./references/_autosummary-econml.dr.ForestDRLearner.html.html:html},  url = {\url{https://econml.azurewebsites.net/_autosummary/econml.dr.ForestDRLearner.html}},  urldate = {2022-02-24}}


@unpublished{
CE888_project_causality,
author={Ana Matran-Fernandez},
title={Causal Inference: Machine Learning for Causal Inference from Observational Data},
note={CE888 assignment brief},
year={2022}
}

@article{ASMITH2005305,
title = {Does matching overcome LaLonde's critique of nonexperimental estimators?},
journal = {Journal of Econometrics},
volume = {125},
number = {1},
pages = {305-353},
year = {2005},
note = {Experimental and non-experimental evaluation of economic policy and models},
issn = {0304-4076},
doi = {https://doi.org/10.1016/j.jeconom.2004.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S030440760400082X},
author = {Jeffrey {A. Smith} and Petra {E. Todd}},
abstract = {This paper applies cross-sectional and longitudinal propensity score matching estimators to data from the National Supported Work (NSW) Demonstration that have been previously analyzed by LaLonde (1986) and Dehejia and Wahba (1999, 2002). We find that estimates of the impact of NSW based on propensity score matching are highly sensitive to both the set of variables included in the scores and the particular analysis sample used in the estimation. Among the estimators we study, the difference-in-differences matching estimator performs the best. We attribute its performance to the fact that it eliminates potential sources of temporally invariant bias present in the NSW data, such as geographic mismatch between participants and nonparticipants and the use of a dependent variable measured in different ways for the two groups. Our analysis demonstrates that while propensity score matching is a potentially useful econometric tool, it does not represent a general solution to the evaluation problem.}
}

@misc{fernandezloria2021causal,
      title={Causal Decision Making and Causal Effect Estimation Are Not the Same... and Why It Matters}, 
      author={Carlos Fernández-Loría and Foster Provost},
      year={2021},
      eprint={2104.04103},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@incollection{HILL2015255,
title = {Causal Inference: Overview},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {255-260},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.42095-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868420957},
author = {Jennifer Hill and Elizabeth A. Stuart},
keywords = {Causal inference, Common support, Ignorability, Observational studies, Overlap, Potential outcomes, Propensity scores, Quasi-experiments, Randomized experiments, Regression, SUTVA},
abstract = {This article discusses causal inference in statistics. It describes the theoretical framework and notation needed to formally define causal effects and the assumptions required to identify them nonparametrically. This involves definition of potential outcomes that represent the potential value of the outcome across different treatment exposures. Designs that allow researchers to satisfy or weaken these assumptions are briefly described. Then common parametric assumptions used to model effects and more current approaches that require weaker assumptions are discussed.}
}

@Article{Glass2013,
author={Thomas A. Glass and Steven N. Goodman and Miguel A. Hernán and Jonathan M. Samet},
title={Causal inference in public health},
journal={Annual review of public health},
year={2013},
edition={2013/01/07},
volume={34},
pages={61-75},
abstract={Causal inference has a central role in public health; the determination that an association is causal indicates the possibility for intervention. We review and comment on the long-used guidelines for interpreting evidence as supporting a causal association and contrast them with the potential outcomes framework that encourages thinking in terms of causes that are interventions. We argue that in public health this framework is more suitable, providing an estimate of an action's consequences rather than the less precise notion of a risk factor's causal effect. A variety of modern statistical methods adopt this approach. When an intervention cannot be specified, causal relations can still exist, but how to intervene to change the outcome will be unclear. In application, the often-complex structure of causal processes needs to be acknowledged and appropriate data collected to study them. These newer approaches need to be brought to bear on the increasingly complex public health challenges of our globalized world.},
note={23297653[pmid]},
note={PMC4079266[pmcid]},
issn={1545-2093},
doi={10.1146/annurev-publhealth-031811-124606},
url={https://pubmed.ncbi.nlm.nih.gov/23297653},
url={https://doi.org/10.1146/annurev-publhealth-031811-124606},
language={eng}
}

@ARTICLE{Mitchell2020-wi,
  title     = "Inverse probability of treatment weighting (propensity score)
               using the Military Health System Data Repository and national
               death index",
  author    = "Mitchell, Joshua D and Gage, Brian F and Fergestrom, Nicole and
               Novak, Eric and Villines, Todd C",
  abstract  = "When randomized controlled trials are not feasible,
               retrospective studies using big data provide an efficient and
               cost-effective alternative, though they are at risk for
               treatment selection bias. Treatment selection bias occurs in a
               non-randomized study when treatment selection is based on
               pre-treatment characteristics that are also associated with the
               outcome. These pre-treatment characteristics, or confounders,
               can influence evaluation of a treatment's effect on the outcome.
               Propensity scores minimize this bias by balancing the known
               confounders between treatment groups. There are a few approaches
               to performing propensity score analyses, including stratifying
               by the propensity score, propensity matching, and inverse
               probability of treatment weighting (IPTW). Described here is the
               use of IPTW to balance baseline comorbidities in a cohort of
               patients within the US Military Health System Data Repository
               (MDR). The MDR is a relatively optimal data source, as it
               provides a contained cohort in which nearly complete information
               on inpatient and outpatient services is available for eligible
               beneficiaries. Outlined below is the use of the MDR supplemented
               with information from the national death index to provide robust
               mortality data. Also provided are suggestions for using
               administrative data. Finally, the protocol shares an SAS code
               for using IPTW to balance known confounders and plot the
               cumulative incidence function for the outcome of interest.",
  journal   = "J. Vis. Exp.",
  publisher = "MyJove Corporation",
  number    =  155,
  month     =  jan,
  year      =  2020,
  language  = "en"
}
